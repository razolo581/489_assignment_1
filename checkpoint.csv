,First and Last Name,Unnamed: 1,"Source (Indeed, Linkedin, company site, usajobs...)",Job title,"Job Type (full, part time, hourly)",Company Name,Location,Remote/hybrid/onsite,Date Posted,Job post link (url),Job description (raw) - summary information about the role,Education required (High School/Bachelor/Masters),years experience required,Responsibilities/Duties (what you'll do),Qualifications (raw),Required qualifications,Preferred Qualifications,salary range (annual)
0,Ceyhun Eksin,,Indeed,Data Analyst - Junior,Full time,BRMS Global Systems,"Dallas, TX",on site,,https://www.indeed.com/cmp/Brms-Global-Systems/jobs?jk=95f2be488394bf76&start=0&clearPrefilter=1,"We are seeking a detail-oriented and analytical Data Analyst to join our dynamic team. The ideal candidate will be responsible for interpreting data, analyzing results using statistical techniques, and providing ongoing reports. You will work closely with various departments to identify trends and insights that can help drive business decisions. A strong background in data analysis, along with proficiency in relevant tools and programming languages, is essential for success in this role.",bachelors or higher,0,"Analyze large datasets to identify trends, patterns, and actionable insights.
Develop and implement machine learning models using frameworks such as TensorFlow and Spark.
Conduct data mining and perform ETL (Extract, Transform, Load) processes to prepare data for analysis.
Design and maintain databases ensuring optimal performance and reliability.
Utilize programming languages such as Python, R, Java, and C for data manipulation and model development.
Collaborate with stakeholders to define analytical requirements and deliver impactful solutions.
Implement unsupervised learning techniques for clustering and classification tasks.
Deploy models into production environments ensuring scalability and efficiency.
Utilize tools like Looker for data visualization and reporting.
Stay updated on advancements in AI, quantum engineering, and big data technologies.
","Proficiency in machine learning frameworks including TensorFlow, SAS, and Hadoop.
Strong experience with SQL for database querying and management.
Familiarity with linked data concepts and analytics methodologies.
Knowledge of programming languages such as Python, R, Java, C, VBA, and Bash (Unix shell).
Experience in model training, deployment, and performance evaluation.
Understanding of natural language processing techniques is a plus.
Strong problem-solving skills with the ability to work independently or as part of a team.
Excellent communication skills to convey complex technical concepts to non-technical stakeholders. Join us in our mission to harness the power of data to drive innovation and improve outcomes. If you are passionate about leveraging technology to solve real-world problems, we encourage you to apply.","Proficiency in machine learning frameworks including TensorFlow, SAS, and Hadoop.
Strong experience with SQL for database querying and management.
Familiarity with linked data concepts and analytics methodologies.
Knowledge of programming languages such as Python, R, Java, C, VBA, and Bash (Unix shell).
Experience in model training, deployment, and performance evaluation.
Understanding of natural language processing techniques is a plus.
Strong problem-solving skills with the ability to work independently or as part of a team.
Excellent communication skills to convey complex technical concepts to non-technical stakeholders. Join us in our mission to harness the power of data to drive innovation and improve outcomes. If you are passionate about leveraging technology to solve real-world problems, we encourage you to apply.",-,"$75,246.10 - $90,618.96"
1,Ceyhun Eksin,,Company site,Data Scientist,Full time,CVS Caremark,"Multiple locations (Atlanta, GA; Austin, TX; Hartford, CT etc)",hybrid,,https://jobs.cvshealth.com/us/en/job/CVSCHLUSR0809634EXTERNALENUS/Data-Scientist?utm_source=Appcast_Indeedorganic&ittk=Z1JMJCAUFF,"We’re building a world of health around every individual — shaping a more connected, convenient and compassionate health experience. At CVS Health®, you’ll be surrounded by passionate colleagues who care deeply, innovate with purpose, hold ourselves accountable and prioritize safety and quality in everything we do. Join us and be part of something bigger – helping to simplify health care one person, one family and one community at a time.","bachelors, masters (preferred)",1-2+,"Implements systems using data-oriented programming languages and visualization software to explore, analyze, and interpret large volumes of contract data and solve complex business problems.
Deploys data science initiatives using data mining, data modeling, NLP, and ML techniques (RAG, vector embeddings, LLMs) to extract key information from contracts.
Designs data solutions that meet client requirements by leveraging industry-leading tools and best practices to profile and translate contract data.
Applies data science and ML knowledge to improve contract extraction capabilities, optimize document processing operations, and drive evidence-based decision-making.
Develops analytical frameworks, key metrics, and performance dashboards to monitor extraction accuracy, processing efficiency, and system performance, including OKRs.
Communicates with stakeholders (executives, legal professionals, IT, business analysts) to understand needs and provide data-driven solutions.
Coordinates presentations and consultative services that outline data analytics results and demonstrate business impact of system improvements.
Stays current on innovative data analysis techniques, visualization tools, programming languages, and latest research papers in RAG, LLM applications, and information extraction.
Ensures adherence to data governance policies and procedures by educating team members on data science best practices and quality standards.","Experience programming using R or Python
Experience in SQL and MongoDB querying
Experience working in at least 1 cloud environment
Experience with data analysis libraries. Demonstrates good written and verbal communication skills and a strong ability to communicate technical concepts and implications to business partners
Effectively resolves problems and roadblocks as they occur
Demonstrates proficiency in several areas of data modeling, machine learning algorithms, statistical analysis, data engineering, and data visualization
Ability to work with large data sets from multiple data sources
Experience with Generative AI/LLM applications, prompt engineering, model evaluation.
Experience with vector embeddings and semantic search analysis
Experience with document processing and text analysis
Familiarity with data validation frameworks and quality assurance systems
Experience with performance analysis and optimization metrics","Experience programming using R or Python
Experience in SQL and MongoDB querying
Experience working in at least 1 cloud environment
Experience with data analysis libraries.","Demonstrates good written and verbal communication skills and a strong ability to communicate technical concepts and implications to business partners
Effectively resolves problems and roadblocks as they occur
Demonstrates proficiency in several areas of data modeling, machine learning algorithms, statistical analysis, data engineering, and data visualization
Ability to work with large data sets from multiple data sources
Experience with Generative AI/LLM applications, prompt engineering, model evaluation.
Experience with vector embeddings and semantic search analysis
Experience with document processing and text analysis
Familiarity with data validation frameworks and quality assurance systems
Experience with performance analysis and optimization metrics","$64,890.00 - $158,620.00"
2,Gabriel Rangel-Orozco,,Linkedin,Jr Business Analyst/Data Analytics,Full time,IntagHire,"Houston, TX",on site,2/11/2026,https://www.linkedin.com/jobs/view/4368253270/,"About the job
Junior Business Analyst – ONSITE IN HOUSTON 5X A WEEK. Some USA based travel (8 trips a year roughly for 2/3 nights). Perm role with benefits. Salary range is $70K to $85K. Recent graduates with Data Analytics or Data Science would be ideal. SQL.



The Business Analyst will help analyze design and recommend improvements to business processes and data flows. On projects or system enhancements, the BA will gather requirements, provide assistance with initial system configurations and data loading, perform testing, design reports and provide support for end users.



Location: 5 day a week-onsite role working in a beautiful office setting in downtown Houston, TX. with some USA travel.

Level: Entry-level (recent graduates only)



Required Qualifications

Bachelor’s or Master’s degree in Data Analytics, Data Science, or a closely related quantitative field (completed within the last 12 months preferred)
Strong academic performance from a recognized, rigorous program (preference for coursework in advanced analytics, databases, programming, or systems analysis)
Demonstrated relevant experience through internships, capstone projects, or academic research involving data analysis, requirements gathering, or process improvement


Preferred Qualifications

Master’s degree in a technical or analytical discipline (e.g., Math, Data Science, Business Analytics)
Exposure to SQL or similar query languages (through coursework, projects, or internships)
Exposure to Tibco Spotfire, Power BI, Tableau, or other data analytic/reporting tools for report writing and visualization (through coursework, projects, or internships)
Stakeholder-facing projects (e.g., working directly with business users, gathering requirements, or delivering insights/reports to non-technical audiences)


Key Competencies & Traits

Exceptional analytical and critical thinking skills – ability to break down complex problems, identify patterns, and draw logical conclusions
Applied intelligence – strong ability to learn quickly, connect dots across domains, and translate technical concepts into clear, actionable insights for non-technical stakeholders
High drive and intellectual curiosity – proven self-motivation, proactive ownership of challenges, and a genuine hunger to grow and contribute meaningfully
Excellent verbal and written communication skills – clear, concise, and professional in all interactions
Adaptability in dynamic environments – able to work independently in evolving situations, take initiative, and ask the right questions to drive clarity and progress",bachelors,0,"The Business Analyst will help analyze design and recommend improvements to business processes and data flows. On projects or system enhancements, the BA will gather requirements, provide assistance with initial system configurations and data loading, perform testing, design reports and provide support for end users.","Required Qualifications

Bachelor’s or Master’s degree in Data Analytics, Data Science, or a closely related quantitative field (completed within the last 12 months preferred)
Strong academic performance from a recognized, rigorous program (preference for coursework in advanced analytics, databases, programming, or systems analysis)
Demonstrated relevant experience through internships, capstone projects, or academic research involving data analysis, requirements gathering, or process improvement


Preferred Qualifications

Master’s degree in a technical or analytical discipline (e.g., Math, Data Science, Business Analytics)
Exposure to SQL or similar query languages (through coursework, projects, or internships)
Exposure to Tibco Spotfire, Power BI, Tableau, or other data analytic/reporting tools for report writing and visualization (through coursework, projects, or internships)
Stakeholder-facing projects (e.g., working directly with business users, gathering requirements, or delivering insights/reports to non-technical audiences)


Key Competencies & Traits

Exceptional analytical and critical thinking skills – ability to break down complex problems, identify patterns, and draw logical conclusions
Applied intelligence – strong ability to learn quickly, connect dots across domains, and translate technical concepts into clear, actionable insights for non-technical stakeholders
High drive and intellectual curiosity – proven self-motivation, proactive ownership of challenges, and a genuine hunger to grow and contribute meaningfully
Excellent verbal and written communication skills – clear, concise, and professional in all interactions
Adaptability in dynamic environments – able to work independently in evolving situations, take initiative, and ask the right questions to drive clarity and progress","Bachelor’s or Master’s degree in Data Analytics, Data Science, or a closely related quantitative field (completed within the last 12 months preferred)
Strong academic performance from a recognized, rigorous program (preference for coursework in advanced analytics, databases, programming, or systems analysis)
Demonstrated relevant experience through internships, capstone projects, or academic research involving data analysis, requirements gathering, or process improvement","Master’s degree in a technical or analytical discipline (e.g., Math, Data Science, Business Analytics)
Exposure to SQL or similar query languages (through coursework, projects, or internships)
Exposure to Tibco Spotfire, Power BI, Tableau, or other data analytic/reporting tools for report writing and visualization (through coursework, projects, or internships)
Stakeholder-facing projects (e.g., working directly with business users, gathering requirements, or delivering insights/reports to non-technical audiences)","$70,000.00 - $85,000"
3,Gabriel Rangel-Orozco,,Linkedin,Data Analyst,Full time,ExxonMobil,"Houston, TX",on site,1/29/2026,https://www.linkedin.com/jobs/view/4337073004/,"About the job
About Us
At ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net-zero future. As one of the world’s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.

The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower-emissions technologies.

We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society’s evolving needs. Learn more about our What and our Why and how we can work together.

About Houston
ExxonMobil's state-of-the-art campus north of Houston serves as home to its Upstream, Product Solutions and Low Carbon Solutions businesses and their associated service groups. The facility opened in 2014 and accommodates more than 10,000 employees and visitors.

By bringing many global functional groups together, the campus provides employees with the tools and capabilities needed today, and in the future, to achieve business objectives and accelerate the discovery of new resources, technologies and products. It was designed to foster improved collaboration, creativity and innovation and enhance the company’s ability to attract, develop and retain the top talent in the industry.

The campus is located in Spring, Texas, on 385 wooded acres immediately to the west of Interstate Highway 45 (I-45), at the intersection of I-45 and the Hardy Toll Road, approximately 25 miles from the cultural vibrancy of downtown Houston.

The campus was constructed to the highest standards of energy efficiency and environmental stewardship. Its design incorporates extensive research into best practices in building and workplace design through extensive benchmarking of the world’s top academic, research, and corporate facilities.

About
Learn more about what we do in Houston here. 
 What role you will play in our team

A Data Analyst will leverage data engineering and BI development techniques to pipeline, automate, analyze, and visualize data
This role reports to the Continuous Improvement team and supports strategic decision-making for safety, production, and cost optimization by applying data-driven insights
This job will be located in Houston, TX

What You Will Do
Develop automated reports, conduct analyses, and provide visibility into KPIs and performance drivers and trends  help create final displays of the results, often for formal presentations
Build and manage data pipelines integrating structured and unstructured data sources
Design, develop, and institute automated workflows utilizing various technologies (SQL, Python, Databricks, Alteryx, Spotfire, MS Power Platform and more) to minimize human error, standardize data, and apply data management best practices with a focus on data integrity and governance
Develop ETL processes and maintain application integrations across multiple systems and data sources
Coordinate with Field and Engineering to perform analysis on drivers impacting LOE, Capital, and Production
Develop, maintain, and distribute recurring reports for Permian Operations timely and accurately
Assist in compiling data for regulatory, financial, and accounting reporting
Maintain up-to-date and accurate data analysis and tool documentation for reference purposes
Evaluate current processes around data entry, data QC, report distribution and provide recommendations and solutions on optimizing existing processes
Identify redundancies, automation opportunities, process inefficiencies and provide solutions
Communicate, collaborate, and report with multiple departments – field operations, IT, accounting, data support groups, etc
Develop, maintain, distribute, and provide training on standardized tools for analyzing LOE, Capital, Production, and SSHE events/observations
Stay updated on advancements in data automation, analysis, AI, machine learning, and digital oilfield technologies
Mentor engineers/analysts within the team on data engineering and BI development techniques

About You
Bachelor's degree required in Data/Computer Science, Engineering, Mathematics or related field
Education should include mathematical and computer training
5+ years experience in a technical role
Advanced level of data handling skills to include data integration and creating reports
Proficient working with relational databases and generating complex data visualizations
Can modify established workflows and evaluate and assess errors as they arise
Can interpret, understand, and explain workflows and data processes
Performs complex analytics, generates insightful dashboards and or can write code to automate basic redundant workflows/processes
Works under limited supervision
Works with technical staff and professionals
Experience with data visualization including Spotfire and PowerBI applications is required
Experience with ETL processes and Workflow automation (Ex: Databricks, Alteryx) is required
Advanced proficiency in MS Office suite

Preferred Qualifications/ Experience
Understanding of programming languages such as Python, R, Matlab or similar is highly preferred
Subject Matter Expert within select functions applicable to Data Analyst role

Your Benefits
An ExxonMobil career is one designed to last. Our commitment to you runs deep: our employees grow personally and professionally, with benefits built on our core categories of health, security, finance, and life.

We offer you: 

Pension Plan: Enrollment is automatic and at no cost to you. The basic benefit is a monthly annuity to be paid to you in retirement for the rest of your life. 
Savings Plan: You can contribute between 6% and 20% of your pay and are encouraged to enroll right away. If you contribute at least 6% to your savings plan, the Company will contribute a 7% match
Comprehensive medical, dental, and vision plans. 
Culture of Health: Programs and resources to support your wellbeing. 
Employee Health Advisory Program: Provides confidential professional counseling for you and your family, including tools and resources promoting mental health and resiliency at no additional cost to you. 
Disability Plan: Income replacement for when you cannot work due to illness or injury occurring on or off the job. Enrollment is automatic and at no cost to you. 

More information on our Company’s benefits can be found at www.exxonmobilfamily.com

Please note benefits may be changed from time to time without notice, subject to applicable law.

Stay connected with us

Learn more at our website

Follow us on LinkedIN and Instagram

Like us on Facebook

Subscribe our channel at YouTube

Employer equal opportunity

ExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, citizenship status, protected veteran status, genetic information, or physical or mental disability.

Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship.

Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.

Job Id: 82322

",bachelors,5,"Develop automated reports, conduct analyses, and provide visibility into KPIs and performance drivers and trends  help create final displays of the results, often for formal presentations
Build and manage data pipelines integrating structured and unstructured data sources
Design, develop, and institute automated workflows utilizing various technologies (SQL, Python, Databricks, Alteryx, Spotfire, MS Power Platform and more) to minimize human error, standardize data, and apply data management best practices with a focus on data integrity and governance
Develop ETL processes and maintain application integrations across multiple systems and data sources
Coordinate with Field and Engineering to perform analysis on drivers impacting LOE, Capital, and Production
Develop, maintain, and distribute recurring reports for Permian Operations timely and accurately
Assist in compiling data for regulatory, financial, and accounting reporting
Maintain up-to-date and accurate data analysis and tool documentation for reference purposes
Evaluate current processes around data entry, data QC, report distribution and provide recommendations and solutions on optimizing existing processes
Identify redundancies, automation opportunities, process inefficiencies and provide solutions
Communicate, collaborate, and report with multiple departments – field operations, IT, accounting, data support groups, etc
Develop, maintain, distribute, and provide training on standardized tools for analyzing LOE, Capital, Production, and SSHE events/observations
Stay updated on advancements in data automation, analysis, AI, machine learning, and digital oilfield technologies
Mentor engineers/analysts within the team on data engineering and BI development techniques","About You
Bachelor's degree required in Data/Computer Science, Engineering, Mathematics or related field
Education should include mathematical and computer training
5+ years experience in a technical role
Advanced level of data handling skills to include data integration and creating reports
Proficient working with relational databases and generating complex data visualizations
Can modify established workflows and evaluate and assess errors as they arise
Can interpret, understand, and explain workflows and data processes
Performs complex analytics, generates insightful dashboards and or can write code to automate basic redundant workflows/processes
Works under limited supervision
Works with technical staff and professionals
Experience with data visualization including Spotfire and PowerBI applications is required
Experience with ETL processes and Workflow automation (Ex: Databricks, Alteryx) is required
Advanced proficiency in MS Office suite

Preferred Qualifications/ Experience
Understanding of programming languages such as Python, R, Matlab or similar is highly preferred
Subject Matter Expert within select functions applicable to Data Analyst role","Bachelor's degree required in Data/Computer Science, Engineering, Mathematics or related field
Education should include mathematical and computer training
5+ years experience in a technical role
Advanced level of data handling skills to include data integration and creating reports
Proficient working with relational databases and generating complex data visualizations
Can modify established workflows and evaluate and assess errors as they arise
Can interpret, understand, and explain workflows and data processes
Performs complex analytics, generates insightful dashboards and or can write code to automate basic redundant workflows/processes
Works under limited supervision
Works with technical staff and professionals
Experience with data visualization including Spotfire and PowerBI applications is required
Experience with ETL processes and Workflow automation (Ex: Databricks, Alteryx) is required
Advanced proficiency in MS Office suite","Understanding of programming languages such as Python, R, Matlab or similar is highly preferred
Subject Matter Expert within select functions applicable to Data Analyst role",
4,Gabriel Rangel-Orozco,,Linkedin,Senior Business Analyst - Information Technology,Full time,United Airlines,"Houston, TX",on site,2/7/2026,https://www.linkedin.com/jobs/view/4369976752/,"About the job
Achieving our goals starts with supporting yours. Grow your career, access top-tier health and wellness benefits, build lasting connections with your team and our customers, and travel the world using our extensive route network.

Come join us to create what’s next. Let’s define tomorrow, together.

Description

Job overview and responsibilities

The Senior Business Analyst will be responsible for understanding and documenting business requirements by providing strategic insights and recommendations for business improvement. In this role you will facilitate the development of solutions that effectively meet business needs. The role involves working closely with stakeholders to define and prioritize business requirements and ensure that the solutions developed by IT align with business strategy. This role emphasizes deep understanding of finance, stakeholder collaboration, and the use of predictive analytics to enhance analytics and decision-making.

The Role

Business Insights and Analysis:
Conduct deep-dive analyses into complex financial data to uncover trends and provide actionable insights
Utilize predictive analytics to forecast future financial scenarios and advise on potential business impacts
Tool Proficiency:
Effectively use analytical tools such as Power BI, OBIEE, Oracle Analytics, and Data Bricks to gather and interpret data, supporting business decision-making
Collaboration with Stakeholders:
Work directly with business units, including finance and operational teams, to define data requirements and business objectives
Translate these business needs into analytical projects
Collaborate closely with developers to ensure that financial analytics tools and systems are developed in alignment with both the technical roadmaps and business strategies
Simplify the communication bridge between finance stakeholders and technical teams to support effective implementation and ongoing enhancements
Project Management and Methodology:
Utilize Agile methodologies to manage multiple analytics projects, ensuring alignment with broader business goals and timely delivery of outcomes
Presentation and Reporting:
Prepare and present reports to senior management detailing findings, with clear visualizations and strategic recommendations to guide business decisions
Collaborate closely with developers to ensure that financial analytics tools and systems are developed in alignment with both the technical roadmaps and business strategies
Simplify the communication bridge between finance stakeholders and technical teams to support effective implementation and ongoing enhancements
Qualifications

What’s needed to succeed (Minimum Qualifications):

Bachelor's degree in computer science, business, finance, economics, or related field
3+ years of experience in a business analysis role, preferably within a finance or analytics-focused team.
Proven track record of delivering actionable business insights and managing analytical projects
Strong understanding of business analysis principles, methodologies, and best practices
Familiarity with agile project management methodologies, particularly Scrum and Kanban
Excellent verbal and written communication skills, with the ability to translate complex data into understandable reports and presentations
Proficiency in data analysis and analytics, including the ability to interpret and communicate insights from data
Proven ability to work effectively with cross-functional teams and influence business decisions through data-driven insights
Must be legally authorized to work in the United States for any employer without sponsorship
Successful completion of interview required to meet job qualification
Reliable, punctual attendance is an essential function of the position

What will help you propel from the pack (Preferred Qualifications):

Master's degree
Relevant certifications in business analysis, such as CBAP (Certified Business Analysis Professional) or certification in Agile methodologies like Scrum or Kanban
Training or certification in analytics tools used in financial analysis, such as Power BI or Oracle Analytics, is advantageous

The base pay range for this role is $102,220.00 to $133,194.00.

The base salary range/hourly rate listed is dependent on job-related, factors such as experience, education, and skills. This position is also eligible for bonus and/or long-term incentive compensation awards.

You may be eligible for the following competitive benefits: medical, dental, vision, life, accident & disability, parental leave, employee assistance program, commuter, paid holidays, paid time off, 401(k) and flight privileges.

United Airlines is an equal opportunity employer. United Airlines recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, gender identity, sexual orientation, physical ability, age, veteran status and other protected status as required by applicable law. Equal Opportunity Employer - Minorities/Women/Veterans/Disabled/LGBT.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions. Please contact JobAccommodations@united.com to request accommodation.

Benefits found in job post

401(k)","bachelors, masters (preferred)",3,"Business Insights and Analysis:
Conduct deep-dive analyses into complex financial data to uncover trends and provide actionable insights
Utilize predictive analytics to forecast future financial scenarios and advise on potential business impacts
Tool Proficiency:
Effectively use analytical tools such as Power BI, OBIEE, Oracle Analytics, and Data Bricks to gather and interpret data, supporting business decision-making
Collaboration with Stakeholders:
Work directly with business units, including finance and operational teams, to define data requirements and business objectives
Translate these business needs into analytical projects
Collaborate closely with developers to ensure that financial analytics tools and systems are developed in alignment with both the technical roadmaps and business strategies
Simplify the communication bridge between finance stakeholders and technical teams to support effective implementation and ongoing enhancements
Project Management and Methodology:
Utilize Agile methodologies to manage multiple analytics projects, ensuring alignment with broader business goals and timely delivery of outcomes
Presentation and Reporting:
Prepare and present reports to senior management detailing findings, with clear visualizations and strategic recommendations to guide business decisions
Collaborate closely with developers to ensure that financial analytics tools and systems are developed in alignment with both the technical roadmaps and business strategies
Simplify the communication bridge between finance stakeholders and technical teams to support effective implementation and ongoing enhancements","Qualifications

What’s needed to succeed (Minimum Qualifications):

Bachelor's degree in computer science, business, finance, economics, or related field
3+ years of experience in a business analysis role, preferably within a finance or analytics-focused team.
Proven track record of delivering actionable business insights and managing analytical projects
Strong understanding of business analysis principles, methodologies, and best practices
Familiarity with agile project management methodologies, particularly Scrum and Kanban
Excellent verbal and written communication skills, with the ability to translate complex data into understandable reports and presentations
Proficiency in data analysis and analytics, including the ability to interpret and communicate insights from data
Proven ability to work effectively with cross-functional teams and influence business decisions through data-driven insights
Must be legally authorized to work in the United States for any employer without sponsorship
Successful completion of interview required to meet job qualification
Reliable, punctual attendance is an essential function of the position

What will help you propel from the pack (Preferred Qualifications):

Master's degree
Relevant certifications in business analysis, such as CBAP (Certified Business Analysis Professional) or certification in Agile methodologies like Scrum or Kanban
Training or certification in analytics tools used in financial analysis, such as Power BI or Oracle Analytics, is advantageous
","Bachelor's degree in computer science, business, finance, economics, or related field
3+ years of experience in a business analysis role, preferably within a finance or analytics-focused team.
Proven track record of delivering actionable business insights and managing analytical projects
Strong understanding of business analysis principles, methodologies, and best practices
Familiarity with agile project management methodologies, particularly Scrum and Kanban
Excellent verbal and written communication skills, with the ability to translate complex data into understandable reports and presentations
Proficiency in data analysis and analytics, including the ability to interpret and communicate insights from data
Proven ability to work effectively with cross-functional teams and influence business decisions through data-driven insights
Must be legally authorized to work in the United States for any employer without sponsorship
Successful completion of interview required to meet job qualification
Reliable, punctual attendance is an essential function of the position","Master's degree
Relevant certifications in business analysis, such as CBAP (Certified Business Analysis Professional) or certification in Agile methodologies like Scrum or Kanban
Training or certification in analytics tools used in financial analysis, such as Power BI or Oracle Analytics, is advantageous","$102,220.00 - $133,194.00"
5,Anthony Do,,indeed,Quality Measures Data Analyst,Full time,Central Health,"Austin, TX",hybrid,,https://www.indeed.com/viewjob?jk=0c4f6ee48be03904,"Overview:
The Quality Measures Data Analyst will provide measure selection and data analysis expertise in support of Central Health’s Quality and Population Health initiatives. This team member will also participate in the selection, documentation, analysis, interpretation and reporting of clinical quality measures.
The Quality Measures Data Analyst will also contribute to the design and development of data warehouses, performance dashboards and other systems that respond to the needs of an integrated network of physicians, safety net providers and hospitals to advance care that is patient centered and data driven.","bachelor's, prefer master's",3,"Responsibilities:
ESSENTIAL DUTIES:
Prepares presentations and recurring and ad hoc reports to support the Quality, Assessment, and Improvement Department
Researches and selects clinical, financial, operational, and other measures used to provide quality and performance insight and decision support
Collects and documents business requirements from dashboard requestors, advises on source data and choice of visualization, and communicates requirements to dashboard developer/analysts
Develops and presents data reports and other complex information to executive leadership, board committees, provider partners, and stakeholders
Researches national, regional, and internal best practices/benchmarks and makes recommendations for change as appropriate
Analyzes, develops, identifies and troubleshoots data, data sources, and data anomalies
Assist with identifying opportunities for improvement and developing solutions using established performance improvement methodologies
Collaborates with internal and external clinical and administrative partners to develop metrics and to identify data sources and data collection methods
Provides education and consultation to staff throughout Central Health and contracted providers regarding measure calculation, reporting requirements and associated impact
Requires the use of independent judgement based on experience and industry knowledge 75 % of the time.
Detail-oriented to ensure accuracy.
Supports measurement and system improvement
Assist in the design and development of data warehouses
Design and develop performance reports and dashboard
Develop and maintain a metrics library","Knowledge of:
Healthcare quality measures for ambulatory, specialty, and inpatient settings (HEDIS, PQRS, NQF, AHRQ, CMS, etc.)
Healthcare reform and transformation initiatives
Principles and practices of project management and performance improvement
Data privacy practices and laws (e.g., HIPAA)
Skill in:
Tableau
SQL
R or Python scripting
Microsoft Office with emphasis in Word, Excel, PowerPoint, and Visio
Critical Thinking, analysis, and problems solving
Writing documentation, standard operating procedures, user guides, and similar products to clearly disseminate information to an enterprise-wide audience
Ability to:
Prioritize work and remain detailed oriented
Communicate complex information in clear and unambiguous terms
Collaborate effectively with team members, leadership, and internal and external customers","Bachelor’s degree in statistics, economics, finance, business, accounting, science, healthcare, social science, mathematics or any field conductive to the development of critical and analytical thinking skills.                                                                     MINIMUM EXPERIENCE:
Three (3) years of experience analyzing and reporting healthcare data.
Two (2) years’ experience in using SQL or Python scripting for databases queries.","PREFERRED EDUCATION:
Master’s degree in public health (epidemiology or biostatistics), public affairs, public policy or a clinical field such as nursing, medical assistant or similar is preferred.
PREFERRED EXPERIENCE:
Experience developing timeliness and work plans for data collection activities.
Experience conducting clinical or data quality assessments and audits.
Experience with patient throughput in the clinical setting.
Experience using statistical analysis software such as R or Python.
PREFERRED CERTIFICATIONS/LICENSURE:
Certified Professional in Healthcare Quality (CPHQ) or the ability to obtain certification within six (6) months of employment.",
6,Archelaus Paxon,,Handshake,Data Engineer,Full time,Glint Tech Solutions LLC,"Austin, TX",onsite,1/31/2026,https://app.joinhandshake.com/job-search/10690391?query=Data+Engineer&per_page=25&sort=relevance&page=1&employmentTypes=1&jobType=9,"Job description: We are looking for a talented and motivated Data Engineer to join our team and contribute to the organization’s data-driven initiatives. This position is well-suited for someone who enjoys creating scalable data solutions and working closely with various teams to deliver meaningful insights. Key Responsibilities: Build, enhance, and maintain secure and scalable data pipelines and engineering solutions Develop and manage both cloud-based and on-premise data systems, including data warehouses and APIs Work with business partners to understand needs and convert them into clear technical requirements Improve data workflows by optimizing processes and automating recurring tasks Investigate data issues, perform root cause analysis, and identify areas for process improvement Support analytics projects by integrating new data sources and ensuring strong data quality Qualifications: Bachelor’s degree in Computer or Information Science; Master’s degree is a plus 1-3 years of experience in data engineering or IT Strong SQL abilities and experience with relational database technologies Proficient in Python and Java/Scala, with experience working in cloud environments (AWS preferred) Hands-on experience with big data and ETL technologies such as Apache Spark, Hadoop, Snowflake, Informatica, Airflow, and Kafka Knowledge of .NET technologies (C# or VB.NET) and web application development Strong analytical thinking, problem-solving skills, and effective communication Ability to work independently as well as collaboratively in a fast-paced environment","bachelor's, masters",1-3,"Build, enhance, and maintain secure and scalable data pipelines and engineering solutions
Develop and manage both cloud-based and on-premise data systems, including data warehouses and APIs
Work with business partners to understand needs and convert them into clear technical requirements
Improve data workflows by optimizing processes and automating recurring tasks
Investigate data issues, perform root cause analysis, and identify areas for process improvement
Support analytics projects by integrating new data sources and ensuring strong data quality","Bachelor’s degree in Computer or Information Science; Master’s degree is a plus
1-3 years of experience in data engineering or IT
Strong SQL abilities and experience with relational database technologies
Proficient in Python and Java/Scala, with experience working in cloud environments (AWS preferred)
Hands-on experience with big data and ETL technologies such as Apache Spark, Hadoop, Snowflake, Informatica, Airflow, and Kafka
Knowledge of .NET technologies (C# or VB.NET) and web application development
Strong analytical thinking, problem-solving skills, and effective communication
Ability to work independently as well as collaboratively in a fast-paced environment","Bachelor’s degree in Computer or Information Science; Master’s degree is a plus
1-3 years of experience in data engineering or IT
Strong SQL abilities and experience with relational database technologies
Proficient in Python and Java/Scala, with experience working in cloud environments (AWS preferred)
Hands-on experience with big data and ETL technologies such as Apache Spark, Hadoop, Snowflake, Informatica, Airflow, and Kafka
Knowledge of .NET technologies (C# or VB.NET) and web application development
Strong analytical thinking, problem-solving skills, and effective communication
Ability to work independently as well as collaboratively in a fast-paced environment",Master's degree,
7,Archelaus Paxon,,Handshake,Junior Data Engineer,Full time,Quintrix Solutions,"Dallas, TX",onsite,1/23/2026,https://app.joinhandshake.com/public/jobs/10659944?utm_source=web&utm_campaign=job_share&utm_medium=copy_link&utm_content=stu-copy_link-job_page,"Job Title:             Data Engineer (Entry Level)

Location:             Dallas, TX (Onsite)

 

Job Overview:

We are looking for a motivated Junior Data Engineer to join our team. This role is perfect for recent graduates or interns who are eager to build their career in data engineering and work on cutting-edge big data technologies. You will work closely with experienced engineers to design, develop, and support enterprise-wide big data solutions.

 

Key Responsibilities:

Assist in the design and development of big data solutions using technologies such as Spark, Scala, AWS Glue, Lambda, SNS/SQS, and CloudWatch.
Develop applications primarily in Scala and Python with guidance from senior team members.
Write and optimize SQL queries, preferably with Redshift; experience with Snowflake is a plus.
Work on ETL/ELT processes and frameworks to ensure smooth data integration.
Participate in development tasks, including configuration, writing unit test cases, and testing support.
Help identify and troubleshoot defects and assist in root cause analysis during testing.
Support performance testing and production environment troubleshooting.
Collaborate with the team on best practices, including Git version control and CI/CD deployment processes.
Continuously learn and grow your skills in big data technologies and cloud platforms.
 

Prerequisites:

Recent graduate or currently pursuing a degree in Computer Science, Information Technology, Engineering, or related fields.
Basic experience or coursework in Scala, Python, or other programming languages.
Familiarity with SQL and database concepts.
Understanding of ETL/ELT concepts is preferred.
Exposure to AWS cloud services (Glue, Lambda, SNS/SQS) is a plus but not mandatory.
Strong problem-solving skills and eagerness to learn.
Good communication and teamwork abilities.
 

Selection Process & Training: 

Online assessment and technical interview by Quintrix.
Client Interview(s). 
2-3 weeks of pre-employment online instructor-led training. ",bachelor's,0,"Assist in the design and development of big data solutions using technologies such as Spark, Scala, AWS Glue, Lambda, SNS/SQS, and CloudWatch. Develop applications primarily in Scala and Python with guidance from senior team members. Write and optimize SQL queries, preferably with Redshift; experience with Snowflake is a plus. Work on ETL/ELT processes and frameworks to ensure smooth data integration. Participate in development tasks, including configuration, writing unit test cases, and testing support. Help identify and troubleshoot defects and assist in root cause analysis during testing. Support performance testing and production environment troubleshooting. Collaborate with the team on best practices, including Git version control and CI/CD deployment processes. Continuously learn and grow your skills in big data technologies and cloud platforms.","Recent graduate or currently pursuing a degree in Computer Science, Information Technology, Engineering, or related fields. Basic experience or coursework in Scala, Python, or other programming languages. Familiarity with SQL and database concepts. Understanding of ETL/ELT concepts is preferred. Exposure to AWS cloud services (Glue, Lambda, SNS/SQS) is a plus but not mandatory. Strong problem-solving skills and eagerness to learn. Good communication and teamwork abilities.","Recent graduate or currently pursuing a degree in Computer Science, Information Technology, Engineering, or related fields. Basic experience or coursework in Scala, Python, or other programming languages. Familiarity with SQL and database concepts. Understanding of ETL/ELT concepts is preferred. Exposure to AWS cloud services (Glue, Lambda, SNS/SQS) is a plus but not mandatory. Strong problem-solving skills and eagerness to learn. Good communication and teamwork abilities.",AWS Cloud Services,$52000 - $62400
8,Archelaus Paxon,,Handshake,Data Engineer,Full time,SoftStandard Solutions,"Multiple locations (Texas City, TX, Trenton, MI, etc)",hybrid,9/13/2025,https://app.joinhandshake.com/public/jobs/10016568?utm_source=web&utm_campaign=job_share&utm_medium=copy_link&utm_content=stu-copy_link-job_page,"Job brief We are looking for an experienced data engineer to join our team. You will use various methods to transform raw data into useful data systems. For example, you’ll create algorithms and conduct statistical analysis. Overall, you’ll strive for efficiency by aligning data systems with business goals. To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you. Contract Type: W2 Contract Responsibilities Analyze and organize raw data Build data systems and pipelines Evaluate business needs and objectives Interpret trends and patterns Conduct complex data analysis and report on results Prepare data for prescriptive and predictive modeling Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality and reliability Identify opportunities for data acquisition Develop analytical tools and programs Collaborate with data scientists and architects on several projects Requirements and skills BS/MS in Computer Science or related discipline (math, engineering etc). Experienced with 3 – 5 years. 3+ years of experience in data engineering disciplines. A passion for writing good, clean, and reliable code. Substantial experience with a broad range of database systems. Strong communications skills with both technical and non-technical team members. Collaborative and enthusiastic approach to software development. Strong sense of project ownership and personal responsibility. Requires technical competencies: Expertise in Python, SQL Expertise in at least one orchestration tool (Airflow, Dagster, etc.) Experience working with Apache Spark Column-oriented SQL data warehouses such as Snowflake or Redshift Experience working with AWS suite of data tools (S3, Glue, Lambda etc) Distributed messaging systems such as Apache Kafka or Amazon SNS Experience with Databricks, Deltalake. Must have any of these mentioned certifications : Databricks Certified Data Engineer Associate , Microsoft Azure Data Engineer Associate",bachelor's or master's,3-5,Analyze and organize raw data Build data systems and pipelines Evaluate business needs and objectives Interpret trends and patterns Conduct complex data analysis and report on results Prepare data for prescriptive and predictive modeling Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality and reliability Identify opportunities for data acquisition Develop analytical tools and programs Collaborate with data scientists and architects on several projects,"BS/MS in Computer Science or related discipline (math, engineering etc). Experienced with 3 – 5 years. 3+ years of experience in data engineering disciplines. A passion for writing good, clean, and reliable code. Substantial experience with a broad range of database systems. Strong communications skills with both technical and non-technical team members. Collaborative and enthusiastic approach to software development. Strong sense of project ownership and personal responsibility. Requires technical competencies: Expertise in Python, SQL Expertise in at least one orchestration tool (Airflow, Dagster, etc.) Experience working with Apache Spark Column-oriented SQL data warehouses such as Snowflake or Redshift Experience working with AWS suite of data tools (S3, Glue, Lambda etc) Distributed messaging systems such as Apache Kafka or Amazon SNS Experience with Databricks, Deltalake. Must have any of these mentioned certifications : Databricks Certified Data Engineer Associate , Microsoft Azure Data Engineer Associate","BS/MS in Computer Science or related discipline (math, engineering etc). Experienced with 3 – 5 years. 3+ years of experience in data engineering disciplines. A passion for writing good, clean, and reliable code. Substantial experience with a broad range of database systems. Strong communications skills with both technical and non-technical team members. Collaborative and enthusiastic approach to software development. Strong sense of project ownership and personal responsibility. Requires technical competencies: Expertise in Python, SQL Expertise in at least one orchestration tool (Airflow, Dagster, etc.) Experience working with Apache Spark Column-oriented SQL data warehouses such as Snowflake or Redshift Experience working with AWS suite of data tools (S3, Glue, Lambda etc) Distributed messaging systems such as Apache Kafka or Amazon SNS Experience with Databricks, Deltalake. Must have any of these mentioned certifications : Databricks Certified Data Engineer Associate , Microsoft Azure Data Engineer Associate",Master's degree,$62400 - $83200
9,Alejandro Rojo,,Toyota Careers,Data Scientist,Full time,Toyota Financial Services,"Plano, TX",onsite,12/15/2025,https://careers.toyota.com/us/en/job/10314000/Data-Scientist,"Toyota Financial Services is seeking highly motivated people to fill multiple Data Scientists openings to help our growing Data Science practice. 

This role is ideal for someone who will thrive working at the intersection of computational science, predictive modeling, and business consulting. The ideal candidate will excel at analysis, manipulation, and cleaning of data, building predictive and prescriptive models using a variety of theoretical and computational techniques, extract insights from models to help inform business decisions, and present results and recommendations to various business partners and leaders. Additionally, the ideal candidate will also possess the technical expertise to help transition models from development to production and deploy them efficiently. If you have a passion for end-to-end data solutions and enjoy working in a dynamic, collaborative setting, you could be the perfect fit for our team. ",masters or higher,0,"What you’ll be doing   

Work closely with team members and business partners to identify and prioritize key questions and drive impactful data-based decisions. 
Extract, manipulate, and clean data from diverse sources using SQL and Python, preparing it for detailed analysis and model development. 
Develop and implement sophisticated predictive and prescriptive models using statistical and machine learning techniques. Ensure these models address key business challenges and deliver actionable insights. 
Create clear, compelling data visualizations to effectively communicate findings to both technical and non-technical stakeholders. 
Effectively and efficiently transition models from development to production within the organization’s existing cloud ecosystem. 
Participate actively in project planning and prioritization sessions to ensure data initiatives align with business goals. 
Stay updated with the latest industry trends and tools and integrate this knowledge to improve methodologies and solutions.","Master’s degree or higher in a relevant analytical field. 
Hands-on experience building and optimizing data solutions using Python. 
Experience solving problems using a variety of statistical and machine learning techniques. 
Hands-on experience using statistical or machine learning frameworks to solve a variety of real-world problems (e.g., statsmodels, scikit-learn, PyTorch). 
Knowledge of methods like Logistic Regression, Time Series Analysis, GLMs, Mixed Modeling, Multivariate Statistics, Predictive Modeling, Decision Trees, Gradient-Boosted Trees, Random Forests, and Neural Networks. 
Experience with identifying problems and developing innovative solutions. 
Experience working in a data science role outside of a degree-seeking academic program. ","Master’s degree or higher in a relevant analytical field. 
Hands-on experience building and optimizing data solutions using Python. 
Experience solving problems using a variety of statistical and machine learning techniques. 
Hands-on experience using statistical or machine learning frameworks to solve a variety of real-world problems (e.g., statsmodels, scikit-learn, PyTorch). 
Knowledge of methods like Logistic Regression, Time Series Analysis, GLMs, Mixed Modeling, Multivariate Statistics, Predictive Modeling, Decision Trees, Gradient-Boosted Trees, Random Forests, and Neural Networks. 
Experience with identifying problems and developing innovative solutions. 
Experience working in a data science role outside of a degree-seeking academic program. ","Experience with version control systems such as GitHub, and familiarity with CI/CD practices to streamline model deployment and code management. 
Hands-on experience with cloud-based machine learning platforms (e.g., AWS SageMaker or Azure ML) to leverage scalable computing resources and tools. 
Demonstrated ability to lead through influence, effectively navigating and prioritizing complex cross-departmental projects to drive impactful change. 
Capability to replace and bridge existing legacy infrastructure and processes. 
Experience working with Data Science outside of a degree-seeking program.",Not specified
10,Alejandro Rojo,,Simplex Careers,Junior Data and Analytics Engineer,Full time,Simplex,"Austin, TX",onsite,1/27/2026,https://simplexhires.com/jobs/,"This role is in-office in Austin, TX. You must be local. 
Our client is a well-funded multi-site services/technology company headquartered in Austin, TX.
We are looking for a Junior Data/Analytics Engineer to assist the business with reviewing incoming Data. The role will require you to review, rationlize and report to the company's technical and leadership team. They are looking for customer trends and to be able to answer complicated questions about our business and our customers. These questions come from both internal business stakeholders and external clients.
As it stands, we can have the ability to run basic requests through Metabase using our current data architecture, but there are significant shortcomings to that process. You will work directly with the Head of Engineering in this role. ",bachloers,1-2,"Review Data and Data structures that address key questions we need to answer about our customers.
Partner with VPE/Product to report your findings
Maintain data quality/reliability ","SQL/Python for modeling and light ETL is an advantage.
A Computer Science Degree.
Ideally, 1-2 years of commercial experience in a Data Role. 
BI tools (Metabase/Tableau expert); AWS/Heroku a plus.
Business acumen: You can understand our business model and the ""why"" behind the data. 
Growth-stage scrappiness: a willingness to ask questions and solve problems.","SQL/Python for modeling and light ETL is an advantage.
A Computer Science Degree.
Ideally, 1-2 years of commercial experience in a Data Role. 
BI tools (Metabase/Tableau expert); AWS/Heroku a plus.
Business acumen: You can understand our business model and the ""why"" behind the data. 
Growth-stage scrappiness: a willingness to ask questions and solve problems.","SQL/Python for modeling and light ETL is an advantage.
A Computer Science Degree.
Ideally, 1-2 years of commercial experience in a Data Role. 
BI tools (Metabase/Tableau expert); AWS/Heroku a plus.
Business acumen: You can understand our business model and the ""why"" behind the data. 
Growth-stage scrappiness: a willingness to ask questions and solve problems.","$50,000.00-$60,000.00"
11,Alejandro Rojo,,IBM Careers,Associate Data Engineer,Full time,IBM,Multiple locations,onsite,2/2/2026,https://careers.ibm.com/en_US/careers/JobDetail?jobId=87247&source=WEB_Leadrouting,"Works with clients to advocate business process transformation, analyzes the application portfolio across ecosystem to understand the process optimization and automation opportunity and proposes end-to-end process transformation journey, including reimagined process/workflow models, improving business value and outcomes that meet the client objectives, with agility and flexibility.
Prioritizes and translates Client requirements and defines current and future operational scenarios (processes, models, use cases, plans and solutions) and works with Client business and the Architect to ensure proper translation of business requirements to solution requirements.
These positions are anticipated to start in 2026. We have positions open in these locations:
Atlanta, GA
Austin, TX
Chicago, IL
Dallas, TX
Houston, TX",bachelors,0,"Assist in designing and implementing scalable data architecture and management systems tailored for modern cloud environments. 
Work on optimizing existing data pipelines and processes for improved performance.
Work with ETL/ELT ingestion pipelines
Collect and analyze data to identify trends, providing clients with actionable insights to enhance marketing, operational, and business practices.
Participate in troubleshooting data-related issues, working to solve challenges and data inconsistencies. 
Create visually compelling and user-friendly data visualizations, dashboards, and reports to effectively communicate findings to both technical and non-technical stakeholders.
Ensure the integrity, accuracy, and reliability of data through rigorous data cleaning, validation, and preprocessing procedures.
Work with project team to prioritize and translate Client requirements and define current and future operational scenarios (processes, models, use cases, plans and solutions). Work collaboratively with Client and the Architect to ensure proper translation of business requirements to solution requirements.
Present analytical findings and recommendations clearly and concisely, demonstrating the value of data-driven decision-making to clients.
Work with cross-functional teams to tackle complex business problems, utilizing your data expertise to drive innovative solutions.
Stay informed about the latest trends and advancements in the modern data stack, bringing new ideas and best practices to the team.
Consulting Skills:
Works with clients to advocate business process transformation, analyzes the application portfolio across ecosystem to understand the process optimization and automation opportunity.
Strong communication skills and ability to articulate thoughts clearly and concisely.
Problem-solving mindset with the ability to ask questions, seek to understand, and recommend solutions.
Curious and eager to learn new skills, with the ability to adapt to changes easily.
Planning capabilities with an understanding of basic project management skills and Agile methodology.
Strong teamwork orientation, contributing positively to a collaborative environment.","Experience: ETL/ELT projects, data warehouse design, analytics pipelines, capstone data engineering
Skills/Tech: SQL, Python, dbt, Snowflake, BigQuery, Airflow, data modeling, CI/CD basics
Skills include a range of package workflow tool experience including on one of the following IBM BAW, Lombardi, iLog, Appian, Pega etc.
Data Engineer skills- pipeline design, infrastructure, vector databases, deployment, and scalability.
Other: strong analytical mindset, data governance, or data quality exposure 
Willingness to travel up to 100%, based on project requirements
Bachelor’s degree in a related field (Computer Science, Data Science, Statistics, Math, MIS, Engineering).
Minimum of 1 year of practical project experience or relevant training.
Certifications: SnowPro Core, Google Associate Cloud Engineer or Data Engineer coursework
General skills: GenAI literacy - prompt engineering, RAG, fine-tuning, and evaluation of generative models.","Experience: ETL/ELT projects, data warehouse design, analytics pipelines, capstone data engineering
Skills/Tech: SQL, Python, dbt, Snowflake, BigQuery, Airflow, data modeling, CI/CD basics
Skills include a range of package workflow tool experience including on one of the following IBM BAW, Lombardi, iLog, Appian, Pega etc.
Data Engineer skills- pipeline design, infrastructure, vector databases, deployment, and scalability.
Other: strong analytical mindset, data governance, or data quality exposure 
Willingness to travel up to 100%, based on project requirements","Bachelor’s degree in a related field (Computer Science, Data Science, Statistics, Math, MIS, Engineering).
Minimum of 1 year of practical project experience or relevant training.
Certifications: SnowPro Core, Google Associate Cloud Engineer or Data Engineer coursework
General skills: GenAI literacy - prompt engineering, RAG, fine-tuning, and evaluation of generative models.","$79,200.00-$118,800.00"
12,Alejandro Rojo,,Apple Careers,"Applied ML Engineer, Responsible AI",Full time,Apple,"Cupertino, CA",onsite,2/12/2026,https://jobs.apple.com/en-us/details/200645686-0836/aiml-applied-ml-engineer-responsible-ai?team=MLAI,"As engineer on this team, you will own the full lifecycle of our abuse detection machine learning models. You will collaborate closely with researchers to understand the threat landscape and partner with software and product teams to deploy robust, scalable defenses. We believe the most effective security systems are built by engineers who can translate adversarial insights into production-ready code. Your work will directly contribute to the architecture of Apple's AI platform and protect users from real-world harm. Here is what you will do: 
Design, build, and deploy production-grade ML models to detect and mitigate abuse across multiple modalities (text, image, audio).
Own the full ML lifecycle: from prototyping and data analysis to deployment, monitoring, and the continuous improvement of models in production.
Drive the data strategy to continuously improve model performance by analyzing distribution gaps, contributing to synthetic data pipelines, and creating automated annotation systems.
Architect end-to-end systems for monitoring platform activity, detecting misuse, and triggering automated enforcement actions in real-time.
Collaborate with cross-functional partners in engineering, research, and product to define project requirements, establish technical direction, and deliver robust security solutions.",bachelors or higher,2+,"As engineer on this team, you will own the full lifecycle of our abuse detection machine learning models. You will collaborate closely with researchers to understand the threat landscape and partner with software and product teams to deploy robust, scalable defenses. We believe the most effective security systems are built by engineers who can translate adversarial insights into production-ready code. Your work will directly contribute to the architecture of Apple's AI platform and protect users from real-world harm. Here is what you will do: 
Design, build, and deploy production-grade ML models to detect and mitigate abuse across multiple modalities (text, image, audio).
Own the full ML lifecycle: from prototyping and data analysis to deployment, monitoring, and the continuous improvement of models in production.
Drive the data strategy to continuously improve model performance by analyzing distribution gaps, contributing to synthetic data pipelines, and creating automated annotation systems.
Architect end-to-end systems for monitoring platform activity, detecting misuse, and triggering automated enforcement actions in real-time.
Collaborate with cross-functional partners in engineering, research, and product to define project requirements, establish technical direction, and deliver robust security solutions.","2+ years experience shipping machine learning models to production. You have owned the end-to-end lifecycle of a model, from development to deployment and maintenance.
Strong familiarity with research fundamentals, machine learning principles, and development methodologies around LLMs, foundation models, and diffusion models
Proficient programming skills in Python and deep learning toolkits (e.g. JAX, PyTorch, Tensorflow)
Ability to work with sensitive and offensive content as part of building robust security and abuse detection systems
BS, MS or PhD in Computer Science, Machine Learning, or related fields or an equivalent qualification acquired through other avenues
Hands-on experience with fine-tuning or aligning large language models for security or safety applications.
Experience building large-scale data processing pipelines and ML infrastructure.
Experience driving technical projects and collaborating with large, diverse, cross-functional teams","2+ years experience shipping machine learning models to production. You have owned the end-to-end lifecycle of a model, from development to deployment and maintenance.
Strong familiarity with research fundamentals, machine learning principles, and development methodologies around LLMs, foundation models, and diffusion models
Proficient programming skills in Python and deep learning toolkits (e.g. JAX, PyTorch, Tensorflow)
Ability to work with sensitive and offensive content as part of building robust security and abuse detection systems","BS, MS or PhD in Computer Science, Machine Learning, or related fields or an equivalent qualification acquired through other avenues
Hands-on experience with fine-tuning or aligning large language models for security or safety applications.
Experience building large-scale data processing pipelines and ML infrastructure.
Experience driving technical projects and collaborating with large, diverse, cross-functional teams","$181,100.00-$272,100.00"
13,Isa Victor,,LinkedIn,Business Intelligence Analyst,Full time,Corebridge Financial,"Multiple locations (Woodland Hills, CA; Houston, TX; New York, NY; Jersey City, NJ)",hybrid,2/11/26,https://www.linkedin.com/jobs/view/business-intelligence-analyst-at-corebridge-financial-4361906546?position=1&pageNum=0&refId=HFR6kzy6w7x276Pf8Omb1A%3D%3D&trackingId=pRXIk9cW0pBqdprttSsqKA%3D%3D,"We are seeking a dynamic and detail-oriented Business Intelligence Analyst with experience in financial services to support and modernize our Life & Annuities sales reporting function. This role combines data transformation, visualization, and stakeholder collaboration to deliver accurate, scalable, and actionable reporting solutions. The ideal candidate will have strong SQL skills, experience in developing interactive dashboards in Power BI and Tableau, and the ability to translate complex data into clear business insights.

The candidate will be naturally curious and possess strong interpersonal skills required to effectively build and maintain relationships with business stakeholders. This role is critical in replacing legacy processes with modern solutions and partnering with stakeholders to define and track meaningful KPI’s that drive sales strategy and performance.

","bachelors, masters (preferred)",3+,"Maintain, update, and distribute sales reports using Cognos Report Studio
Manage burst schedules and security filters to ensure accurate distribution to wholesalers, strategic accounts, and internal partners.
Translate complex business requirements into functional report changes or enhancements.
Fulfill custom reporting request and generate insights for Sr Leadership, Financial Distribution teams, and other stakeholders.
Ensure data integrity, perform validation checks, and resolve discrepancies for reporting and analytical teams.
Provide ad hoc statistical analysis and support for strategic initiatives through clear data storytelling

Data Wrangling & Transformation

Develop optimized data queries/scripts (i.e., SQL/Python) queries to extract, transform, and load data from multiple sources.
Collaborate with Data Governance Analyst to ensure report accuracy, resolve data quality issues, and maintain version control.
Support processes to improve data quality, consistency, and accessibility.

Modernization of Legacy Processes

Lead or support the transition from legacy reports to scalable automated BI solutions.
Translate static reports and complex datasets into interactive dashboard for business users.
Collaborate with stakeholders to define KPIs and key business metrics.
Implement best practices for data integration, metric consistency and scalable dashboard design.","3+ years of experience in data wrangling, analysis, and visualization within financial services , with direct experience in life insurance and annuities.
Demonstrated/Proven proficiency in SQL for querying large datasets. Python, R, or other programming languages for data manipulation and analysis a plus.
Experience with cloud-based data warehouses required (i.e., Snowflake)
Expertise in BI tools such as Power BI, Tableau, etc.
Experience with data governance frameworks and tools
Ability to work with large datasets and develop insights that drive business strategy.
Strong problem-solving skills and the ability to work independently and in cross-functional teams.","3+ years of experience in data wrangling, analysis, and visualization within financial services , with direct experience in life insurance and annuities.
Demonstrated/Proven proficiency in SQL for querying large datasets. Python, R, or other programming languages for data manipulation and analysis a plus.
Experience with cloud-based data warehouses required (i.e., Snowflake)
Expertise in BI tools such as Power BI, Tableau, etc.
Experience with data governance frameworks and tools
Ability to work with large datasets and develop insights that drive business strategy.
Strong problem-solving skills and the ability to work independently and in cross-functional teams..","Demonstrates good written and verbal communication skills and a strong ability to communicate technical concepts and implications to business partners
Effectively resolves problems and roadblocks as they occur
Demonstrates proficiency in several areas of data modeling, machine learning algorithms, statistical analysis, data engineering, and data visualization
Ability to work with large data sets from multiple data sources
Experience with Generative AI/LLM applications, prompt engineering, model evaluation.
Experience with vector embeddings and semantic search analysis
Experience with document processing and text analysis
Familiarity with data validation frameworks and quality assurance systems
Experience with performance analysis and optimization metrics","$82,000.00/yr - $100,000.00/yr"
14,Isa Victor,,LinkedIn,Data Engineer II,Full Time,Lennar,"Irving, TX",on-site,2/10/26,https://www.linkedin.com/jobs/view/data-engineer-ii-at-lennar-4370835576?position=3&pageNum=0&refId=vWIh%2BlW16saZtred1sNh4g%3D%3D&trackingId=wtbvoOMrTTjF3UME%2BZ7N5g%3D%3D,"Lennar is one of the nation's leading homebuilders, dedicated to making an impact and creating an extraordinary experience for their Homeowners, Communities, and Associates by building quality homes and providing exceptional customer service, giving back to the communities in which we work and live in, and fostering a culture of opportunity and growth for our Associates throughout their career. Lennar has been recognized as a Fortune 500® company and consistently ranked among the top homebuilders in the United States.

Join a Company that Empowers you to Build your Future

As a Data Engineer, you are responsible for analyzing large amounts of business data, solving real world problems, and developing metrics and business cases that will enable Business Insights. This is done by leveraging data from various platforms such as Jira, Portal, Salesforce. You will work with a team of Product Managers, Software Engineers and Business Intelligence Engineers to automate and scale the analysis, and to make the data more actionable to manage business at scale. You will own many large datasets, implement new data pipelines that feed into or from critical data systems.",bachelor's degree,3-5,"Design, implement and support an analytical data infrastructure and working knowledge of Modern Data Warehouse concepts.
Design, build, and maintain efficient and scalable data pipelines and ETL processes to process large volumes of structured and unstructured data.
Optimize data storage and retrieval methods to ensure performance, scalability, and cost-efficiency.
Manage AWS resources including EC2, S3, Glue, Lambda, API’s, IAM, Cloud Watch etc.
Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies
Collaborate with Data Scientists and Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in reporting and analysis
Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers
Maintain internal reporting platforms/tools including troubleshooting and development. Interact with internal users to establish and clarify requirements in order to develop report specifications.
Work with Engineering partners to help shape and implement the development of BI infrastructure including Data Warehousing, reporting and analytics platforms.
Contribute to the development of the BI tools, skills, culture and impact.
Write advanced SQL queries and Python code to develop solutions.","AWS Glue, Lambda, S3, EC2, CloudWatch, Cloud Trail.
Dbt, Snowflake, SQL, Python, Qlik.
Proficient in SQL, with the ability to write complex queries, perform query optimization, and conduct performance tuning.
Experience with NoSQL databases, such as MongoDB, Cassandra, or DynamoDB, and an understanding of their appropriate use cases.
Strong programming skills in Python, Java, or Scala, with experience in data processing frameworks (e.g., Apache Spark, Hadoop).
Experience with cloud platforms (AWS, Azure, GCP) and data services, such as AWS Redshift, Azure Synapse, or Google BigQuery.
Knowledge of big data technologies, including Hadoop, Spark, Kafka, and HBase, with experience in distributed data processing.
Familiarity with data orchestration tools, such as Apache Airflow for scheduling and managing data workflows.
Experience with data versioning and testing tools, such as DVC (Data Version Control) and dbt (data build tool).
Understanding of data security practices, including encryption, access controls, and data masking.","AWS Glue, Lambda, S3, EC2, CloudWatch, Cloud Trail.
Dbt, Snowflake, SQL, Python, Qlik.
Proficient in SQL, with the ability to write complex queries, perform query optimization, and conduct performance tuning.
Experience with NoSQL databases, such as MongoDB, Cassandra, or DynamoDB, and an understanding of their appropriate use cases.
Strong programming skills in Python, Java, or Scala, with experience in data processing frameworks (e.g., Apache Spark, Hadoop).
Experience with cloud platforms (AWS, Azure, GCP) and data services, such as AWS Redshift, Azure Synapse, or Google BigQuery.
Knowledge of big data technologies, including Hadoop, Spark, Kafka, and HBase, with experience in distributed data processing.
Familiarity with data orchestration tools, such as Apache Airflow for scheduling and managing data workflows.
Experience with data versioning and testing tools, such as DVC (Data Version Control) and dbt (data build tool).
Understanding of data security practices, including encryption, access controls, and data masking.","AWS Glue, Lambda, S3, EC2, CloudWatch, Cloud Trail.
Dbt, Snowflake, SQL, Python, Qlik.
Proficient in SQL, with the ability to write complex queries, perform query optimization, and conduct performance tuning.
Experience with NoSQL databases, such as MongoDB, Cassandra, or DynamoDB, and an understanding of their appropriate use cases.
Strong programming skills in Python, Java, or Scala, with experience in data processing frameworks (e.g., Apache Spark, Hadoop).
Experience with cloud platforms (AWS, Azure, GCP) and data services, such as AWS Redshift, Azure Synapse, or Google BigQuery.
Knowledge of big data technologies, including Hadoop, Spark, Kafka, and HBase, with experience in distributed data processing.
Familiarity with data orchestration tools, such as Apache Airflow for scheduling and managing data workflows.
Experience with data versioning and testing tools, such as DVC (Data Version Control) and dbt (data build tool).
Understanding of data security practices, including encryption, access controls, and data masking.",Not specified
15,Isa Victor,,LinkedIn,Data Analyst,Full Time,Interchecks,"Brooklyn, NY",on-site,2/12/26,https://www.linkedin.com/jobs/view/data-analyst-at-interchecks-4372134594?trk=public_jobs_topcard-title,"As a Data Analyst, you'll be the primary owner for day-to-day descriptive & diagnostic analytics—turning team outputs into executive-ready insights and decks, answering ad-hoc questions, and enforcing consistent metrics and narratives while being a direct contact for key stakeholders. This position is ideal for someone who loves turning messy questions into clean answers and thrives at the intersection of technical analysis and business communication..
",bachelor's degree,2 to 3,"

Monitor trends, quantify impact and deliver concise and compelling story
Create ad-hoc descriptive data summaries for a wide range of internal and external audiences
Document workflows, data definitions and processes to support compliance and organizational knowledge sharing


Demonstrate a deep and ongoing understanding of key performance metrics and extract valuable insights while communicating them across all levels of an organization
Become the trusted analytical partner, build scalable dashboards that reduce manual reporting time, and establish best practices for data quality that the broader team follows","2-3 years in business intelligence, reporting, or data analysis
Proficient in Tableau
Proficient in Excel and PowerPoint
Excellent written and verbal skills across all levels of an organization
Proficient in writing SQL queries to extract, transform, and analyze data from diverse data sources
Strong attention to detail and the ability to work with large datasets while maintaining data integrity
Excellent analytical and problem-solving skills with the ability to interpret complex data sets and communicate insights effectively
Strong data visualization design skills and modern presentation skills
Familiarity with Python based data analysis
Strong understanding of data quality principles and best practices","2-3 years in business intelligence, reporting, or data analysis
Proficient in Tableau
Proficient in Excel and PowerPoint
Excellent written and verbal skills across all levels of an organization
Proficient in writing SQL queries to extract, transform, and analyze data from diverse data sources
Strong attention to detail and the ability to work with large datasets while maintaining data integrity
Excellent analytical and problem-solving skills with the ability to interpret complex data sets and communicate insights effectively
Strong data visualization design skills and modern presentation skills
","Familiarity with Python based data analysis
Strong understanding of data quality principles and best practices",
16,Anthony Do,,Indeed,Senior AI Engineer,Full Time,Charles Schwab,"Austin, TX",hybrid,,https://www.indeed.com/viewjob?jk=35ba4c94ad4f928b,"Your opportunity
At Schwab, you’re empowered to make an impact on your career. Here, innovative thought meets creative problem solving, helping us “challenge the status quo” and transform the finance industry together.
We believe in the importance of in-office collaboration and fully intend for the selected candidate for this role to work on site in the specified location(s).
Schwab Technology Services enables the future of how clients manage their money by providing innovative and reliable technology products and services as a part of our ongoing commitment to democratize access to investing and financial planning.",bachelor's degree,8+,"As part of Schwab's AI Engineering & Operations team, you will be building the next generation Generative AI solutions that shape the future of technology at Schwab. In this role, you will contribute to the development and deployment of AI products that are instrumental in driving data-informed business decisions and elevating client experiences. You’ll collaborate across teams to deliver scalable, secure, and high-performing AI systems that align with Schwab’s innovation strategy and operational goals.","Required Qualifications:
8+ years of data engineering experience, with 4+ years as a hands-on senior engineer
4+ years developing scalable workflows and data pipelines that interface with large and complex datasets.
3+ years designing and implementing solutions utilizing Artificial Intelligence components such as NLP, LLMs, or machine learning techniques.
Bachelor’s degree in Computer Science, Data Engineering, Mathematics, Analytics, or related field.
2+ years working hands-on with containers and cloud-native platforms.
Preferred Qualifications:
Strong data engineering fundamentals and experience across the tech stack.
Commitment to quality—driving high standards including writing tests at all levels.
Strong written and verbal communication skills to clearly convey ideas and feedback.
Mentoring junior engineers and supporting their technical growth through code reviews and guidance.
Mindset of continuous learning and improvement.
Ability to solve complex problems with ambiguous or incomplete data in distributed systems.
Demonstrated business domain knowledge relevant to previous products.
Curiosity about new technologies and processes, proactively sharing knowledge and seeking improvement.
Experience with Python preferred but not required.
Master’s or advanced degree in Computer Science, Data Engineering, Mathematics, Analytics, or related field.","Required Qualifications:
8+ years of data engineering experience, with 4+ years as a hands-on senior engineer
4+ years developing scalable workflows and data pipelines that interface with large and complex datasets.
3+ years designing and implementing solutions utilizing Artificial Intelligence components such as NLP, LLMs, or machine learning techniques.
Bachelor’s degree in Computer Science, Data Engineering, Mathematics, Analytics, or related field.
2+ years working hands-on with containers and cloud-native platforms.","Preferred Qualifications:
Strong data engineering fundamentals and experience across the tech stack.
Commitment to quality—driving high standards including writing tests at all levels.
Strong written and verbal communication skills to clearly convey ideas and feedback.
Mentoring junior engineers and supporting their technical growth through code reviews and guidance.
Mindset of continuous learning and improvement.
Ability to solve complex problems with ambiguous or incomplete data in distributed systems.
Demonstrated business domain knowledge relevant to previous products.
Curiosity about new technologies and processes, proactively sharing knowledge and seeking improvement.
Experience with Python preferred but not required.
Master’s or advanced degree in Computer Science, Data Engineering, Mathematics, Analytics, or related field.","$150,000 - $175,000 a year"
17,Anthony Do,,Indeed,Lead Data Engineer,Full Time,L.G. Betts & Associates,"Austin, TX",hybrid,,https://www.indeed.com/viewjob?jk=ff98f74c7e3f3ecb,"Overview
As a Lead Data Engineer, you will play a critical role in ensuring the successful delivery and optimization of technical solutions in support of a value stream team. Your primary responsibility is to collaborate with team members to deliver high-quality solutions that align with business objectives. This position requires technical expertise and effective communication to support both new implementations and enhancements to existing systems.",bachelor's degree or equivalent experience,6-10 years,"Responsibilities

Solutions Delivery & Implementation
Collaboration with Stakeholders
System & Process Optimization
Agile Development
Troubleshooting & Resolution
Documentation
Best Practices
Testing & Debugging","Qualifications:

Bachelor's degree or equivalent experience
6-10 years of experience
Highly Preferred:
Experience in the insurance/financial industry
AWS Cloud Practitioner Certification
AWS: Glue, Step Functions, Lambda, Batch, S3, DynamoDB
Proficiency in Excel, SQL Server (queries, SSIS, SSRS), and ETL (Extract, Transform, Load) processes for supporting legacy solutions.
GitHub
Experience with project management software (e.g., Jira).
Expertise in Agile methodologies (e.g., Kanban, Scrum) for managing delivery
Understanding of SDLC processes, best practices, testing, deployment, and version control systems.
Experience ensuring secure data handling, especially sensitive financial data and personally identifiable information (PII).
Proficient in data validation and data cleansing practices.","Bachelor's degree or equivalent experience
6-10 years of experience","Experience in the insurance/financial industry
AWS Cloud Practitioner Certification
AWS: Glue, Step Functions, Lambda, Batch, S3, DynamoDB
Proficiency in Excel, SQL Server (queries, SSIS, SSRS), and ETL (Extract, Transform, Load) processes for supporting legacy solutions.
GitHub
Experience with project management software (e.g., Jira).
Expertise in Agile methodologies (e.g., Kanban, Scrum) for managing delivery
Understanding of SDLC processes, best practices, testing, deployment, and version control systems.
Experience ensuring secure data handling, especially sensitive financial data and personally identifiable information (PII).
Proficient in data validation and data cleansing practices.","$130,000.00 - $150,000.00 per year"
18,Aidan Villarreal,,Tallo,"Lead, Data Scientists",Full-Time,Petco,"Huston, Texas",on-site,2/12/2026,https://tallo.com/jobs/technology/data-scientist/tx/bexar/lead-data-scientist-543abaf783dc/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,"Create a healthier, brighter future for pets, pet parents and people! If you want to make a real difference, create an exciting career path, feel welcome to be your whole self and nurture your wellbeing, Petco is the place for you. Our core values capture that spirit as we work to improve lives by doing what’s right for pets, people and our planet. We love all pets like our own We’re the future of the pet industry We’re here to improve lives We drive outstanding results together We’re welcome as we are Petco is a category-defining health and wellness company focused on improving the lives of pets, pet parents and Petco partners. We are 29,000 strong and operate 1,500+ pet care centers in the U.S., Mexico and Puerto Rico, including 250+ Vetco Total Care hospitals, hundreds of preventive care clinics and eight distribution centers. We’re focused on purpose-driven work, and strongly believe what’s good for pets, people and our planet is good for Petco. Position Purpose As Lead Data Scientist on Petco’s Enterprise Analytics and Data Science team, you will spearhead the development and deployment of scalable, production-grade machine learning models that enable personalized membership and digital experiences. You will partner closely with stakeholders in the membership and digital teams to plan and execute data science initiatives that support customer engagement, loyalty growth, and digital performance.",masters or higher,8+ years,"Build, maintain, optimize, and productionize machine learning models and advanced algorithms that enhance membership and digital customer experiences. Generate and test hypotheses and analyze and interpret results of experiments. Communicate insights and recommendations through clear written reports and verbal presentations to audiences of varying technical sophistication. Improve upon existing methodologies by developing new data sources, testing model enhancements, and refining model parameters. Define requirements and collaborate with engineering teams to develop analytic capabilities, platforms, and pipelines that enable scalable modeling. Develop and monitor KPIs across multiple business areas, ensuring accurate tracking and performance measurement.","Education And Experience MS or PhD in Statistics, Math, Engineering, Economics, or a related quantitative field. 8+ years of experience in business analytics and data science. Previous experience working with machine learning/deep learning for real-world problems in a corporate environment is a must. Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.  Ability to explain/present complicated/advanced analytical methodology and results to non-technical audiences. Advanced quantitative modeling, statistical analysis, and critical thinking skills. ","Education And Experience MS or PhD in Statistics, Math, Engineering, Economics, or a related quantitative field. 8+ years of experience in business analytics and data science. Previous experience working with machine learning/deep learning for real-world problems in a corporate environment is a must. Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.",Proficiency with SQL and Python required; proficiency in R is a strong plus. Related experience in a retail organization is a strong plus. ,"$142,100.00 – $213,100.00"
19,Aidan Villarreal,,Indeed,"Senior Manager, Marketing Analytics & Data Engineering",Full-Tiime,Intellibright,"San Antonio, Texas",hybrid,,https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjS7r-ptdmSAxXYkmoFHbVCD3EQpowCKAB6BAgEEB4&url=https%3A%2F%2Fwww.indeed.com%2Fviewjob%3Fjk%3Df26f24bbd00f7844%26utm_campaign%3Dgoogle_jobs_apply%26utm_source%3Dgoogle_jobs_apply%26utm_medium%3Dorganic&usg=AOvVaw0mqfCDSLvSyKpqIFNpO99d&opi=89978449,"Our clients make real revenue decisions based on the data we deliver. Our strategists rely on it to set direction. Our executives trust it to scale the business.

As Senior Manager, Marketing Analytics & Data Engineering, you own the foundation that makes all of that possible.

This role sits at the center of how marketing, pipeline, and revenue data flow through the organization. You will design, build, and evolve the analytics infrastructure that connects marketing activity to real business outcomes at scale.

This is a role for someone who wants to build systems that last. You will think like an engineer, understand marketing deeply, and turn complex data environments into clear, trusted, decision ready insight.

If you care about accuracy, scalability, and impact and want your work to directly influence executive strategy and client retention, this role gives you that seat.",bachelor's or higher,6 to 9 years,"As Senior Manager, Marketing Analytics & Data Engineering, you own the foundation that makes all of that possible
This role sits at the center of how marketing, pipeline, and revenue data flow through the organization
You will design, build, and evolve the analytics infrastructure that connects marketing activity to real business outcomes at scale
This is a role for someone who wants to build systems that last
If you care about accuracy, scalability, and impact and want your work to directly influence executive strategy and client retention, this role gives you that seat
The evolution of Intellibright’s marketing and revenue analytics infrastructure, ensuring scalability, reliability, and clarity
End to end ownership of the analytics and reporting ecosystem, including data integrity, pipelines, models, dashboards, and documentation
Design and maintenance of data pipelines from ad platforms and CRMs into BigQuery","You will think like an engineer, understand marketing deeply, and turn complex data environments into clear, trusted, decision ready insight
Evaluation and optimization of analytics tooling including GA4, Looker Studio, BigQuery, CRM integrations, and attribution frameworks
Establishment of documentation, standards, and best practices for analytics and data engineering
You design systems for scale, not one off answers
You think in terms of decision making, not just reporting
You understand real world measurement limitations and model accordingly
You simplify complexity without oversimplifying truth
You take ownership of outcomes and build trust through consistency
Fast moving environment with high expectations and clear ownership
16 plus years of profitable, self funded growth
6 to 9 years of experience in marketing analytics, data engineering, or performance intelligence
Hands on experience building and maintaining data pipelines into BigQuery
Deep understanding of marketing and revenue data across paid, organic, web, and CRM systems","6 to 9 years of experience in marketing analytics, data engineering, or performance intelligence
Hands on experience building and maintaining data pipelines into BigQuery
Deep understanding of marketing and revenue data across paid, organic, web, and CRM systems
Strong fluency in Google Cloud Platform
Experience with Fivetran, Zapier, Looker or Looker Studio, Cloudflare, and GitHub
Ability to design and maintain scalable data models and transformations
Strong understanding of attribution, funnel modeling, and measurement tradeoffs
Ability to translate technical systems into clear business insight","Comfort operating in a growing, evolving analytics environment Agency or multi client experience strongly preferred"," $114,000 to $150,000"
20,Aidan Villarreal,,SimplyHired,Data Analyst / Report Writer,Full-Time,NavitasPartners,"Austin, Texas",on-site,2/10/2026,https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiwnKDTuNmSAxWdlmoFHRXRAu0Q3d0CKAN6BAgDECM&url=https%3A%2F%2Fwww.simplyhired.com%2Fjob%2FShYjN1gQLLcZnNHlEkuR6B3cDMBkkv7jdnojx-EhxIkX3fsyBbrVhQ%3Futm_campaign%3Dgoogle_jobs_apply%26utm_source%3Dgoogle_jobs_apply%26utm_medium%3Dorganic&usg=AOvVaw2iOxZ-_MLufTcEUTYmEmCw&opi=89978449,"Seeking an experienced Data Analyst to support the development of a platform that presents school system data in a clear, actionable, and user-friendly format. This role focuses on transforming complex datasets into meaningful insights and practical recommendations that help organizations identify areas for growth, establish goals, and improve outcomes.",bachelor's or higher,8+ years,"Seeking an experienced Data Analyst to support the development of a platform that presents school system data in a clear, actionable, and user-friendly format
This role focuses on transforming complex datasets into meaningful insights and practical recommendations that help organizations identify areas for growth, establish goals, and improve outcomes
The ideal candidate will have strong data storytelling skills, experience building low-code solutions, and expertise in creating dashboards and reporting tools that enable non-technical stakeholders to interpret and act on data effectively
Analyze school system data and translate findings into clear, practical recommendations to help identify priorities, set measurable goals, and improve performance outcomes
Develop and maintain low-code platforms (e.g., Power Platform, Qualtrics, or similar tools) to display key metrics and collect stakeholder input on progress and impact","8+ years of experience in Data Analytics and Data Storytelling
8+ years of experience working with low-code platforms and solutions
5+ years of proficiency in Microsoft Office Suite, particularly Excel (advanced formulas, data analysis, scorecards)
3+ years of experience with data visualization tools, including Power BI","8+ years of experience working with low-code platforms and solutions
5+ years of proficiency in Microsoft Office Suite, particularly Excel (advanced formulas, data analysis, scorecards)
3+ years of experience with data visualization tools, including Power BI","8+ years of experience in Data Analytics and Data Storytelling","$100,000-$180,000"
21,David Stein,,LinkedIn,AI Engineering/Data Scientist,Full Time,PwC,"Dallas, TX",hybrid,2/8/2026,https://www.linkedin.com/jobs/search-results/?currentJobId=4360122734&eBP=NON_CHARGEABLE_CHANNEL&refId=ndJ1FPogA5fJp0T89m%2Bu2g%3D%3D&trackingId=wC9evKDqRiCusOBosgrFjQ%3D%3D&keywords=machine%20learning%20internship&origin=BLENDED_SEARCH_RESULT_NAVIGATION_JOB_CARD&originToLandingJobPostings=4372797706%2C4372938118%2C4360122734,"As an AI Engineering/Data Scientist Intern, you will immerse yourself in the dynamic world of data science and machine learning engineering. You will engage with cutting-edge technologies and methodologies, contributing to projects that harness the power of data to drive impactful solutions for clients. As an Intern, you will support teams by participating in projects, observing professional work environments, and conducting research to contribute to the team's success. This role emphasizes learning and gaining exposure to PwC's practices, allowing you to develop your personal brand and build commercial awareness. In this role at PwC, you will have the chance to work on a variety of assignments, each presenting unique challenges and scope. You will be encouraged to ask questions, take initiative, and produce quality work that adds value. Your journey will involve applying a learning mindset, appreciating diverse perspectives, and adopting habits to sustain performance. This opportunity is designed to help you grow and develop your potential, paving the way for future opportunities within the firm.",pursuing bachelor's or higher,0,"Supporting data science and machine learning projects by assisting in the development and implementation of models
 Participating in the design and maintenance of data pipelines to facilitate seamless data flow and integration
 Engaging in complex data analysis to extract meaningful insights and identify patterns using quantitative methods
 Assisting in the application of artificial intelligence and natural language processing techniques to enhance data-driven solutions
 Collaborating with team members to apply programming languages in the development of machine learning algorithms
 Contributing to the creation of predictive models to forecast outcomes and inform decision-making processes
 Assisting in the evaluation and improvement of data quality to validate reliability and accuracy in analytics
 Observing and learning from experienced professionals to gain exposure to data engineering and analytics practices
 Supporting project management activities by coordinating tasks and tracking progress to meet project goals","Currently pursuing or have completed a Bachelor's degree
 Client service intern positions are entry-level roles intended for job seekers who are in their third year of a four-year degree program or fourth year of a five-year program at the time of application","Client service intern positions are entry-level roles intended for job seekers who are in their third year of a four-year degree program or fourth year of a five-year program at the time of application"," Currently pursuing or have completed a Bachelor's degree",$29.25-$48
22,David Stein,,LinkedIn,AI/ML Architect,Full Time,UST,"Plano, TX",hybrid,2/12/2026,https://www.linkedin.com/jobs/search-results/?currentJobId=4362263054&eBP=CwEAAAGcXVPGe0eodxXrkXA8tQ7lTl5EC_szGwjKA2Dz0l9xNkqXeeB8_FovFAd0TkfJZ4_IkJMQngnoCB9_sptl_fAuBoTPudlMmDQEFsg_onvX9C1f6jfkkpN-id82vL1hVVkfuCUgiUpplitBNUbnbZ58XdP-GeX6IeqFsXnpe-sMZgh4q4034H71vw8psEB6TO7_lTyFb5wPj20XuQxBH26G47uolc6F8mIZpLNHzY08dM3Qzbxbx94rr_2O0884ipgaiwhud_aI9GmRB88r-QH_eQ-SZYJOIGwdxwha_nHj-1-GrDLyIswUK8eE1L2kCiQ6LRVHAPQ2oZyuD75JmNXJwyQfudy6uWiwFYSJL1tAFKFh_E2jVIhFVo4gdkGYh_Aq15ILSzx99NALct6JY_PtloAEHtNJh1AXK40UbnnF9Wev6IFDj6ShUW6UYtPD1ocrF_SG5DkCPsfSWe493GcUB7O_oye-dpboGvBMNiY_TZhgQWjwG2WUlXEXMvZtCzHoqpveOWHVM7ZiFOCdUWwWBAMKdXY6&refId=%2FGDeGbrEZLXrEeXjoIgqnQ%3D%3D&trackingId=RBhswu%2F3QQoH6guLMgeDlg%3D%3D&keywords=machine%20learning&origin=SEMANTIC_SEARCH_LANDING_PAGE,"An AI/ML Architect designs and leads the development of artificial intelligence and machine learning solutions that align with business objectives. This role involves creating scalable AI/ML architectures, selecting appropriate algorithms and technologies, and guiding data science and engineering teams to deliver impactful AI-driven products.
",bachelor's or higher,8 to 10 years,"Design end-to-end AI and machine learning system architectures, including data pipelines, model development, deployment, and monitoring.
 Collaborate with business stakeholders to understand requirements and translate them into technical AI/ML solutions.
 Evaluate and select appropriate AI/ML frameworks, tools, and platforms.
 Define best practices and standards for AI/ML model development, testing, and deployment.
 Lead and mentor data scientists, ML engineers, and software developers in implementing AI solutions.
 Ensure AI/ML systems are scalable, secure, and maintainable.
 Oversee integration of AI/ML models with existing IT infrastructure and applications.","Years of Experience - 8-10
 Bachelor’s or master’s degree in computer science, Data Science, Artificial Intelligence, or related field.
 Proven experience as an AI/ML Architect, Data Scientist, or Machine Learning Engineer.
 Strong expertise in machine learning algorithms, deep learning, natural language processing, and computer vision.
 Proficiency with AI/ML frameworks and libraries such as TensorFlow, PyTorch, Scikit-learn, or similar.
 Experience with cloud AI/ML services (AWS SageMaker, Google AI Platform, Azure ML).
 Knowledge of data engineering, big data technologies, and data pipeline design.
 Strong programming skills in Python, R, or Java.
 Familiarity with containerization (Docker, Kubernetes) and CI/CD for ML workflows.","Proven experience as an AI/ML Architect, Data Scientist, or Machine Learning Engineer.
 Strong expertise in machine learning algorithms, deep learning, natural language processing, and computer vision.
 Proficiency with AI/ML frameworks and libraries such as TensorFlow, PyTorch, Scikit-learn, or similar.
 Experience with cloud AI/ML services (AWS SageMaker, Google AI Platform, Azure ML).
 Knowledge of data engineering, big data technologies, and data pipeline design.
 Strong programming skills in Python, R, or Java.
 Familiarity with containerization (Docker, Kubernetes) and CI/CD for ML workflows.","Years of Experience - 8-10
 Bachelor’s or master’s degree in computer science, Data Science, Artificial Intelligence, or related field.",$75000-$113000
23,David Stein,,LinkedIn,Machine Learning Tech Lead,Full Time,Crowe,"Plano, TX",hybrid,1/31/2026,https://www.linkedin.com/jobs/search-results/?currentJobId=4358640750&eBP=CwEAAAGcXVPGe-Jfk0rA-crKwYIHvqd7hFR0nxifcMvVthGnWJ5ER2x_Ah08_qv7IzbR9AOjO-YU7NmtNy2jxVvy-vs6j1354Agd717NRbFq54rw3-cresgeRvxio2-GZwuTXu5PeBLfpgw85YEigX6gvoNcCiC7rD4KC2EnlPr_N2iDNCQ1j49Py4J1stpSTAET57Vlkx1LUQ-xcBoHydR_kzojcR0Bp3JmAOcT4Nl-Cf4j7toO4mMoeRyA0QxXq3yTpdG5Y89slB96x85kvayCL4ktoqJAtaboLAmmmawvG_uaaxTvgATR2y8Ke6MFcjcJ3uc7xX65kC1ZIlufR-nxM_UaWxh9ly7_L3e7foBlO0srfGy01Q_Xr8ySHWFCvWDX9IicMTBUhD622_MaExAkzE-2HtwRK3zNmLeX4yNY9j5HUMqS3Be_RsnJqBMIwhIj31pZXbFQLevb0HiB5q3bRncN2eNX4is4cfhICxf3ugfAV3CnSxFanyyHXUZ2Q-4BJVgsl6uc_FNjHoft4TQqfBeSAqRQvC0l&refId=%2FGDeGbrEZLXrEeXjoIgqnQ%3D%3D&trackingId=q1xRFuvTtua7UXyYPEH7AQ%3D%3D&keywords=machine%20learning&origin=SEMANTIC_SEARCH_LANDING_PAGE,"As a Tech Lead in AI Products, your responsibilities will vary across the development lifecycle, and include providing solutions architecture and vision for existing solutions, supporting new feature development and testing, and preparing for release of high-quality, deployment-ready code. ",bachelor's or higher,,"AI Product Tech Leads must have strong stakeholder-facing skills to translate business problems into AI solution designs, reference architectures, and implementation roadmaps. 
AI Product Tech Leads are responsible for architecting the transition of AI projects from Proof of Concept to robust, production-ready solutions that transform our business offerings. 
Conduct lightweight sprint planning and review sessions, prioritizing features and managing project timelines. 
Write, review, and ensure the quality of production-ready code, setting high standards for the team. 
You seek deep understanding and take ownership of the impact your technical decision-making has on driving costs for the firm and/or clients. 
Oversee the implementation of testing protocols, including smoke tests and unit tests, to maintain high-quality outputs, in collaboration with members of the AI Platform and Infrastructure engineers. 
Prepare and refine Service Level Agreements (SLAs) and release documentation in preparation for production deployment; collaborate with Enablement team to create user upskilling materials that support effective use and drive adoption of AI solutions and latest features. 
Lead ethical reviews and risk/security evaluations to ensure compliance and safeguard our solutions. 
Engage with business stakeholders and proactively identify big picture improvements that benefit the client, product, and/or development team. 
Act as a career coach, fostering the growth and development of 3+ team members through knowledge-sharing, constructive code review, and by setting the standard for code quality and research best practices. 
Willingness to travel domestically to meet client needs. ","""AI Agent Experience. Familiarity with evaluation, monitoring, and observability of AI agents, including guardrails, hallucination mitigation, and human-in-the-loop designs. Ability to translate business requirements into agent behaviors, decision logic, and measurable performance outcomes. Proven ability to design end-to-end AI architectures that integrate agents with enterprise systems (ERP, CRM, data platforms, APIs) using scalable, secure integration patterns. 
Cloud Experience: Experience designing and deploying AI/ML solutions on major cloud platforms (AWS, Azure, and/or GCP), including the use of managed AI services, cloud-native integration patterns, scalable data architectures, and secure, enterprise-grade deployments. 
Knowledge sharing. You enjoy sharing what you learn, whether by offering cross-training opportunities, giving internal team “lightning talks,” or by writing detailed comments on tickets when you close them. 
Curiosity about AI and machine learning. You want to stay fresh in AI and machine learning. You demonstrate curiosity and continuous learning mindset in Generative AI and applied machine learning, with an interest in staying current on emerging models, architectures, and techniques, including engaging with original research, technical papers, and pre-release concepts before they are broadly commercialized
Professional Services experience. You’re familiar with the landscape of a professional services firm and interested in engaging with the unique value proposition of products associated with a diverse range of services, from advising and consulting to tax and public accounting."". Programming experience. You’re experienced writing scalable, production-level code in Python. You’re familiar with Linux/UNIX systems. 
Machine learning experience. You’re proficient in machine learning packages, such as Tensorflow and Pytorch, and have proven expertise in designing/developing AI/ML models. You understand the mechanics of supporting ML solutions in a production environment and can help develop/maintain tests that validate functionality and evaluate model performance. 
GenAI Experience. Experience designing and implementing AI agents using large language models (LLMs), including prompt engineering, tool use, memory, and multi-agent orchestration patterns. Proficiency with modern AI/ML frameworks, tools, and agent platforms (e.g. MCP, A2A, Microsoft Foundry, OpenAI Agent SDK, Semantic Kernel, LangChain, LlamaIndex, Microsoft Copilot Studio, or equivalent). Knowledge of retrieval-augmented generation (RAG), vector databases, embeddings, and techniques for grounding model outputs in enterprise data. 
Software Experience. You’re familiar with the software development lifecycle, and ideally tenets of MLOps. You have exposure to CI/CD frameworks and tools like Docker and Git. You’re experienced deploying code in production environments. 
AI-Assisted Software Engineering: Demonstrated ability to embrace and advocate for AI-assisted software engineering practices, including the effective use of coding assistants (e.g. Claude Code), automated testing, and design-time AI tools to accelerate solution design, improve quality, and enhance developer productivity. 
Communication. Excellent communication skills, capable of effectively documenting and summarizing technical details for non-technical stakeholders. 
Agile experience. You’re experienced attending Scrum or Kanban meetings; you favor incremental, iterative improvements through regular releases, testing, and monitoring. 
","AI Agent Experience. Familiarity with evaluation, monitoring, and observability of AI agents, including guardrails, hallucination mitigation, and human-in-the-loop designs. Ability to translate business requirements into agent behaviors, decision logic, and measurable performance outcomes. Proven ability to design end-to-end AI architectures that integrate agents with enterprise systems (ERP, CRM, data platforms, APIs) using scalable, secure integration patterns. 
Cloud Experience: Experience designing and deploying AI/ML solutions on major cloud platforms (AWS, Azure, and/or GCP), including the use of managed AI services, cloud-native integration patterns, scalable data architectures, and secure, enterprise-grade deployments. 
Knowledge sharing. You enjoy sharing what you learn, whether by offering cross-training opportunities, giving internal team “lightning talks,” or by writing detailed comments on tickets when you close them. 
Curiosity about AI and machine learning. You want to stay fresh in AI and machine learning. You demonstrate curiosity and continuous learning mindset in Generative AI and applied machine learning, with an interest in staying current on emerging models, architectures, and techniques, including engaging with original research, technical papers, and pre-release concepts before they are broadly commercialized
Professional Services experience. You’re familiar with the landscape of a professional services firm and interested in engaging with the unique value proposition of products associated with a diverse range of services, from advising and consulting to tax and public accounting.","Programming experience. You’re experienced writing scalable, production-level code in Python. You’re familiar with Linux/UNIX systems. 
Machine learning experience. You’re proficient in machine learning packages, such as Tensorflow and Pytorch, and have proven expertise in designing/developing AI/ML models. You understand the mechanics of supporting ML solutions in a production environment and can help develop/maintain tests that validate functionality and evaluate model performance. 
GenAI Experience. Experience designing and implementing AI agents using large language models (LLMs), including prompt engineering, tool use, memory, and multi-agent orchestration patterns. Proficiency with modern AI/ML frameworks, tools, and agent platforms (e.g. MCP, A2A, Microsoft Foundry, OpenAI Agent SDK, Semantic Kernel, LangChain, LlamaIndex, Microsoft Copilot Studio, or equivalent). Knowledge of retrieval-augmented generation (RAG), vector databases, embeddings, and techniques for grounding model outputs in enterprise data. 
Software Experience. You’re familiar with the software development lifecycle, and ideally tenets of MLOps. You have exposure to CI/CD frameworks and tools like Docker and Git. You’re experienced deploying code in production environments. 
AI-Assisted Software Engineering: Demonstrated ability to embrace and advocate for AI-assisted software engineering practices, including the effective use of coding assistants (e.g. Claude Code), automated testing, and design-time AI tools to accelerate solution design, improve quality, and enhance developer productivity. 
Communication. Excellent communication skills, capable of effectively documenting and summarizing technical details for non-technical stakeholders. 
Agile experience. You’re experienced attending Scrum or Kanban meetings; you favor incremental, iterative improvements through regular releases, testing, and monitoring. 
",$126500-$299500
24,Ryan Dobbelaere,,LinkedIn,"Technology, Data & Analytics",Full Time,LPL Financial,"Austin, Texas",hybrid,1/31/2026,https://www.linkedin.com/jobs/view/4367611228/,"The Data & Analytics team is looking for candidates who will collaborate with Business Product Team, other Agile/Development teams, Enterprise Architecture and with various LPL Operations Business Units to design, develop, test, and maintain the various Bot-Apps, UI-Apps & Automation platforms and their integration with other systems. You will maintain, troubleshoot, optimize and enhance existing systems, while communicating with technical and non-technical groups regularly as part of product/project support.
If you are eager to learn, thrive in collaborative settings, and are excited by the prospect of working with the latest technology, we want to hear from you!
This position would like the ideal candidate to be local to the Fort Mill and Austin offices functioning off a hybrid schedule at the manager’s discretion.",bachelor's degree or higher,,"Co-Design, develop, test, tune and implement n-tiered Cloud-hosted Bot-Apps & UI-apps
Collaborate with Business Product Team, other Agile/Development teams, Enterprise Architecture and with various LPL Operations Business Units to design, develop, test, and maintain the various Bot-Apps, UI-Apps & Automation platforms and their integration with other systems
Assess opportunities for application and process improvements and prepare documentation outlining platform road map
Maintain, troubleshoot, optimize and enhance existing systems
Work collaboratively with QA, DevOps, Release Management teams to adopt CI/CD toolchain and develop automation
Communicate with technical and non-technical groups regularly as part of product/project support
Design and develop core services and components with expertise in service-oriented architecture","Bachelor's Degree or advanced degree in Computer Science, Data Science, or related field required
Classroom experience directly related to your preferred role
Experiences such as an internship, hackathon, research project or related experience","Bachelor's Degree or advanced degree in Computer Science, Data Science, or related field required
Classroom experience directly related to your preferred role
Experiences such as an internship, hackathon, research project or related experience","Demonstrated time management skills
Ability to work independently and collaborate with teams",$40.87-$45.18/hour
25,Ryan Dobbelaere,,LinkedIn,Software Engineer Data/AI/Intelligent Systems I,Full-Time,Cisco,"Austin, Texas",hybrid,2/11/2026,https://www.linkedin.com/jobs/view/4336565505/?trackingId=XOJzJlAvis2NwsBte20osg%3D%3D&refId=u6XkH55ifH2KegXszdgoLQ%3D%3D&eBP=CwEAAAGcXdppCVt2WJf5rCSfwFnmpQ8Zz0hW5hocpSB1tKntT3vVmdrF8_JzHMpG6tVJS92jiOvIJR-DGrC9H49pvF7eJf5qaXvOiKE7MMYhnQ1tduDP-_ZzbTgt7i_fGxcWTXC2amlrYfnQpHAL9_6fPY7sAz1PMxpVUwzT9eyemtZHjm2Q16-b1t1Rz3H-9thFKe8NwjRCuaaKC60s_V8q_OrpEA4FKCktuAckm_5xtvnOCJTGOE7wJaxkNQPrVhLmif9wDxfrp476bYREaY1c4hRT1SNTvSbwWGpm0yzlcIkEQ4xKO6IGtakLloVc19fQvyd-DWpWi3dE465K0EcKH2wiBHZbzZKlZ04yi3WYq-J4J9SA8BKL8v9TZe-eiioPL3rjDO8NEkxl4XoeFXCJP0mNWfEiB9iMMimRmE5H1usPNHaeDK5GiNI9DUIqVNnzifhLLD0MDwbFa7J_KBjuUf2PCZSRkgI_Mi3GljeOEB9Zd83xCj1B0W0IY1rWGGUXnYjDwnT7GlEUqR-_bZkI5lPsvnlOMLbq&alternateChannel=search&isJobSearch=false,"Our dedicated team members are building the future of Cisco’s AI-driven platforms and data infrastructure, supporting innovation across the globe. You will join teams focused on developing advanced data pipelines, machine learning infrastructure, and analytics platforms within business groups such as S&TO, Supply Chain, and Infrastructure Engineering. As part of this collaborative environment, you will contribute to the growth of emerging technologies in data and intelligent systems. Explore the opportunities at the intersection of data engineering and AI, helping to transform how Cisco and its customers harness information and intelligent automation.
",bachelor’s or equivalent,0-3,"You are a passionate software engineer with expertise in developing scalable data pipelines, designing robust analytics platforms, and building infrastructure to support machine learning initiatives. Your strong background in programming, data systems, and collaboration enables you to solve complex challenges with innovation and attention to detail. By building and maintaining key software tools and platforms, you enable Cisco’s business groups to leverage AI and data-driven insights for operational excellence and strategic growth. Your work ensures high-quality, reliable data infrastructure that supports Cisco’s leadership in intelligent, scalable technology solutions.","Minimum Qualifications

Completion within the past 3 years, or current enrollment with expected completion within 12 months, of a certification or relevant degree program (e.g., Associate’s, Apprenticeship, Boot Camp, or Certification in a specialized program + 1 year of relevant experience, High School Diploma + 2 years of relevant experience) or Bachelor’s + 0 years of relevant experience. 
Proficiency in Python, with a strong understanding of fundamental data structures. 
Hands-on experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn. 
Familiarity with distributed data processing technologies, including Apache Spark, Hadoop (MapReduce), or Apache Flink. 
Experience with containerization and orchestration tools, such as Docker and Kubernetes, for deploying data and machine learning workloads. 

Preferred Qualifications

Hands-on experience with AI/ML. 
Familiarity with major cloud platforms, such as AWS, Azure, or Google Cloud. 
Understanding of distributed systems concepts, including scalability, reliability, fault tolerance, and data consistency, as well as familiarity with distributed computing patterns (e.g., load balancing, consensus algorithms, and inter-service communication). ","Hands-on experience with AI/ML. 
Familiarity with major cloud platforms, such as AWS, Azure, or Google Cloud. 
Understanding of distributed systems concepts, including scalability, reliability, fault tolerance, and data consistency, as well as familiarity with distributed computing patterns (e.g., load balancing, consensus algorithms, and inter-service communication). ","Completion within the past 3 years, or current enrollment with expected completion within 12 months, of a certification or relevant degree program (e.g., Associate’s, Apprenticeship, Boot Camp, or Certification in a specialized program + 1 year of relevant experience, High School Diploma + 2 years of relevant experience) or Bachelor’s + 0 years of relevant experience. 
Proficiency in Python, with a strong understanding of fundamental data structures. 
Hands-on experience with machine learning frameworks such as TensorFlow, PyTorch, or scikit-learn. 
Familiarity with distributed data processing technologies, including Apache Spark, Hadoop (MapReduce), or Apache Flink. 
Experience with containerization and orchestration tools, such as Docker and Kubernetes, for deploying data and machine learning workloads. ","$92,100.00 - $136,000.00"
26,Ryan Dobbelaere,,LinkedIn,AI Engineer,Full-Time,CNSS National Security Systems,"Fort Meade, Maryland",on-site,2/11/2026,https://www.linkedin.com/jobs/view/ai-engineer-entry-to-expert-level-maryland-at-cnss-•-national-security-systems-4372267752/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,"At NSA, AI Engineering is a specialized discipline that intersects data science, software engineering, data engineering, and systems engineering, focusing specifically on the unique challenges of building, deploying, and maintaining artificial intelligence (AI) systems at scale. AI Engineers combine expertise from each of these domains to address the entire AI lifecycle, including infrastructure management, efficient model training, production deployment, performance monitoring, and continuous optimization. As an AI Engineer, you will help design and implement mission-critical AI systems that keep NSA at the cutting edge of intelligence collection, processing, and reporting. Responsibilities include: - Lead or contribute to cross-functional teams to develop and operationalize AI solutions that help solve our most challenging problems. - Apply modern engineering techniques to design, develop, deploy, and maintain end-to-end AI workflows spanning model training, inference, and performance monitoring. - Adapt and integrate diverse AI model architectures including computer vision systems, natural language processors, audio processors, large language models (LLMs), and multi-modal frameworks to address complex mission-critical challenges. - Monitor and maintain AI products through systematic identification of performance degradation and computational inefficiency and address these challenges through regular retuning and fine-tuning to ensure continued alignment with evolving mission needs and organizational goals. - Maintain knowledge of current AI research and adapt emerging techniques to intelligence applications. - Test and evaluate Al solutions against mission requirements and produce actionable recommendations.",associate's degree or bachelor's degree,1-3,"As a newly hired AI Engineer you may, depending on the skill-sets currently in demand, be assigned to a mission office, or alternatively enrolled in the three-year Data Science Development Program (DSDP) in which you will both broaden and specialize your AI Engineering skills by taking courses and touring with a variety of mission offices (each for several months). In either case you will work with NSA experts in AI Engineering, related technical domains, and specialized subject areas. You will have opportunities to participate in internal technical roundtables, and to attend technical conferences with experts from industry and academia. Please attach a copy of your resume and all transcripts (unofficial are fine) as part of your application when given the opportunity to do so to speed application processing."," Deep learning frameworks (PyTorch, TensorFlow, Jax) - Model training, fine-tuning, and optimization techniques - Computer vision, NLP, speech/audio processing, and/or multi-modal AI systems - Large language models (LLMs) and transformer architectures - Model evaluation, validation, and performance monitoring - Transfer learning and domain adaptation - Python programming and other relevant languages (C++, Java, Scala, TypeScript) - Version control (Git) and collaborative development - API design and microservices architecture - Software testing frameworks and CI/CD pipelines - Containerization (Docker, Kubernetes) - Data processing frameworks (Spark, Dask, Ray) - Feature engineering and data preprocessing - Production model deployment and serving infrastructure - Monitoring, logging, and observability tools - Cloud platforms (AWS, Azure, GCP) and/or HPC systems - Distributed computing and parallel processing - GPU optimization and resource management - Database systems (SQL and NoSQL) - Cross-function collaboration and communication - Technical documentation and presentation - Ability to translate mission requirements into technical solutions"," Deep learning frameworks (PyTorch, TensorFlow, Jax) - Model training, fine-tuning, and optimization techniques - Computer vision, NLP, speech/audio processing, and/or multi-modal AI systems - Large language models (LLMs) and transformer architectures - Model evaluation, validation, and performance monitoring - Transfer learning and domain adaptation - Python programming and other relevant languages (C++, Java, Scala, TypeScript) - Version control (Git) and collaborative development - API design and microservices architecture - Software testing frameworks and CI/CD pipelines - Containerization (Docker, Kubernetes) - Data processing frameworks (Spark, Dask, Ray) - Feature engineering and data preprocessing - Production model deployment and serving infrastructure - Monitoring, logging, and observability tools - Cloud platforms (AWS, Azure, GCP) and/or HPC systems - Distributed computing and parallel processing - GPU optimization and resource management - Database systems (SQL and NoSQL) - Cross-function collaboration and communication - Technical documentation and presentation - Ability to translate mission requirements into technical solutions",,"$87,362 - $197,200 (Entry - Expert)"
27,Ainsley Dungan,,LinkedIn,Data Engineer,Full Time,Dallas College,"Dallas, TX",on-site,2/7/2026,https://www.linkedin.com/jobs/view/4369248128,"This role will help maintain and improve data pipelines, Lakehouse tables, and quality checks that feed HR dashboards and reporting. The Data Engineer I will work with the People Analytics team, HRIS, and IT to ensure that HR data is accurate, reliable, and ready for analysis. This is a hands-on learning role ideal for someone early in their data engineering or analytics career who wants experience with cloud data platforms, HR workflows, and enterprise-scale reporting. The Data Engineer I will assist senior staff with pipeline development, data modeling, and data governance activities while gaining exposure to advanced tools such as Microsoft Fabric, Delta Lake, and Workday RaaS integrations.",bachelors,0-2,"Data Engineering & Pipeline Support, Data Modelinfg & Data Preparation, Analytics Enablement, Collaboration & Learning","0–2 years of experience in data engineering, data analytics, or related technical work (internship or project experience acceptable).
Foundational knowledge of Python or R and SQL.
Familiarity with cloud data tools (e.g., Microsoft Fabric, Databricks, Snowflake, Azure, or similar) preferred.
Understanding of basic ETL/ELT concepts, data cleaning, and data transformation.
Ability to learn REST APIs, JSON parsing, and automated ingestion patterns.
Basic understanding of data modeling concepts such as tables, joins, relational structure, and time-series data.
Familiarity with Git/GitHub or willingness to learn.
Bachelor’s degree in Computer Science, Information Systems, Data Analytics, Statistics, or related field.
Equivalent experience or technical certifications (e.g., Azure, Databricks, Python) also considered.
Exposure to HRIS or enterprise systems (e.g., Workday, PeopleSoft, SAP).
Experience with Power BI, semantic models, or dashboard development.
Coursework or project experience with Delta Lake or distributed computing.
Some knowledge of DAX, R, PySpark/SparkR, or statistical modeling.
Exposure to data governance concepts (data quality, metadata, lineage).
","0–2 years of experience in data engineering, data analytics, or related technical work (internship or project experience acceptable).
Foundational knowledge of Python or R and SQL.
Familiarity with cloud data tools (e.g., Microsoft Fabric, Databricks, Snowflake, Azure, or similar) preferred.
Understanding of basic ETL/ELT concepts, data cleaning, and data transformation.
Ability to learn REST APIs, JSON parsing, and automated ingestion patterns.
Basic understanding of data modeling concepts such as tables, joins, relational structure, and time-series data.
Familiarity with Git/GitHub or willingness to learn.
Bachelor’s degree in Computer Science, Information Systems, Data Analytics, Statistics, or related field.
Equivalent experience or technical certifications (e.g., Azure, Databricks, Python) also considered.","Exposure to HRIS or enterprise systems (e.g., Workday, PeopleSoft, SAP).
Experience with Power BI, semantic models, or dashboard development.
Coursework or project experience with Delta Lake or distributed computing.
Some knowledge of DAX, R, PySpark/SparkR, or statistical modeling.
Exposure to data governance concepts (data quality, metadata, lineage).","$66,900"
28,AInsley Dungan,,Indeed,Data Engineer,Full Time,Forman Technology Group,"Irving, TX",on-site,,https://www.indeed.com/viewjob?jk=f2d45fab761e67f9&from=shareddesktop_copy,"We are looking for a Data Engineer to help build and maintain reliable data pipelines and scalable data infrastructure. In this role, you will contribute to data integration, transformation, and data quality efforts that support analytics and reporting across the organization.

This is a hands-on role ideal for someone with a solid foundation in SQL and Python, a good understanding of ETL/ELT and data warehousing concepts, and experience working in a cloud-based environment. You will work closely with analytics, BI, and engineering teams to ensure data is accurate, accessible, and well managed.",bachelors or masters,2+,"Build and maintain data ingestion and transformation pipelines using SQL and Python
Support day-to-day operations of data lakes and data warehouses
Implement data quality checks, validation, and error handling
Monitor pipelines and scheduled jobs to ensure reliable data delivery
Optimize query and table performance
Work with structured and semi-structured data (e.g., CSV, JSON, Parquet)
Collaborate with analysts and stakeholders to understand data needs
Follow best practices for version control, testing, and documentation
Support deployments and updates to data pipelines in development and production
Participate in code reviews and team knowledge sharing","Bachelor’s or Master’s degree in Computer Science, Engineering, Data Science, or a related field (or equivalent practical experience)
2+ years of experience in data engineering, data analytics, or a related technical role
Strong working knowledge of SQL for querying and transformation
Hands-on experience with Python for data processing
Understanding of ETL/ELT concepts and data pipeline workflows
Experience with relational databases; familiarity with NoSQL is a plus
Familiarity with at least one cloud platform (AWS, Azure, or GCP)
Basic knowledge of data warehousing and analytical data modeling
Exposure to tools such as Spark or Kafka is a plus
Experience with modern data warehouses (e.g., Snowflake, BigQuery, Redshift) is a plus
Familiarity with orchestration tools (e.g., Airflow, ADF, Glue) is helpful
Experience using Git or similar version control systems
Strong problem-solving and communication skills","Bachelor’s or Master’s degree in Computer Science, Engineering, Data Science, or a related field (or equivalent practical experience)
2+ years of experience in data engineering, data analytics, or a related technical role
Strong working knowledge of SQL for querying and transformation
Hands-on experience with Python for data processing
Understanding of ETL/ELT concepts and data pipeline workflows
Experience with relational databases; familiarity with NoSQL is a plus
Familiarity with at least one cloud platform (AWS, Azure, or GCP)
Basic knowledge of data warehousing and analytical data modeling
Exposure to tools such as Spark or Kafka is a plus
Experience with modern data warehouses (e.g., Snowflake, BigQuery, Redshift) is a plus
Familiarity with orchestration tools (e.g., Airflow, ADF, Glue) is helpful
Experience using Git or similar version control systems
Strong problem-solving and communication skills",-,"$98,495 - $135,478"
29,AInsley Dungan,,LinkedIn,Engineer III - AI,Full Time,Frost,"San Antonio, TX",on-site,2/7/2026,https://www.linkedin.com/jobs/view/4352596510,"As an Engineer III - AI , you believe in using technology to do the right thing. You thrive on designing thoughtful, intelligent workflows and are excited by the future of AI. In this role, you will lead technical efforts on AI reliability, bias mitigation, and adrift detection. You believe in effective communication and will have the opportunity to address potential problems with solutions to complex issues. More than that, this role is about constant improvement and doing so with our signature all-win approach in mind.",bachelors,4+,"Design and architect intelligent systems and workflows that leverage agentic behavior and LLM decision-making capabilities
Drive design sessions for agent loop architectures, tool orchestration, and task planning
Lead technical efforts on AI reliability, bias mitigation, and drift detection
Collaborate with product and design leaders to define outcomes and performance metrics
Act as a system designer and workflow architect, not just a code implementer
Evaluate agent behavior using AI principles (fairness, reliability, explainability, safety)
Optimize performance of agentic systems with caching, throttling, and fallback strategies
Mentor engineers in best practices for LLM prompting, agent decomposition, and tool design
Always take action using Integrity, Caring, and Excellence to achieve all-win outcomes","Bachelor’s in Computer Science, Data Science, or related field
4+ years of experience with enterprise-grade AI/ML systems
Deep understanding of event-driven design, API orchestration, prompt engineering, tool orchestration, planner/verifier roles, and system modularity
Strong skills in prompt engineering, memory and context handling, and agent loop optimization
Experience leading teams in applying LLMs and autonomous agents to real-world problems
Strong experience with Python, FastAPI, LangChain, vector databases, and agent loop architectures
Excellent written and verbal communication skills
Proficient in Microsoft computer applications","Bachelor’s in Computer Science, Data Science, or related field
4+ years of experience with enterprise-grade AI/ML systems
Deep understanding of event-driven design, API orchestration, prompt engineering, tool orchestration, planner/verifier roles, and system modularity
Strong skills in prompt engineering, memory and context handling, and agent loop optimization
Experience leading teams in applying LLMs and autonomous agents to real-world problems
Strong experience with Python, FastAPI, LangChain, vector databases, and agent loop architectures
Excellent written and verbal communication skills
Proficient in Microsoft computer applications","Experience creating reusable agent libraries or co-pilots
Open-source contributions to AI frameworks or tooling
Experience with tools like LangGraph, CrewAI, or Autogen",not specified
30,Sergio Esteves,,USAJOBS,Data Scientist,Full Time,US DEPARTMENT OF JUSTICE,"Washington, DC",on-site,2/5/26,USAJOBS - Job Announcement,"This position serves as a Data Scientist in the Justice Management Division, Budget Staff, Budget Operations Group (BOG) located in Washington, DC. The purpose of this position is to serve as the JMD Budget Staff authority in the identification, collection, analysis, measurement, documentation, reporting, and presentation of reliable budgetary and financial data for the purpose of improving the delivery of data-driven policy and resource recommendations and decisions",bachelors,1+,"Design, plan, and modify existing hardware, software, and data architecture to support JMD Budget Staff mission.
Conduct strategic operational level assessments to determine technical competencies.
Identify ways to improve data reliability, efficiency, and quality for JMD Budget Staff mission, goals, and future planning.
Identify reliable budgetary and financial data for improving the delivery of data-driven policies and resource recommendations.","You must be a United States Citizen or National.
You will be required to complete a pre-employment security investigation and background check which includes a drug screening.
You may be required to complete a probationary or trial period.
Selective Service registration is required for males born on, or after, December 31st, 1959. Those not registered should have an approved exemption on file.
You must meet all eligibility requirements by the closing date of this announcement and continue to meet these requirements throughout the hiring process. Offers can be rescinded if requirements are not met.
Additional selections may be made from this announcement.
Qualifications
To qualify for the position of Data Scientist, at GS-1560-14 you must meet the basic qualification requirements listed below.

BASIC QUALIFICATIONS:

A. Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position.

OR

B. Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience.

Specialized Experience: For the GS-14, you must have one year of specialized experience at the GS-13 grade level or equivalent pay band in the Federal Service, which includes: Developing policies essential to the organization's mission; Applying mathematic, statistical, or scientific analysis to analyze data; AND Applying analytical or evaluative techniques to identify or resolve issues or problems

You MUST meet all qualification requirements, including time-in-grade, by the 02/18/2026 of this announcement.

Your resume must support your responses to the application questionnaire and the qualification requirements. Failure to do so may result in an ineligible rating.See the Required Documents section for important notes about what must be included in your resume.

Education
If you are relying on your education to meet qualification requirements, please see the statements below.

Education must be reviewed and certified by an accrediting institution recognized by the U.S. Department of Education, in order for it to be creditable towards your qualifications. Therefore, provide only the attendance and/or degrees from accredited institution.","You must be a United States Citizen or National.
You will be required to complete a pre-employment security investigation and background check which includes a drug screening.
You may be required to complete a probationary or trial period.
Selective Service registration is required for males born on, or after, December 31st, 1959. Those not registered should have an approved exemption on file.
You must meet all eligibility requirements by the closing date of this announcement and continue to meet these requirements throughout the hiring process. Offers can be rescinded if requirements are not met.
Additional selections may be made from this announcement.
Qualifications
To qualify for the position of Data Scientist, at GS-1560-14 you must meet the basic qualification requirements listed below.

BASIC QUALIFICATIONS:

A. Degree: Mathematics, statistics, computer science, data science or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position.

OR

B. Combination of education and experience: Courses equivalent to a major field of study (30 semester hours) as shown in paragraph A above, plus additional education or appropriate experience.

Specialized Experience: For the GS-14, you must have one year of specialized experience at the GS-13 grade level or equivalent pay band in the Federal Service, which includes: Developing policies essential to the organization's mission; Applying mathematic, statistical, or scientific analysis to analyze data; AND Applying analytical or evaluative techniques to identify or resolve issues or problems

You MUST meet all qualification requirements, including time-in-grade, by the 02/18/2026 of this announcement.

Your resume must support your responses to the application questionnaire and the qualification requirements. Failure to do so may result in an ineligible rating.See the Required Documents section for important notes about what must be included in your resume.

Education
If you are relying on your education to meet qualification requirements, please see the statements below.

Education must be reviewed and certified by an accrediting institution recognized by the U.S. Department of Education, in order for it to be creditable towards your qualifications. Therefore, provide only the attendance and/or degrees from accredited institution.",,"143,913 to - $187,093"
31,Sergio Esteves,,Dice,Data Architect,Full Time,Navy Federal Credit Union,"Vienna, VA",on-site,2/10/26,"Data Architect - Navy Federal Credit Union - Hybrid in Vienna, VA, US | Dice.com","The Data Architect role supports the Enterprise Data & Information Management (EDIM) organization by architecting, designing, and guiding data strategies and frameworks that enable all Enterprise Data & Analytics (EDAS) initiatives. In this role, you will develop cloud data strategies and design data models, ETL/ELT pipelines, and data lake/warehouse solutions. Key responsibilities include creating and optimizing conceptual, logical and physical data models, implementing data migration strategies, and ensuring the secure and efficient storage of company data. You will also develop and maintain architectural solutions that support scalable and secure data ingestion in Azure cloud environments, as well as the consumption of data products for operational analytics and AI/GenAI-enabled solutions. Your expertise in cloud data platforms will help shape the organization's data strategy, drive innovation, and deliver scalable, high-performing analytics, machine learning, and AI solutions.",bachelors,5-7,"Translate business requirements into scalable, enterprise-grade technical designs.
Provide technical leadership and guidance to ensure adherence to best practices, architectural standards, and security protocols.
Lead the design and architecture of Azure-based data solutions that align with organizational data capability needs.
Define and optimize data integration patterns (batch, streaming, API-based) for performance and cost.
Lead architecture discussions, conduct design reviews, and mentor technical teams.
Create and maintain end-to-end data architecture blueprints, covering conceptual, logical, and physical layers.
Develop and maintain logical and physical data models that support scalable, secure, and high-quality data solutions in Azure, partnering with data engineers, analysts and business stakeholders to ensure optimal structures for analytics, reporting, operations, and AI.
Establish and enforce data modeling standards, metadata and lineage practices, and master/reference data management principles.
Provide thought leadership in designing and optimizing an Analytical Semantic Layer (ASL).
Develop architecture strategies grounded in modern data architecture principles including Data Products, Data Mesh, Data Fabric, and Domain-Driven Design.
Build frameworks to monitor data quality and resolve integrity issues.
Collaborate with cross-functional teams-including data scientists, data engineers, application developers, and business partners-to translate business needs into data architecture blueprints, design patterns, and frameworks.
Evaluate existing systems and compute environments to identify opportunities for performance, reliability, and cost optimization.
Stay current on industry trends, emerging technologies, and advancements in cloud data platforms to drive continuous innovation.
Collaborate with internal and external partners on discovery and fit-gap analyses to recommend appropriate tools, platforms, and services for data analytics, ML, and AI solutions.
Mentor team members and promote a culture of continuous learning and development.
Develop and maintain the enterprise data strategy and multi-year roadmap.
Identify opportunities for optimization, automation, and innovation across data platforms and processes.","Qualifications
5 to 7 years of data architecture and design experience, cloud technologies and cloud data solutions experience.
Bachelor's degree in computer science, information technology, or a related field.
Extensive experience as a Data Architect, with a strong focus on Enterprise Data Lake (Azure, AWS etc.), Data Warehouse (Azure Synapse, Snowflake etc.), and Data Hubs (Azure Cosmos DB, MongoDB etc.).
Experience in data modeling (Erwin, Hackolade, DB Artisan or similar), data quality solution (Ataccama, or similar), data governance solution (Unity Catalog, Alation, Azure Purview or similar).
In-depth knowledge and hands-on experience in designing, implementing, and managing cloud-based data analytics, ML. AI solutions using Azure.
Extensive experience in enabling and shaping up data architecture of complex data ecosystems to adopt modern data architecture paradigms like Data Products, Data Mesh, Data Fabric and Domain Driven Design.
Strong experience in data/information modelling (canonical, conceptual and logical data models and data flow charts) at enterprise level, modelling governance and good exposure to data modelling tools and best practices.
A highly capable communicator, both written and verbal, adept in engaging, collaborating, and influencing people across different business units and at all levels of financial service organizations.
Strong knowledge and experience in designing and architecting cloud-based data analytics, ML and AI solutions.
Experience in cloud data architecture and services, including Azure Data Lake, Synapse Analytics, Databricks, Azure SQL Data Warehouse, Cosmos DB, Azure Blob Storage, Azure Data Factory, and Azure Functions.
Successful in driving architectural change that transforms and optimizes complex businesses preferably in financial industry.
Proficiency in SQL, NoSQL, structured and unstructured data.
Well experienced with Relational Data Modeling (3NF and Dimensional Modeling) techniques; familiarity with NoSQL modeling preferred.
Extensive experience with Data Architecture, Database Design including Data Quality and Master Data Management (MDM) tools, processes, and governance.
Experience with ETL and ELT techniques and deep understanding of information architecture including data quality, data governance, data lineage, metadata management and data security.
Strong understanding of big data technologies, data warehousing concepts, and data integration patterns.
Solid understanding of DevOps practices, CI/CD pipelines, and infrastructure-as-code concepts.
Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions.
Strong communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams and communicate complex concepts to technical and non-technical stakeholders.


Desired Qualifications
Master's degree in computer science, information technology, or a related field.
Experience with Lakehouse architecture and Unity Catalog-based governance.
Knowledge of ML/AI data preparation and feature store design.
Experience working in highly regulated industries (finance, healthcare, retail, etc.).
Strong communication, leadership, and architectural documentation skills.
Experience with data analytics and use of data analytics tools like Power BI and Tableau.
Experience as a Sr data architect, with a strong focus on Azure Cloud data platform.","5 to 7 years of data architecture and design experience, cloud technologies and cloud data solutions experience.
Bachelor's degree in computer science, information technology, or a related field.
Extensive experience as a Data Architect, with a strong focus on Enterprise Data Lake (Azure, AWS etc.), Data Warehouse (Azure Synapse, Snowflake etc.), and Data Hubs (Azure Cosmos DB, MongoDB etc.).
Experience in data modeling (Erwin, Hackolade, DB Artisan or similar), data quality solution (Ataccama, or similar), data governance solution (Unity Catalog, Alation, Azure Purview or similar).
In-depth knowledge and hands-on experience in designing, implementing, and managing cloud-based data analytics, ML. AI solutions using Azure.
Extensive experience in enabling and shaping up data architecture of complex data ecosystems to adopt modern data architecture paradigms like Data Products, Data Mesh, Data Fabric and Domain Driven Design.
Strong experience in data/information modelling (canonical, conceptual and logical data models and data flow charts) at enterprise level, modelling governance and good exposure to data modelling tools and best practices.
A highly capable communicator, both written and verbal, adept in engaging, collaborating, and influencing people across different business units and at all levels of financial service organizations.
Strong knowledge and experience in designing and architecting cloud-based data analytics, ML and AI solutions.
Experience in cloud data architecture and services, including Azure Data Lake, Synapse Analytics, Databricks, Azure SQL Data Warehouse, Cosmos DB, Azure Blob Storage, Azure Data Factory, and Azure Functions.
Successful in driving architectural change that transforms and optimizes complex businesses preferably in financial industry.
Proficiency in SQL, NoSQL, structured and unstructured data.
Well experienced with Relational Data Modeling (3NF and Dimensional Modeling) techniques; familiarity with NoSQL modeling preferred.
Extensive experience with Data Architecture, Database Design including Data Quality and Master Data Management (MDM) tools, processes, and governance.
Experience with ETL and ELT techniques and deep understanding of information architecture including data quality, data governance, data lineage, metadata management and data security.
Strong understanding of big data technologies, data warehousing concepts, and data integration patterns.
Solid understanding of DevOps practices, CI/CD pipelines, and infrastructure-as-code concepts.
Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions.
Strong communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams and communicate complex concepts to technical and non-technical stakeholders.","Master's degree in computer science, information technology, or a related field.
Experience with Lakehouse architecture and Unity Catalog-based governance.
Knowledge of ML/AI data preparation and feature store design.
Experience working in highly regulated industries (finance, healthcare, retail, etc.).
Strong communication, leadership, and architectural documentation skills.
Experience with data analytics and use of data analytics tools like Power BI and Tableau.
Experience as a Sr data architect, with a strong focus on Azure Cloud data platform.","$130,500-$179,500"
32,Sergio Esteves,,Dice,Data System Engineer,Full Time,The Atlantic Group,"Greenwich, CT",on-site,1/23/26,"Data System Engineer - The Atlantic Group - Greenwich, CT, US | Dice.com","The Systems Integration & Data Engineer maintains and improves integrations, automation routines, and data pipelines that connects the CTRM to downstream systems and reporting. This role designs integration patterns, builds ETL pipelines, supports BI reporting distributions, and ensures data outputs (PnL/exposure) match reality.",,N/A (Not explicit),"Integration and Automation:

Design blueprints for how integrations interact, including processes, gates (authentication), and communication patterns across systems.
Maintain all in-house connections, vessel tracking, price feeds, document generation tools, and automation utilities.
Build and maintain scheduled jobs, ETL routines, and VM scripts; monitor and debug issues.
Data Engineering and Warehouse Management:

Build and maintain the data warehouse and data models supporting reporting and reconciliation.
Manage ETL pipelines between data environments and reporting environments.
Implement validation logic and reconciliation checks to ensure data quality and consistency.
Reporting & Distribution:

Manage reporting distributions and delivery schedules.
Support BI development and stakeholder communication for reporting outputs (PowerBI/Tableau).
Ensure PnL and exposure reports match operational reality (sense-checking data).","Required Skills and Experience:

Fluent in programming languages (Python) with strong scripting skills.
Strong SQL, data modeling, and ETL pipeline experience.
API architecture, integration patterns, authentication methods, and system design knowledge.
BI tools familiarity (PowerBI/Tableau) and reporting distribution experience.
Strong monitoring, debugging, and troubleshooting skills.
PnL/exposure and trading/finance data understanding for validation and reconciliation.","Required Skills and Experience:

Fluent in programming languages (Python) with strong scripting skills.
Strong SQL, data modeling, and ETL pipeline experience.
API architecture, integration patterns, authentication methods, and system design knowledge.
BI tools familiarity (PowerBI/Tableau) and reporting distribution experience.
Strong monitoring, debugging, and troubleshooting skills.
PnL/exposure and trading/finance data understanding for validation and reconciliation.",,"$110,000 - $140,000"
33,Manu Jampana,,Linkdeln,"AI/ML Engineer, Cloud and Developer Infrastructure Intern",Full Time,GM,"Sunnyvale, CA",on-site,2/14/26,AI/ML Engineering Intern,"Job Description

GM does not provide immigration-related sponsorship for this role. Do not apply for this role if you will need GM immigration sponsorship now or in the future. This includes direct company sponsorship, entry of GM as the immigration employer of record on a government form, and any work authorization requiring a written submission or other immigration support from the company (e.g., H1-B, OPT, STEM OPT, CPT, TN, J-1, etc.)

Work Arrangement:
Hybrid: This internship is categorized as hybrid. The selected intern is expected to report to the office up to three times per week or as determined by the team. This internship may be considered remote for an individual in the Seattle area.

Locations: 
Mountain View, California
Sunnyvale, California
Austin, Texas
Detroit, Michigan
Warren, Michigan
Milford, Michigan

About the Team
The AI Cloud and Developer Infrastructure organization is responsible for delivering and maintaining the tools and services engineers here at GM use every day to do their best work and drive our cars forward. Tools and services we work on enhancing the entire development process of engineers at GM — how/where code is checked out, modified, compiled, tested, merged, and eventually deployed. Our goal is to ensure our AV engineers and others here have world class tools and a seamless development experience so that they can focus on the problems that matter most in their domain.

About The Role: 
We are looking for an intern with strong engineering fundamentals and who is passionate about developer productivity. As a member of this team, we are looking for someone who cares deeply about the quality of software and products the team owns.

The way this engineer will deliver impact may vary depending on the situation but they will be expected to partner effectively with other engineers, take feedback and guidance from more experienced team members, and deliver effective and reliable solutions to tasks at hand.",bachelor's,Not specified,"What You’ll Do:

Ship improvements to our AV development toolchains and services which have a measurable and direct impact on engineering productivity and our core company metrics.

Leverage the guidance and experience of more senior engineers on the team to identify engineering pain points and implement solutions that are reliable, scalable, and maintainable.

Effectively communicate the status of their work.

Follow software engineering best practices within your team.

Contribute to the engineering culture on the team.

Demonstrate high levels of accountability.

Type of tools/functionality this position works on.

Golang, Python, gRPC, SSH, Kubernetes, Docker, Linux, Buildkite, GCP, OpenTelemetry.","Required Qualifications:

Currently enrolled in a full-time, degree-seeking program and in the process of obtaining a Bachelor's degree in Computer Science or a related field.

An academic understanding of highly scalable distributed systems.

Experience writing Go, Python, or other languages commonly used for production services.

Understanding of Unix/Linux, SSH, and networking fundamentals.

Able to work full-time, 40 hours per week.


Preferred Qualifications: 

Attention to detail, and a desire to improve processes and systems around you.

Experience with GCP.

Experience with Docker and Kubernetes.

Passion for self-driving technology and its potential impact on the world.

Intent to return to degree-program after the completion of the internship.

Graduating with a Bachelor's Degree between December 2026 and June 2027.","Required Qualifications:

Currently enrolled in a full-time, degree-seeking program and in the process of obtaining a Bachelor's degree in Computer Science or a related field.

An academic understanding of highly scalable distributed systems.

Experience writing Go, Python, or other languages commonly used for production services.

Understanding of Unix/Linux, SSH, and networking fundamentals.

Able to work full-time, 40 hours per week.","Preferred Qualifications: 

Attention to detail, and a desire to improve processes and systems around you.

Experience with GCP.

Experience with Docker and Kubernetes.

Passion for self-driving technology and its potential impact on the world.

Intent to return to degree-program after the completion of the internship.

Graduating with a Bachelor's Degree between December 2026 and June 2027.","$7,300 - $8,600 per month"
34,Manu Jampana,,LinkedIn,Data Mining - Intern,Full Time,RWE,"Austin, Texas",on-site,2/12/26,Data Mining Intern ,"This role will be focused on data mining for Turbines within the Operations Procurement department of RWECE. The data as it pertains to part numbers and category codes need to be improved significantly for reporting purposes.

 

This role will support miing the data of existing parts of the assets in the United States from the end of construction at a project site to repowering and decommissioning with effort on Operational success and needed repair at existing projects. The role also covers support for the category managers to improve their respective category Strateies.

 

As RWECE is growing in terms of managed assets as the existing fleet ages, the intern supports the growing asset base and part numbers and growing maintenance needs which often come with age.",bachelor's,1+,"Role Responsibilities:

Collect all the part number data from SAP
Perform analysis based on parts to classify them
Evaluate the criticality of parts along with engineering
Understand and document any failure modes in terms
Support category managers to perform reports and categorize the parts
Perform analysis and define pilots
Evaluation of quality of work done by contractors
Support development of new parts and structrure the process of adding new parts
Support categortization of parts for Solar and Wind
Adhere to the Company’s values and behaviors as aspired to by RWECE
Additionally: Perform all other duties assigned as may be required from time to time","Job Requirements and Experiences:

Enrolled in an accredited US university program, pursuing a degree in electrical, mechanical or computer science engineering 
Experience within the wind energy sector is preferred
Working knowledge of mechanical and electrical systems and components
Knowledge of data analytics, reduction and reporting
Strong interpersonal skills, with ability to manage customer relationships
Demonstrated desire to learn about the Company and the renewables space
Excellent proficiency with Microsoft Office (Excel, Word, PowerPoint, Outlook) and Teams
Strong leadership and communication, and ability to meet deadlines
Strong organization skills and ability to coordinate multiple tasks and deliverables
Ability to multi-task, while working independently and as part of a team
Motivated self-starter, goal-oriented, and strong problem-solving abilities
Proven ability to empathize, build relationships, and effectively communicate with people from a diverse set of backgrounds
Responds well to direction, is easy to challenge and develop, and is coachable
Is detail-oriented, has strong business acumen, and a sound understanding of business concepts
This position is an office-based role with some travel and visits to other RWECE office and field locations
Must be able to sit, walk, or stand for long durations of time","Job Requirements and Experiences:

Enrolled in an accredited US university program, pursuing a degree in electrical, mechanical or computer science engineering 
Experience within the wind energy sector is preferred
Working knowledge of mechanical and electrical systems and components
Knowledge of data analytics, reduction and reporting
Strong interpersonal skills, with ability to manage customer relationships
Demonstrated desire to learn about the Company and the renewables space
Excellent proficiency with Microsoft Office (Excel, Word, PowerPoint, Outlook) and Teams
Strong leadership and communication, and ability to meet deadlines
Strong organization skills and ability to coordinate multiple tasks and deliverables
Ability to multi-task, while working independently and as part of a team
Motivated self-starter, goal-oriented, and strong problem-solving abilities
Proven ability to empathize, build relationships, and effectively communicate with people from a diverse set of backgrounds
Responds well to direction, is easy to challenge and develop, and is coachable
Is detail-oriented, has strong business acumen, and a sound understanding of business concepts
This position is an office-based role with some travel and visits to other RWECE office and field locations
Must be able to sit, walk, or stand for long durations of time",Not Specified,Not Specified
35,Manu Jampana,,LinkedIn,Software Engineer Intern,Full TIme,Applied Materials,"Austin, Texas",on-site,2/11/26,Sofware Engineer Intern,"You’ll benefit from a supportive work culture that encourages you to learn, develop, and grow your career as you take on challenges and drive innovative solutions for our customers. We empower our team to push the boundaries of what is possible—while learning every day in a supportive leading global company. Visit our Careers website to learn more. 

At Applied Materials, we care about the health and wellbeing of our employees. We’re committed to providing programs and support that encourage personal and professional growth and care for you at work, at home, or wherever you may go. Learn more about our benefits. 

TEAM OVERVIEW:

The Global Repair Factory Operations (GRFO) Engineering Team serves as the bridge between engineering innovation and sustained manufacturing. The team pilots high complexity, high IP products, creating the documentation, fixtures, tooling, BOM control, and training required to scale internal repair and new manufacturing across the global network. By solving challenges and enabling smooth transition and support, we help turn advanced technology into repeatable, production ready solutions.
KEY RESPONSIBILITIES:

Build and support software tools, scripts, and automation that improve pilot build/repair workflows and reduce cycle time through better data, traceability, and usability.
Partner with EE/ME/Test to integrate software with hardware and fixtures, enabling consistent operation and clearer troubleshooting paths.
Create clear documentation and training artifacts so software solutions can be sustained and scaled.
Contribute to disciplined release practices and configuration control in a production-adjacent environment.",bachelor's,Not Specified,"Build and support software tools, scripts, and automation that improve pilot build/repair workflows and reduce cycle time through better data, traceability, and usability.
Partner with EE/ME/Test to integrate software with hardware and fixtures, enabling consistent operation and clearer troubleshooting paths.
Create clear documentation and training artifacts so software solutions can be sustained and scaled.
Contribute to disciplined release practices and configuration control in a production-adjacent environment.","Programming fundamentals (e.g., Python/C#/C++/Java) and strong debugging skills.
Familiarity with test/automation concepts and working alongside hardware teams.
Comfort producing readable, scalable documentation and training content for end users.","BS in Computer Science, Software Engineering, or related.
Preferred GPA of 3.0 or above
Comfortable working hands-on with hardware and collaborating in a fast-moving environment.
Applications will be reviewed on a rolling basis. Please apply by March 6, 2026. Note: This position may close early based on application volume or candidate selection. ","Experience with automation, robotic arms, end-of-arm tooling, and system integration.
Knowledge of robotics programming languages (e.g., Python, ROS)
Familiarity with PLCs, motion control, and industrial communication protocols.
Exposure to machine vision, AI/ML for optical inspection, and simulation tools.",Not Specified
36,Nicolas Reyes,,LinkedIn,Data Analyst,Full time,General Index,"Houston, TX",on-site,2/11/26,https://www.linkedin.com/jobs/view/4371443328/?alternateChannel=search&trackingId=vhBUp6swQsimuIXqyg2cxQ%3D%3D,"Support data workflows, data cleaning, QA, pipeline work (summary)",bachelor's,Entry Level,"Support data workflows, data cleaning, QA, pipeline work (summary)","Python experience, Excel proficiency, statistical ability, attention to detail","Python, Excel, Bachelor’s degree",Interest/experience in commodities data (preferred but not required),Not Specified
37,Nicolas Reyes,,LinkedIn, Data Analyst,Full Time,ADP,"Houston, TX",hybrid,2/1/26,https://www.linkedin.com/jobs/view/4364400254/?alternateChannel=search&eBP=CwEAAAGcXsdWI6WMfobDnNrFUV-qXJflhIZ05NK9zXCzVv5QdnV8zp2__q1S0j1ukUNkciS8D0W6FXmcbcmSny2mjhPVi9wHGk_gaKh_be_LI1NsJv72F_FwrQ21cShZO9BmoKFV74FYbFt4_qme3Wzak4KvIiSRIoRK3g3zefm3CMTvmkMqqJRK4uB8yD8E-NpRulWp5YaM9Jh3d0dzr4p_NwXN7NKKPO57RXdcQsdz-tRBhPuGi1_iFhOo-FrA9pKB4SZGqTBIKT-yJNdvY6raDtrO3_9_L58UrLHMPrKseu-Q4KphZVtBNWOYOwUA2yCN8WJa8TO8LODBEvCR_oHzkSkohrjaYpai4gCHPkRtRM6F9-eauiWooemnr-lEdSuKd4blaok7O5FVLyKKeLt6Y65X4bwwj2ACUrNO_JNK_njo57L9f2erd7MsCypwTYgPajjRvqU6w21tVveplQjOm-BJuXfyiMC2m3ZLJNB3ClO5ICk7z6MVXhXbWGvhpZzegZvSLD1TAu2sBJLUwiOVJB59PF4Qc_WNcOo&refId=DjykWOKGxiuFeHkW4HRHrQ%3D%3D&trackingId=MqDcjhaS%2BBVTL7Q6S259tg%3D%3D,"Assist with data analysis, dashboards, reporting, BI tools; gather requirements; support analytics tasks",bachelor's,0-2(entry level),"Analyze datasets, prepare reports, support BI tool implementation, collaborate with stakeholders","SQL, Excel, Power BI/Tableau, analytical mindset","SQL, Excel, Bachelor’s","Power BI, Python/R, data visualization experience",Not Specified
38,Nicolas Reyes,,LinkedIn,Entry-Level Data Analyst – Product Analytics,Full-Time,Dell  Technologies,"Houston, TX",hybrid,2/1/26,https://www.linkedin.com/jobs/view/4300783783/?alternateChannel=search&eBP=CwEAAAGcXsrLOvdZKberui8L9yjr6tIdmKAYt672r4tLgnKgpNY6s54Z2ZMb0xmYDhYyu1hmNmGpfiSg2Pe4mhekCGUr9TggOyYuXJgeB0JaG53ySP8weSXneCNHRcD-2lEvzClAmT3DOzWHf0YSL-qKl0Pabbhk3nYPJdeUIftZX2v6MH4pMaNndf-O0WbYY03VQaDU1IDy1KXi3MYs22ZdUKFX-bgwMG6wjP6ejnCu7ll60eqG0-F9leOx_Crs50vkgcWYfOVrV9sxA-XfkMeX-6NyKVKDl_AzocMD_uF9cnNvSToTuKpng1wZ4-9OwlYHh9cLn7bOIuhQQqc6aLPTy5cenhhi3XIXpOJE_o750qcu26edLBgxfz80qm13EGt_uS2ZI_c2rOEzyUKpUQsP5UyvR_nX9atKXxpcfk9B6cMkgfgd7D9el1eH_8-IqnU-ADSMUsUCl_oeHuI0xv7gcbW4zq5qma-0-wmFHfJ7Oh5Q3icO&refId=TFOKFqAOCk1rUSqo21avvA%3D%3D&trackingId=ig6pUzPNm6qveopYU65lDw%3D%3D,"Work with product analytics, data interpretation, dashboards, support analytics deliverables",bachelor's,Entry Level,"Analyze data, support analytics projects, produce reports/dashboards, collaborate with product teams","SQL, data analysis tools, reporting skills, analytical thinking","SQL proficiency, analytical mindset, Bachelor’s degree","Experience with BI tools (Tableau, Power BI), Python/R ",Not Specified
39,Ethan Rasmussen,,Indeed,Data Analysis,Full time,"EJES, Inc.","Houston, TX",on-site,,https://www.indeed.com/viewjob?jk=bb53defd0e9ea568&,"Supports Wastewater Operations by managing, validating, and analyzing data critical to Consent Decree compliance, EPA reporting, and operational decision-making. This position works closely with the reporting team, field crews, GIS team, and construction management team to make sure inspection, cleaning, and rehabilitation data is accurate, consistent, and usable across multiple systems.
The work directly impacts regulatory reporting, audit readiness, and how effectively the city plans and tracks wastewater collection work.",bachelor's,,"Track wastewater inspection, cleaning, and remediation activities to support Consent Decree compliance requirements;
Reviews, cleans, and audits data across multiple systems (Payment, Infor IPS, GIS, dashboards) to ensure accuracy and consistency;
Works with Wastewater Operations Consent Decree Reporting team to resolve data issues and ensure information is entered correctly and is auditable;
Coordinates with the GIS team to keep sewer line and manhole data current and aligned with field inspection data;
Develop and improve data tools using platforms such as ArcGIS, Power BI, Excel, and low-code tools (Power Apps / Power Automate) to support Wastewater Operations workflows","Bachelor’s degree in engineering, Environmental Science, GIS, Information Systems, Data Analytics, or a related field;
Basic working knowledge of GIS or mapping tools (such as ArcGIS Pro or ArcGIS Online), or the ability to learn quickly;
Experience using spreadsheets, dashboards, or reporting tools to summarize and communicate data;
Strong attention to detail and ability to follow data standards and procedures;
Ability to work across teams, ask questions, and follow up to resolve data issues","Bachelor’s degree in engineering, Environmental Science, GIS, Information Systems, Data Analytics, or a related field;
Basic working knowledge of GIS or mapping tools (such as ArcGIS Pro or ArcGIS Online), or the ability to learn quickly;
Experience using spreadsheets, dashboards, or reporting tools to summarize and communicate data;
Strong attention to detail and ability to follow data standards and procedures;
Ability to work across teams, ask questions, and follow up to resolve data issues",Not Specified,"$70,000 - $78,000 a year"
40,Ethan Rasmussen,,Linkedin,Data Engineer,Full time,TAS Energy,"Houston, TX",on-site,2/13/26,https://www.linkedin.com/jobs/view/data-engineer-at-tas-energy-4364196636?position=4&pageNum=0&refId=5vuIMRSoWeBA7mgy%2FN0%2FIA%3D%3D&trackingId=Htzc1aDHeapP7Bsc47hnIg%3D%3D,"The Data Engineer is responsible for designing, building, and maintaining the organization’s enterprise data pipelines, curated datasets, and analytics platform foundation. This role enables timely, accurate, and trusted decision-making by ensuring reliable, scalable, and governed data flows across the Enterprise Resource Planning (ERP) system, Product Lifecycle Management (PLM) system, and other integrated business applications.
The Data Engineer will engineer ingestion and curation from vendor-hosted enterprise data repositories and integration services, including Infor OS Data Lake and supported extraction methods (e.g., Data Fabric Objects API, Compass SQL API / Compass JDBC Driver, ION Data Lake Flows, and ETL Client for Data Lake). The role will enable enterprise analytics and reporting through Microsoft Fabric and Power BI, and will use Spark/PySpark, SQL, and Python to deliver performant, scalable transformations.
This role also supports the organization’s increasing use of AI-enabled analytics by preparing high-quality, well-governed datasets and following company requirements for responsible and compliant AI usage.",bachelor's,3+,"Data Engineering & Architecture (Microsoft Fabric / Lakehouse)

Design and maintain a modern enterprise analytics foundation using Microsoft Fabric (Lakehouse/Warehouse patterns) to support governed reporting and self-service analytics.
Build and manage curated data layers aligned to medallion-style processing (raw → standardized → curated) using Spark/PySpark, SQL, and Python.
Develop and maintain enterprise data models optimized for analytics performance, consistent KPI definitions, and reuse across business domains.

Data Integration & Ingestion (Infor OS Data Lake + APIs + Flows)

Develop and support automated ingestion from Infor OS Data Lake using supported extraction/integration methods such as:
Data Fabric Objects API (object/file extraction)
Compass SQL API / Compass JDBC Driver (query-based extraction)
ION Data Lake Flows (scheduled push to connection points)
ETL Client for Data Lake (scheduled transfer patterns)
Stream Pipelines where applicable for continuous/near real-time delivery
Implement incremental loading patterns, orchestration, monitoring, alerting, and failure recovery to ensure reliable delivery of daily/near real-time datasets.
Partner with application and integration teams to align ingestion with upstream interfaces, data contracts, and security requirements.
Reporting & Analytics Enablement (Power BI + Dataset Modeling)

Provide trusted, well-documented datasets that enable enterprise dashboards and self-service analytics in Power BI.
Build and maintain business-friendly semantic/dimensional models that support high-performance dashboards and consistent KPI definitions.
Support modernization and migration of reporting assets into Microsoft Fabric, ensuring datasets and models align to reporting needs and enterprise metric definitions.

Data Quality, Governance & Master Data Support

Implement validation, reconciliation, and anomaly detection to ensure accuracy and completeness of curated datasets.
Establish automated checks for common data issues (duplicates, missing attributes, invalid statuses, inconsistent units of measure).
Partner with master data stakeholders and business data stewards to define standards, drive adoption, and remediate root-cause issues impacting data quality.

AI-Enabled Analytics Support (Practical AI Competency)

Prepare AI-ready datasets by ensuring data completeness, consistency, lineage, and documentation (e.g., feature-ready curated tables, standardized definitions, and auditability).
Support AI-assisted development workflows (e.g., using copilots/assistants to accelerate transformation code generation, documentation, and standardization) while adhering to company AI requirements for accuracy, confidentiality, compliance, and labeling of AI-generated content where required.

Operational Excellence (Reliability, Supportability, Documentation)

Develop and maintain runbooks, operational documentation, lineage notes, and standardized naming conventions for pipelines, datasets, and reporting layers.
Track pipeline health metrics (freshness, completeness, latency, failure rates) and continuously improve reliability and performance.
Provide knowledge transfer and training to analysts and IT Business Applications team members to improve overall data fluency.
All other duties as assigned by TAS.

Job Skills

Strong understanding of modern data architectures (data lake/lakehouse/warehouse), data modeling, and ETL/ELT engineering patterns.
Proficiency in SQL and Python for data transformation and pipeline development.
Hands-on experience with Spark/PySpark for scalable transformations and performance tuning.
Experience integrating and extracting data from Infor OS Data Lake using Data Fabric Objects API, Compass SQL API/JDBC, ION Data Lake Flows, ETL Client for Data Lake, and/or Stream Pipelines.
Experience developing enterprise analytics assets using Microsoft Fabric and enabling dashboards and self-service reporting using Power BI.
Ability to implement data quality controls, reconciliation, documentation, and lineage practices that support trust and auditability.
Practical AI competency: ability to prepare AI-ready datasets and responsibly use AI assistants to improve productivity while maintaining accuracy, confidentiality, and compliance.
Strong communication skills to translate business needs into technical solutions and collaborate with both technical and non-technical stakeholders.","Minimum Requirements

3+ years of experience in data engineering, analytics engineering, or a related technical role.
Demonstrated experience building and maintaining curated datasets used for enterprise reporting and analytics.
Demonstrated experience with at least two of the following toolsets:
Microsoft Fabric (Lakehouse/Warehouse, pipelines/notebooks)
Power BI (dataset modeling and dashboard enablement)
Infor OS Data Lake extraction/integration methods (Objects API, Compass SQL API/JDBC, ION Data Lake Flows, ETL Client, Stream Pipelines)
Spark/PySpark
Experience implementing monitoring/alerting or operational runbooks for production data pipelines.
Familiarity with manufacturing/operations reporting domains (production, inventory, procurement, costing, project execution) preferred.
PHYSICAL REQUIREMENTS/WORK ENVIRONMENT:

Position is at least 80% to 95% at a desk working with computer. Ability to exert up to 10 pounds of force occasionally and/or a negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body. Performs other physical activities including use of fingers, sitting, stooping, bending, crouching, talking, hearing, and performing repetitive motions. Visual acuity requirements include color, depth perception and field of vision necessary to prepare and analyze data and figures, operate a computer terminal, and conduct extensive reading. The incumbent will be subject to inside environmental conditions.","Minimum Requirements

3+ years of experience in data engineering, analytics engineering, or a related technical role.
Demonstrated experience building and maintaining curated datasets used for enterprise reporting and analytics.
Demonstrated experience with at least two of the following toolsets:
Microsoft Fabric (Lakehouse/Warehouse, pipelines/notebooks)
Power BI (dataset modeling and dashboard enablement)
Infor OS Data Lake extraction/integration methods (Objects API, Compass SQL API/JDBC, ION Data Lake Flows, ETL Client, Stream Pipelines)
Spark/PySpark
Experience implementing monitoring/alerting or operational runbooks for production data pipelines.
Familiarity with manufacturing/operations reporting domains (production, inventory, procurement, costing, project execution) preferred.
PHYSICAL REQUIREMENTS/WORK ENVIRONMENT:

Position is at least 80% to 95% at a desk working with computer. Ability to exert up to 10 pounds of force occasionally and/or a negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body. Performs other physical activities including use of fingers, sitting, stooping, bending, crouching, talking, hearing, and performing repetitive motions. Visual acuity requirements include color, depth perception and field of vision necessary to prepare and analyze data and figures, operate a computer terminal, and conduct extensive reading. The incumbent will be subject to inside environmental conditions.",Not Specified,Not Specified
41,Ethan Rasmussen,,Linkedin,Python Data Engineer/Database Developer,Full time,Dexian,"Houston, TX",on-site,1/31/26,https://www.linkedin.com/jobs/view/python-data-engineer-at-dexian-4356606375?position=14&pageNum=0&refId=5vuIMRSoWeBA7mgy%2FN0%2FIA%3D%3D&trackingId=umXvR1W%2Bds%2FGqYwbT6M2yA%3D%3D,"Dexian stands at the forefront of Talent + Technology solutions with a presence spanning more than 70 locations worldwide and a team exceeding 10,000 professionals. As one of the largest technology and professional staffing companies and one of the largest minority-owned staffing companies in the United States, Dexian combines over 30 years of industry expertise with cutting-edge technologies to deliver comprehensive global services and support.  
Dexian connects the right talent and the right technology with the right organizations to deliver trajectory-changing results that help everyone achieve their ambitions and goals. To learn more, please visit https://dexian.com/.
Dexian is an Equal Opportunity Employer that recruits and hires qualified candidates without regard to race, religion, sex, sexual orientation, gender identity, age, national origin, ancestry, citizenship, disability, or veteran status.",nan,5+,Information Technology,"5+ years in Data Engineering with strong SQL and NoSQL database skills:
Databases: Oracle, SQL Server, Postgres, DB2, Elasticsearch, MongoDB
Advanced Python development and FastAPI microservices experience
Application development experience implementing business logic via SQL stored procedures and NoSQL utilities
Experience using LLM models, coding agents, and testing agents
Detail daily split between support and development, ticketing system usage, or direct user interaction","5+ years in Data Engineering with strong SQL and NoSQL database skills:
Databases: Oracle, SQL Server, Postgres, DB2, Elasticsearch, MongoDB
Advanced Python development and FastAPI microservices experience
Application development experience implementing business logic via SQL stored procedures and NoSQL utilities
Experience using LLM models, coding agents, and testing agents
Detail daily split between support and development, ticketing system usage, or direct user interaction",Not Specified,$60.00/hr - $70.00/hr
42,Jeremy Suen,,Indeed,Data Analysis,Full time,JPMorganChase,"Plano, TX",hybrid,,https://www.indeed.com/viewjob?jk=f8ab1f6ae5b43f51&tk=1jhfl8p8ggghv878&from=serp&vjs=3,"Drive continuous HR innovation with data-driven insights and impactful dashboards. Collaborate across teams to shape strategy and accelerate measurable outcomes.
Join us to lead analytics excellence and ongoing improvement!

As an Associate, HR Product Analytics, you will turn data into clear, compelling insights that drive product decisions and measurable outcomes. You are well‑versed in the modern data stack and provide precise requirements to technical teams for data sourcing and integration—ensuring stakeholder‑ready visualizations and narratives that enable data‑driven decision making. You will operate in a matrixed product organization—partnering with Product, Program Management, UX, Engineering, and HR/Operations—to define success metrics, prioritize in a fast‑paced environment, and present recommendations to senior stakeholders.",bachelor's,1+,"Collaborate and lead the building of enterprise‑ready dashboards and reports using Tableau, Sigma, and Databricks; define, instrument, and track product success metrics with Product and UX partners.
Translate business questions into analytics requirements for data sourcing and integration; partner with data engineering to combine and harmonize datasets using Databricks and Alteryx; automate repeatable workflows and validations to ensure accuracy and scalability.
Partner effectively across a matrix organization (Product, Program Management, UX, Engineering, HR/Operations) to understand needs, deliver impactful analytics, and build trusted relationships.
Present insights through clear, compelling narratives tailored to executive and non‑technical audiences; inform product roadmaps and lifecycle decisions.
Drive continuous improvement by identifying product friction points and analytics process gaps; implement enhancements that accelerate time‑to‑value and adoption.
Plan and execute work using Agile practices and tooling (Jira, Jira Align, Confluence); manage backlog, define acceptance criteria, and maintain delivery predictability.
Uphold quality and controls by ensuring data accuracy, integrity, confidentiality, and compliance in analytics activities; review technical specifications and support compliance operations testing and production readiness.","Required qualifications, capabilities, and skills

Bachelor’s degree in a quantitative or business discipline (Analytics, Data Science, Information Systems, Statistics, Economics, or similar).
1+ year of experience in product or digital analytics within a product‑focused environment.
Experience with SQL and Databricks, and experience designing dashboards with Tableau and Sigma.
Experience utilizing Large Language Models (LLMs) to accelerate analysis and automation.
Experience reviewing technical specifications and supporting compliance operations testing/production.
Excellent communication and stakeholder management; strong data storytelling and executive‑ready presentations.
Agile delivery experience using Jira, Jira Align, and Confluence; ability to prioritize and execute in a fast‑paced environment.
Preferred qualifications, capabilities, and skills

Demonstrated leadership behaviors in an individual‑contributor capacity (mentoring, guiding peers).
Strong written and verbal communication; effective time management and prioritization; ability to work independently and collaboratively.
Solution design that anticipates downstream impacts and supports reuse across products or clients.","Required qualifications, capabilities, and skills

Bachelor’s degree in a quantitative or business discipline (Analytics, Data Science, Information Systems, Statistics, Economics, or similar).
1+ year of experience in product or digital analytics within a product‑focused environment.
Experience with SQL and Databricks, and experience designing dashboards with Tableau and Sigma.
Experience utilizing Large Language Models (LLMs) to accelerate analysis and automation.
Experience reviewing technical specifications and supporting compliance operations testing/production.
Excellent communication and stakeholder management; strong data storytelling and executive‑ready presentations.
Agile delivery experience using Jira, Jira Align, and Confluence; ability to prioritize and execute in a fast‑paced environment.
","Preferred qualifications, capabilities, and skills

Demonstrated leadership behaviors in an individual‑contributor capacity (mentoring, guiding peers).
Strong written and verbal communication; effective time management and prioritization; ability to work independently and collaboratively.
Solution design that anticipates downstream impacts and supports reuse across products or clients.","$80,750 - $125,000 a yea"
43,Jeremy Suen,,Indeed,Lead Data Analysis,Full time,AT&T,"Dallas, TX",in office,,"Lead Data Analysis - Dallas, TX - Indeed.com","At AT&T, we empower leaders to drive change in a fast-evolving, connected world. Your strategic vision will help serve customers and transform lives through innovative solutions and impactful connections.

As a Lead Data Analysis, you'll support sales organizations as well as research, collect, process, and organize data into various data repositories including maintaining and updating interfaces, creating data rules and data mapping, resolving data discrepancies across multiple business applications, then responding to business requests to analyze data to generate actionable insights.",bachelor's,3+,"What you’ll do

Typical tasks may include, but are not limited to, the following:

Data Collection and Processing: Gather, preprocess, and cleanse data from various sources to ensure it is accurate and ready for analysis.

Data Analysis and Interpretation: Analyze data using statistical methods to identify trends and insights, creating reports and recommendations for business decisions.

Reporting and Visualization: Create clear, factual/precise, and compelling data visualizations and reports to effectively communicate findings to stakeholders.

Discrepancy Resolution and Quality Assurance: Identify, resolve, and ensure the accuracy of data discrepancies across platforms, maintaining data reliability through quality control and auditing.

Analytical Tools: Includes SQL, PowerBI, Python, etc.","What you’ll need

Bachelor’s degree (BS/BA) desired in Computer Science, Math, etc.

3+ years of related experience.

Certification is required in some areas.

What you’ll bring

An experienced professional, recognized as an expert, creatively resolving complex issues with broad and in-depth knowledge.

Leads significant projects with strategic autonomy, influencing executive decisions.

Mentors less experienced staff, implements long-term plans impacting the organization, and frequently collaborates with senior leadership.","What you’ll need

Bachelor’s degree (BS/BA) desired in Computer Science, Math, etc.

3+ years of related experience.

Certification is required in some areas.","What you’ll bring

An experienced professional, recognized as an expert, creatively resolving complex issues with broad and in-depth knowledge.

Leads significant projects with strategic autonomy, influencing executive decisions.

Mentors less experienced staff, implements long-term plans impacting the organization, and frequently collaborates with senior leadership.","$130,700.00 - $196,100.00"
44,Jeremy Suen,,Indeed,Data Analyst Staff,Full time,Lockheed Martin,"Fort Worth, TX",hybrid,"Dec. 16, 2025","Data Analyst Staff - Level 4 - Fort Worth, TX 76137 - Indeed.com","Description:What You Will Be Doing:

The selected candidate will perform data analytics in support of F-35 Sustainment and will be responsible for collecting, processing, and analyzing data to develop immersive stories that answer business questions. Using proven and sound statistical methods, the analyst draws insights from data, and translates those insights into action that drive business results. Data Analysts are extremely resourceful and able to find novel new data sources to enrich their analysis. They apply mathematical and statistical methods to business and risk management problems.
Work as a technical team lead and provide guidance to the team in performing analysis to establish data sets that would be used to perform sustainment modeling activities
Support and lead coordination and development of problem statements, modeling approaches and ground rules and assumptions (GR&A)
Collaborate with leadership, customers, and cross-functional teams to drive data-driven decision-making
Program management of key tasks and resources to achieve cost and schedule
Develop interactive data analytics dashboards to monitor operational performance
Monitor key metrics and ensure performance against defined benchmarks and KPIs
Manage the quality assurance of data scraping, query databases for stakeholder requests, and triage data issues for timely resolutions
Analyze large datasets, draw valid inferences and prepare insights in narrative or visual forms, including dashboards
Set up and maintain data processes and new analytics capabilities
Produce and track key performance indicators
Ability to formulate functional and technical requirements from business problems",bachelor's,Experienced Professional,"The selected candidate will perform data analytics in support of F-35 Sustainment and will be responsible for collecting, processing, and analyzing data to develop immersive stories that answer business questions. Using proven and sound statistical methods, the analyst draws insights from data, and translates those insights into action that drive business results. Data Analysts are extremely resourceful and able to find novel new data sources to enrich their analysis. They apply mathematical and statistical methods to business and risk management problems.
Work as a technical team lead and provide guidance to the team in performing analysis to establish data sets that would be used to perform sustainment modeling activities
Support and lead coordination and development of problem statements, modeling approaches and ground rules and assumptions (GR&A)
Collaborate with leadership, customers, and cross-functional teams to drive data-driven decision-making
Program management of key tasks and resources to achieve cost and schedule
Develop interactive data analytics dashboards to monitor operational performance
Monitor key metrics and ensure performance against defined benchmarks and KPIs
Manage the quality assurance of data scraping, query databases for stakeholder requests, and triage data issues for timely resolutions
Analyze large datasets, draw valid inferences and prepare insights in narrative or visual forms, including dashboards
Set up and maintain data processes and new analytics capabilities
Produce and track key performance indicators
Ability to formulate functional and technical requirements from business problems","Basic Qualifications:
Bachelors of Science degree in Engineering or a related technical discipline (Industrial, Mechanical, Aerospace, Electrical, etc.) Physics, Data Science, Data Analysis, or Mathematics
Must be able to obtain a DoD Secret Clearance to perform job duties
Experienced in scripting (one or more common languages e.g., Python, R, SQL) and data visualization (e.g., Tableau, Power BI)
Strong analytical skills and understanding of system databases, data elements, data structures and hierarchies, and/or application software solutions to optimize data gathering and analysis
Project Management experience
Excellent written and verbal communication skills
Desired Skills:
Ability to interact with the customer and senior leadership as the subject matter expert to present and work through data issues and discrepancies
Familiar with working in a SAFe agile framework environment and in a product owner support role
Ability to define technical solutions against business opportunities
Experience with continuous improvement initiatives
Experience deconstructing complex operations into component data problems for distributed work across teams
Experience creating executive level presentations to include summary and talking points
Experience with application of scientific methods for testing and debugging, problem resolution, root-cause analysis
Experience in HANA and/or Oracle
Ability to adapt business processes into automated tools
Experience collecting and compiling datasets from disparate data sources into the required data structure
Ability to perform analysis via multi-criteria decision modeling including life-cycle cost analysis, performance & cost trade-offs, and business case analysis
Experience in the reconciliation process
Proficiency with MS Office tool suite
Security Clearance Statement: This position requires a government security clearance, you must be a US Citizen for consideration.","Basic Qualifications:
Bachelors of Science degree in Engineering or a related technical discipline (Industrial, Mechanical, Aerospace, Electrical, etc.) Physics, Data Science, Data Analysis, or Mathematics
Must be able to obtain a DoD Secret Clearance to perform job duties
Experienced in scripting (one or more common languages e.g., Python, R, SQL) and data visualization (e.g., Tableau, Power BI)
Strong analytical skills and understanding of system databases, data elements, data structures and hierarchies, and/or application software solutions to optimize data gathering and analysis
Project Management experience
Excellent written and verbal communication skills","Desired Skills:
Ability to interact with the customer and senior leadership as the subject matter expert to present and work through data issues and discrepancies
Familiar with working in a SAFe agile framework environment and in a product owner support role
Ability to define technical solutions against business opportunities
Experience with continuous improvement initiatives
Experience deconstructing complex operations into component data problems for distributed work across teams
Experience creating executive level presentations to include summary and talking points
Experience with application of scientific methods for testing and debugging, problem resolution, root-cause analysis
Experience in HANA and/or Oracle
Ability to adapt business processes into automated tools
Experience collecting and compiling datasets from disparate data sources into the required data structure
Ability to perform analysis via multi-criteria decision modeling including life-cycle cost analysis, performance & cost trade-offs, and business case analysis
Experience in the reconciliation process
Proficiency with MS Office tool suite","$130,700.00 – $196,100.00 a year"
45,Jonathan Silberstein,,Indeed,Senior Data Engineer,Full time,"innoVet Health, LLC",United States,remote,,https://www.indeed.com/viewjob?jk=08024e8a312159d0&from=shareddesktop_copy,"InnoVet Health, a small and growing business that provides health IT professional services to the Department of Veterans Affairs (VA) is looking for an experienced Sr. Azure Data Engineer proficient in Databricks, Delta Lake, and medallion/lakehouse architectures to support healthcare analytics, interoperability, and data integration needs. You will build scalable data pipelines, ensure data quality, and support advanced analytics across clinical, operational, and regulatory datasets. Your work will directly impact VA healthcare delivery by building an analytical infrastructure that enables AI/ML and advanced analytics to deliver short-term and longitudinal insights to healthcare professionals serving Veterans. You will work in an agile environment alongside VA and contractor stakeholders. It is flexible, full-time, and does not require relocation (work-from-home). The pay, benefits, and growth potential are competitive.

Responsibilities

    Gather and translate business, technical, and functional requirements into data architecture and pipeline design decisions. Design and develop Azure Data Factory and Databricks-based ETL/ELT pipelines using PySpark, Delta Lake, and medallion/lakehouse architecture.
    Ingest and transform healthcare data (clinical, claims, FHIR, HL7, EHR, ADT, PGHD) from diverse sources.
    Build secure, scalable solutions using Azure Data Lake Storage, ADF, and Event Hubs, and related services, with attention to latency and reliability requirements.
    Implement data quality, lineage, and governance using Microsoft Purview.
    Optimize Databricks jobs (performance tuning, cluster sizing, Z-ordering, partitioning).
    Enforce HIPAA-aligned security practices: RBAC, Key Vault, private endpoints, PHI protection.
    Collaborate with data scientists, analysts, and clinical informatics teams.
    Stay up to date with emerging technologies and trends in data engineering and healthcare data management.
    Present and discuss results with IT and business stakeholders.
    Participate in company growth and other responsibilities, as assigned.

Qualifications

    Bachelor’s or master’s degree in computer science, data analytics, or related field.
    Minimum 6+ years data engineering experience; 4+ years hands-on with Azure and 2+ years hands-on with Databricks.
    Strong skills in PySpark, Delta Lake, SQL, and distributed data processing.
    Experience with healthcare data standards (FHIR, HL7, X12/EDI, CCD, claims data, PGHD).
    Strong understanding of HIPAA, PHI handling, and secure data architecture.
    Experience with ADF, ADLS Gen2, Azure Functions, and event-driven ingestion.
    Strong understanding of data modeling for analytics (dimensional + lakehouse).
    Excellent problem-solving, collaboration and communication skills.
    Green card or US citizen required because of government contract work.
    No 1099 or corp-to-corp or international outsourcing or staffing agencies.

Preferred

    Experience with Federal EHR (VistA and Oracle Health) data.
    Experience with Azure Event Hubs, Stream Analytics, AWS Kinesis, or similar data streaming platforms is also a plus.

Job Type: Full-time

Pay: From $140,000.00 per year

Benefits:

    401(k)
    401(k) matching
    Dental insurance
    Health insurance
    Paid time off
    Referral program
    Vision insurance

Application Question(s):

    This position works directly with US government contracts and under Order 11935, it requires either U.S. Citizenship or valid Green Card. Please answer 2 if you are a US citizen, 1 if you have a valid green card, 0 if neither. Please make sure to answer this question.
    Your LinkedIn profile link (required):

Education:

    Bachelor's (Required)

Experience:

    Azure Data Lake: 4 years (Required)
    Databricks: 4 years (Required)

Location:

    United States (Required)

Work Location: Remote",bachelor's,6+,"
    Gather and translate business, technical, and functional requirements into data architecture and pipeline design decisions. Design and develop Azure Data Factory and Databricks-based ETL/ELT pipelines using PySpark, Delta Lake, and medallion/lakehouse architecture.
    Ingest and transform healthcare data (clinical, claims, FHIR, HL7, EHR, ADT, PGHD) from diverse sources.
    Build secure, scalable solutions using Azure Data Lake Storage, ADF, and Event Hubs, and related services, with attention to latency and reliability requirements.
    Implement data quality, lineage, and governance using Microsoft Purview.
    Optimize Databricks jobs (performance tuning, cluster sizing, Z-ordering, partitioning).
    Enforce HIPAA-aligned security practices: RBAC, Key Vault, private endpoints, PHI protection.
    Collaborate with data scientists, analysts, and clinical informatics teams.
    Stay up to date with emerging technologies and trends in data engineering and healthcare data management.
    Present and discuss results with IT and business stakeholders.
    Participate in company growth and other responsibilities, as assigned.","
    Bachelor’s or master’s degree in computer science, data analytics, or related field.
    Minimum 6+ years data engineering experience; 4+ years hands-on with Azure and 2+ years hands-on with Databricks.
    Strong skills in PySpark, Delta Lake, SQL, and distributed data processing.
    Experience with healthcare data standards (FHIR, HL7, X12/EDI, CCD, claims data, PGHD).
    Strong understanding of HIPAA, PHI handling, and secure data architecture.
    Experience with ADF, ADLS Gen2, Azure Functions, and event-driven ingestion.
    Strong understanding of data modeling for analytics (dimensional + lakehouse).
    Excellent problem-solving, collaboration and communication skills.
    Green card or US citizen required because of government contract work.
    No 1099 or corp-to-corp or international outsourcing or staffing agencies.
    Experience with Federal EHR (VistA and Oracle Health) data.
    Experience with Azure Event Hubs, Stream Analytics, AWS Kinesis, or similar data streaming platforms is also a plus.
",,"
    Experience with Federal EHR (VistA and Oracle Health) data.
    Experience with Azure Event Hubs, Stream Analytics, AWS Kinesis, or similar data streaming platforms is also a plus.","$140,000+"
46,Jonathan Silberstein,,Indeed,Data Scientist,Full time,Valkyrie Intelligence,"Austin, TX",hybrid,,https://www.indeed.com/viewjob?jk=9a5f4cc48652f64f&from=shareddesktop_copy,"Full-time Employment: Ability to work as a full-time employee

Location: Austin, TX (Hybrid)


About Us:

Valkyrie is an applied science firm that builds industry-defining custom AI, Machine Learning and Knowledge Engineering solutions. Our interdisciplinary applied science teams support our clients end-to-end—from data normalization through model deployment—solving complex, high-impact problems across commercial and government sectors. Our work spans industries and institutions including SiriusXM, Activision, Chubb Insurance, and the U.S. Department of Defense. We operate at the intersection of deep technical rigor, operational excellence, and real-world impact.


Data Scientist Position:

The Data Scientist position is an early-career scientist excited to contribute to a growing business and apply the scientific method to uncover insights from data. In this role, you will conduct exploratory data analysis (EDA) and data cleaning, build visualizations to communicate project results, engineer data features for statistical and machine learning models, and identify and evaluate novel data sources. You will support data analysis, modeling, and experimentation while collaborating with senior team members on investigations using emerging tools and frameworks. This role is ideal for someone passionate about data, curious by nature, and eager to grow their skills while transforming data into actionable insights.


Data Scientist Qualifications:

    Bachelor’s degree or master’s degree in STEM (Science, Technology, Engineering, Math) or related field
    1+ years of professional experience in a scientific role or 2+ science or engineering focused internships
    1+ year Python (preferred) experience in a professional role or 3+ years of Python in an academic setting
    Some experience with SciKitLearn and Pandas
    Familiarity of various database structures: Relational (SQL), Document (MongoDB), Graph (Neo4j), Column (Google BigTable)
    Experience with Python data visualization packages (Seaborn, Plotly, Matplotlib)
    At least 1 Data Science, AI, and/or ML course completed
    Exceptional written and verbal communications skills along with experience assisting in the preparation and delivering of documentation, proposals, presentations, and structured working sessions to technical and non-technical audiences.


Data Scientist Like-to-haves:

    Some experience with visualization tools: Plotly, Matplotlib, Seaborn, etc.
    1+ year experience with SQL
    Experience with Cloud Computing (AWS, Azure, GCP)
    Completed software engineering courses


Perks:

    Tremendous growth potential
    Open and unlimited PTO & Sick time
    Medical, dental, vision, & HSA options
    401K
    Exciting office location in Downtown Austin
    Parking Included
    Onsite gym & showers
    Stocked kitchen with healthy snacks, drinks, coffee, etc
    Team events including happy hours, catered lunches, and other fun outings
    Innovative, collaborative, and fun work environment that fosters a positive and supportive culture for growth


Full-time Employment: Ability to work as a full-time employee

The pay range for this role is:
75,000 - 100,000 USD per year(Austin) ",bachelor's,1-3,"The Data Scientist position is an early-career scientist excited to contribute to a growing business and apply the scientific method to uncover insights from data. In this role, you will conduct exploratory data analysis (EDA) and data cleaning, build visualizations to communicate project results, engineer data features for statistical and machine learning models, and identify and evaluate novel data sources. You will support data analysis, modeling, and experimentation while collaborating with senior team members on investigations using emerging tools and frameworks. This role is ideal for someone passionate about data, curious by nature, and eager to grow their skills while transforming data into actionable insights.","
    Bachelor’s degree or master’s degree in STEM (Science, Technology, Engineering, Math) or related field
    1+ years of professional experience in a scientific role or 2+ science or engineering focused internships
    1+ year Python (preferred) experience in a professional role or 3+ years of Python in an academic setting
    Some experience with SciKitLearn and Pandas
    Familiarity of various database structures: Relational (SQL), Document (MongoDB), Graph (Neo4j), Column (Google BigTable)
    Experience with Python data visualization packages (Seaborn, Plotly, Matplotlib)
    At least 1 Data Science, AI, and/or ML course completed
    Exceptional written and verbal communications skills along with experience assisting in the preparation and delivering of documentation, proposals, presentations, and structured working sessions to technical and non-technical audiences.

    Some experience with visualization tools: Plotly, Matplotlib, Seaborn, etc.
    1+ year experience with SQL
    Experience with Cloud Computing (AWS, Azure, GCP)
    Completed software engineering courses
","
    Bachelor’s degree or master’s degree in STEM (Science, Technology, Engineering, Math) or related field
    1+ years of professional experience in a scientific role or 2+ science or engineering focused internships
    1+ year Python (preferred) experience in a professional role or 3+ years of Python in an academic setting
    Some experience with SciKitLearn and Pandas
    Familiarity of various database structures: Relational (SQL), Document (MongoDB), Graph (Neo4j), Column (Google BigTable)
    Experience with Python data visualization packages (Seaborn, Plotly, Matplotlib)
    At least 1 Data Science, AI, and/or ML course completed
    Exceptional written and verbal communications skills along with experience assisting in the preparation and delivering of documentation, proposals, presentations, and structured working sessions to technical and non-technical audiences.","
    Some experience with visualization tools: Plotly, Matplotlib, Seaborn, etc.
    1+ year experience with SQL
    Experience with Cloud Computing (AWS, Azure, GCP)
    Completed software engineering courses","$75,000 - $100,000"
47,Jonathan Silberstein,,Indeed,Data Scientist / Imaging Physics - Research,Full time,MD Anderson,"Houston, TX",on site,,https://www.indeed.com/viewjob?jk=18489cd11e976efc&from=shareddesktop_copy,"The University of Texas MD Anderson Cancer Center invites applications for a Data Scientist (Computational Scientist) to join the Surgical Data Science Program within the Institute for Data Science in Oncology (IDSO). IDSO is composed of five major focus areas dedicated to advancing data science and emerging medical technologies to improve clinical care and operational excellence.

Within the IDSO focus area on Quality, Safety, and Access, the Surgical Data Science Program brings together experts in data science, systems engineering, and technology development. This multidisciplinary team collaborates closely with surgeons, physicists, and engineers to deliver impactful research and translation in:

    Multidimensional data analysis (including medical imaging)
    Predictive modeling
    Clinical outcomes research
    Applied machine learning and AI in surgical and perioperative care


Shift / hours: Based on business needs and 100% onsite

The ideal applicant will have demonstrated experience with/in computing / programming (Python, Matlab, C++, CUDA, Julia, R and/or SQL), machine learning / deep learning methods including neural network design, computer vision / image analysis, and statistical analysis

Key Responsibilities

The Data Scientist will:

    Develop and apply advanced machine learning, deep learning, computer vision, and statistical modeling techniques.
    Conduct multidimensional data analyses, including medical image data, clinical data, and outcomes.
    Contribute to predictive modeling, decision-support tools, and data-driven clinical insights.
    Collaborate with a multidisciplinary team across surgery, physics, engineering, and data science.
    Support research translation into clinical workflows and operational improvement initiatives.


Required Technical Expertise

Candidates should demonstrate experience with:

Programming & Computing

    Python, MATLAB, C++, CUDA, Julia, R, and/or SQL


Machine Learning / Deep Learning

    Neural network design and implementation
    Computer vision and image analysis
    Applied statistics and data modeling


Preferred Experience with Scientific Computing Libraries

    SciPy, pandas, statsmodels
    OpenCV, XGBoost
    PyTorch and/or TensorFlow
    SQL or other database querying languages


Preferred Experience with Modern ML/Statistical Techniques

    Regression, clustering, segmentation
    Time-series analysis
    Recommender systems
    Predictive analytics
    Bayesian modeling
    Data fusion
    Supervised and unsupervised learning
    Decision trees, A/B testing
    Natural language processing (NLP)


EDUCATION

    Required: Bachelor's Degree Biomedical Engineering, Electrical Engineering, Computer Engineering, Physics, Applied Mathematics, Science, Engineering, Computer Science, Statistics, Computational Biology, or related field.
    Preferred: Master's Degree Science, Engineering or related field.
    Preferred: PhD Science, Engineering or related field.


WORK EXPERIENCE

    Required: 3 years Scientific software or industry development/analysis experience. or
    Required: 1 year Required experience with Master's degree. or
    Required: With PhD, no experience required.


The University of Texas MD Anderson Cancer Center offers excellent benefits, including medical, dental, paid time off, retirement, tuition benefits, educational opportunities, and individual and team recognition.

This position may be responsible for maintaining the security and integrity of critical infrastructure, as defined in Section 113.001(2) of the Texas Business and Commerce Code and therefore may require routine reviews and screening. The ability to satisfy and maintain all requirements necessary to ensure the continued security and integrity of such infrastructure is a condition of hire and continued employment.

It is the policy of The University of Texas MD Anderson Cancer Center to provide equal employment opportunity without regard to race, color, religion, age, national origin, sex, gender, sexual orientation, gender identity/expression, disability, protected veteran status, genetic information, or any other basis protected by institutional policy or by federal, state, or local laws unless such distinction is required by law.http://www.mdanderson.org/about-us/legal-and-policy/legal-statements/eeo-affirmative-action.html

Additional Information

    Requisition ID: 178045
    Employment Status: Full-Time
    Employee Status: Regular
    Work Week: Days
    Minimum Salary: US Dollar (USD) 106,500
    Midpoint Salary: US Dollar (USD) 133,000
    Maximum Salary : US Dollar (USD) 159,500
    FLSA: exempt and not eligible for overtime pay
    Fund Type: Soft
    Work Location: Onsite
    Pivotal Position: Yes
    Referral Bonus Available?: No
    Relocation Assistance Available?: Yes",bachelor's,0-3,"The Data Scientist will:

    Develop and apply advanced machine learning, deep learning, computer vision, and statistical modeling techniques.
    Conduct multidimensional data analyses, including medical image data, clinical data, and outcomes.
    Contribute to predictive modeling, decision-support tools, and data-driven clinical insights.
    Collaborate with a multidisciplinary team across surgery, physics, engineering, and data science.
    Support research translation into clinical workflows and operational improvement initiatives.","Required Technical Expertise

Candidates should demonstrate experience with:

Programming & Computing

    Python, MATLAB, C++, CUDA, Julia, R, and/or SQL


Machine Learning / Deep Learning

    Neural network design and implementation
    Computer vision and image analysis
    Applied statistics and data modeling


Preferred Experience with Scientific Computing Libraries

    SciPy, pandas, statsmodels
    OpenCV, XGBoost
    PyTorch and/or TensorFlow
    SQL or other database querying languages


Preferred Experience with Modern ML/Statistical Techniques

    Regression, clustering, segmentation
    Time-series analysis
    Recommender systems
    Predictive analytics
    Bayesian modeling
    Data fusion
    Supervised and unsupervised learning
    Decision trees, A/B testing
    Natural language processing (NLP)","Candidates should demonstrate experience with:

Programming & Computing

    Python, MATLAB, C++, CUDA, Julia, R, and/or SQL


Machine Learning / Deep Learning

    Neural network design and implementation
    Computer vision and image analysis
    Applied statistics and data modeling","Preferred Experience with Scientific Computing Libraries

    SciPy, pandas, statsmodels
    OpenCV, XGBoost
    PyTorch and/or TensorFlow
    SQL or other database querying languages


Preferred Experience with Modern ML/Statistical Techniques

    Regression, clustering, segmentation
    Time-series analysis
    Recommender systems
    Predictive analytics
    Bayesian modeling
    Data fusion
    Supervised and unsupervised learning
    Decision trees, A/B testing
    Natural language processing (NLP)","$106,500 - $159,500"
48,Jonathan Silberstein,,Indeed,"Student Researcher, BS/MS, Winter/Summer 2026",Internship,Google,Multiple locations,on site,,https://www.indeed.com/viewjob?jk=15831d775fd49834&from=shareddesktop_copy,"Applications will be reviewed on a rolling basis and it’s in the applicant’s best interest to apply early. The anticipated application window is open until July 17, 2026, but may close earlier if all available projects are full. Applications submitted after the application window or once role is closed/projects are full will not be considered.

Participation in this program requires that you are located in the United States for the duration of the engagement.

This opportunity is intended for students who are pursuing a Bachelor's or Master’s degree program in Computer Science or a related field. Our Student Researcher opportunities are flexible in time commitment, length of opportunity, and onsite/remote nature, depending on the specific project and host needs. Start dates for this role are typically January through July.

This program is best suited for students who will not be seeking full time employment following this role, as this program is non-conversion eligible.

Google is a global company and, in order to facilitate efficient collaboration and communication globally, English proficiency is a requirement for this internship program.


To start the application process, you will need an updated CV or resume and a current unofficial or official transcript in English (PDFs preferred).

Please ensure your anticipated graduation dates (in MM/YY) and any proficiency in coding languages are listed on the resume.

Applicants in the County of Los Angeles: Qualified applications with arrest or conviction records will be considered for employment in accordance with the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act.

Applicants in San Francisco: Qualified applications with arrest or conviction records will be considered for employment in accordance with the San Francisco Fair Chance Ordinance for Employers and the California Fair Chance Act.

Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; Ann Arbor, MI, USA; Atlanta, GA, USA; Austin, TX, USA; Cambridge, MA, USA; Chicago, IL, USA; Irvine, CA, USA; Kirkland, WA, USA; Los Angeles, CA, USA; Madison, WI, USA; New York, NY, USA; Palo Alto, CA, USA; Pittsburgh, PA, USA; San Bruno, CA, USA; Seattle, WA, USA; San Francisco, CA, USA; Sunnyvale, CA, USA; Washington D.C., DC, USA; Princeton, NJ, USA.
Minimum qualifications:

    Currently enrolled in a Bachelor's or Master’s degree in Computer Science, Linguistics, Statistics, Biostatistics, Applied Mathematics, Operations Research, Economics, Natural Sciences, or related technical field.
    Experience in one area of computer science (e.g., Natural Language Understanding, Human Computer Interactions, Computer Vision, Machine Learning, Deep Learning, Algorithmic Foundations of Optimization, Quantum Information Science, Data Science, Software Engineering, or similar areas).


Preferred qualifications:

    Currently enrolled in a full-time degree program and returning to the program after completion of the internship.
    Currently attending a degree program in the United States.
    Experience as a researcher, including internships, full-time, or at a lab.
    Experience contributing research communities or efforts, including publishing papers in major conferences or journals.
    Experience with one or more general purpose programming languages (e.g., Python, Java, JavaScript, C/C++, etc.).

About the job

The Student Researcher Program fosters academic collaborations by hiring students onto research projects aligned to company priorities in scientific advancement. The program offers placements on teams across Google, for research, engineering, and science roles. As a Student Researcher, you will have the opportunity to participate in research projects focused on developing solutions for real-world, large-scale problems.

Student Researcher projects are exploratory and experiences that drive scientific advancement across a multitude of research areas. Students will work collaboratively on projects that explore innovative research challenges and support the creation of breakthrough technologies.

Projects vary in duration and location based on team and student requirements. It is required that you are located in one of the specific country locations identified for this role for the full duration of the engagement. When you apply, you will be considered for Student Researcher positions across all of Google's research teams including Google DeepMind, Google Research, Google Cloud and more. This allows us to find the right project match for your skills and interests.

Researchers across Google are working to advance the state of the art in computing and build the next generation of intelligent systems for all Google products. To achieve this, we invest in foundational research and work on projects that utilize the latest computer science techniques developed by skilled software developers and research scientists. Whether we're shaping the future of sustainability, optimizing algorithms, or pioneering AI systems, our teams strive to continuously progress science, advance society, and improve the lives of billions of people.
The US base salary range for this full-time position is $92,000-$122,000. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.
Responsibilities

    Participate in research to develop solutions for real-world, large-scale problems.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form. ",high school,0,"Participate in research to develop solutions for real-world, large-scale problems.","
    Currently enrolled in a Bachelor's or Master’s degree in Computer Science, Linguistics, Statistics, Biostatistics, Applied Mathematics, Operations Research, Economics, Natural Sciences, or related technical field.
    Experience in one area of computer science (e.g., Natural Language Understanding, Human Computer Interactions, Computer Vision, Machine Learning, Deep Learning, Algorithmic Foundations of Optimization, Quantum Information Science, Data Science, Software Engineering, or similar areas).
Currently enrolled in a full-time degree program and returning to the program after completion of the internship.
Currently attending a degree program in the United States.
Experience as a researcher, including internships, full-time, or at a lab.
Experience contributing research communities or efforts, including publishing papers in major conferences or journals.
Experience with one or more general purpose programming languages (e.g., Python, Java, JavaScript, C/C++, etc.).","
    Currently enrolled in a Bachelor's or Master’s degree in Computer Science, Linguistics, Statistics, Biostatistics, Applied Mathematics, Operations Research, Economics, Natural Sciences, or related technical field.
    Experience in one area of computer science (e.g., Natural Language Understanding, Human Computer Interactions, Computer Vision, Machine Learning, Deep Learning, Algorithmic Foundations of Optimization, Quantum Information Science, Data Science, Software Engineering, or similar areas).","Currently enrolled in a full-time degree program and returning to the program after completion of the internship.
Currently attending a degree program in the United States.
Experience as a researcher, including internships, full-time, or at a lab.
Experience contributing research communities or efforts, including publishing papers in major conferences or journals.
Experience with one or more general purpose programming languages (e.g., Python, Java, JavaScript, C/C++, etc.).","$92,000 - $122,000"
49,Saketh Thippireddy,,Linkedin,Data Scientist,Full time,Gartner,"Irving, TX",hybrid,,https://www.linkedin.com/jobs/search-results/?currentJobId=4344576100&refId=9eead0aa-82e5-4f88-ab34-d9765190f78f&trackingId=Gha3kkfbT0Sy48JAp%2BLNMQ%3D%3D&keywords=data%20scientist&origin=BLENDED_SEARCH_RESULT_NAVIGATION_JOB_CARD&originToLandingJobPostings=4344576100%2C4320766131%2C4338612569,"In Gartner’s Services Data Science team, we innovate the way our team helps clients receive value, so technology leaders will be able to make smarter decisions in a different way.

We are searching for a talented data scientist to join our team. You will have access to the best facilities, technology and expertise within the industry and will work on challenging business problems. This is an excellent opportunity to be part of a new venture, in a start-up environment where you can truly develop your skill set and knowledge and bring impact to the team.",bachelor's,4,"What You’ll Do

 Designing and implementing state of the art Large Language Model (LLM) based agents that seamlessly synthesize complex information and initiate important actions in a business workflow. 
 Using advanced Generative AI techniques deriving actionable insights from unstructured text data, such as call transcripts and emails. 
 Predicting client interest basis their digital footprint and making relevant recommendations to drive higher client value delivery
 Leverage statistical and machine learning techniques to extract actionable insights from client retention data. 
 Develop customer churn prediction models that proactively identify at-risk clients,
 Build tools to process structured and unstructured data
 Engineering features and signals to train ML model from diverse data collection","BS required/ MS/ preferred; in Computer Science or other technology, Math, Physics, Statistics or Economics (focus on Natural Language Processing, Information Retrieval a plus)
 4 years’ experience in data science methodologies as applied to live initiatives or software development// Experience working with Gen AI projects
 Minimum 4+ years of experience in python coding and statistical analysis
 Minimum 2 years working experience in several of the following:
Prompt Engineering and working with LLMs
Machine Learning and statistical techniques
Data mining and recommendation systems
Natural Language Processing and Information Retrieval
Experience working with large volumes of data
User behavior modeling","BS required4 years’ experience in data science methodologies as applied to live initiatives or software development// Experience working with Gen AI projects
 Minimum 4+ years of experience in python coding and statistical analysis
 Minimum 2 years working experience in several of the following:
Prompt Engineering and working with LLMs
Machine Learning and statistical techniques
Data mining and recommendation systems
Natural Language Processing and Information Retrieval
Experience working with large volumes of data
User behavior modeling",MS/ preferred,"$98,000-$133,000"
50,Saketh Thippireddy,,LinkedIn,Senior API Data Services Engineer,Full time,Cetera Financial Group,"Dallas, TX",hybrid,,https://www.linkedin.com/jobs/search-results/?currentJobId=4365914646&eBP=CwEAAAGcYNN75auKL8KZtcNk86RHbsK2bUos8S9mHiRgjQHoOLryIazioogoHEnojO8e50nosP_jJls1r_OcWRTEBDCKpF7ximbR8HjBePDZMh_VnYbd0qEkagH52XBBuNS6bvbsAIQ6gf-KK6dYftJn8WJ9GFzT0pzd9lWNgCA0eQ7ILuMynvFtiZHSq6P6Q9GOmIBKRgxugsDzppLuv-7NV3VIMhux0ipjZcK87xYAjsJKPsbUVRd2HlIcuFNHP0lyOB4664-FxF3knJ-xK1QfYTxO5udaQa6pSCSE2S8jzG8FL76BojhOY580tYTUQpSzeGnk4MIVLLgBdP9Wi6vxsNwywHfkV4ebuhbjVKoeUzSQvGKXXmIXYLhl7pg_hQGvaMNQoKdg2W50EzEVGWc5vGR_oT0D9_yasaVMvABGVxI3L-2yOYJOuuAO3iB7gKn4phwaVNqMbhOGHhRzU694Y_5n5T_xMQruF6V5PufO-kfGPtLivjSOWQ-p_7gjJjChrVK4x8wTvXUIZyx9QB641ZBM&refId=wH0qhQIZ6HXc32TrbWo0rA%3D%3D&trackingId=7Gwk5mUGStKz6tlB9YEXuw%3D%3D&keywords=data%20engineer&origin=SEMANTIC_SEARCH_LANDING_PAGE,"The Senior API & Data Services Engineer will design, build, and operate high-performance, secure, and scalable data access services within Celera's modernized event-driven data platform. This role focuses on developing API-first data services, caching layers, and access patterns that expose canonical operational data (transactions, positions, accounts, balances) to both operational and analytical consumers. This engineer plays a key role in decoupling data producers from consumers, enabling technology stack simplification while meeting the performance, security, and reliability expectations of a regulated financial services environment. The role requires strong experience with AWS-native services, distributed systems, and low-latency caching technologies.



The ideal candidate is a senior, hands-on engineer who embraces AI-assisted development practices to improve delivery velocity, code quality, and platform reliability and brings strong experience in API-first platforms, distributed systems, and financial services where performance, security, and auditability are paramount.",bachelor's,5-7+,"What You Will Do:



API & Data Service Engineering

Design and develop API‑first data services using REST and GraphQL.
Deliver secure, high‑performance access to canonical data from TPM/PCB platforms.
Build versioned, contract-driven APIs with full documentation and cataloging.
Create reusable components to standardize data access across consumers.


Caching & Performance

Implement Redis/ElastiCache–based low‑latency caching.
Tune APIs and caching layers to meet strict SLAs and near‑real‑time needs.
Balance cache freshness, consistency, and cost in distributed systems.
Diagnose performance issues across API, cache, and backend layers.
Use AWS streaming tech (Kinesis, Kafka/MSK) to support real‑time workloads.


Cloud-Native Engineering (AWS)

Build and deploy services using API Gateway, Lambda, ECS/EKS, DynamoDB, Aurora, S3, ElastiCache.
Deliver resilient, scalable, cost‑efficient cloud services.
Participate in CI/CD, infrastructure‑as‑code, and automated environment pipelines.


Security & Governance

Implement RBAC and entitlement‑aware access.
Ensure compliance with security, privacy, and regulatory standards.
Partner with Governance and Architecture to enforce enterprise policies.


Project & Resource Leadership

Plan and manage multiple API engineering projects.
Coordinate across teams to meet financial services and compliance requirements.
Balance development and operational support demands.


Collaboration Across Platforms

Work with Data Architecture, Ingestion, Mastering, and Integrated Data teams.
Onboard application and analytics consumers to platform services.
Translate business needs into scalable platform capabilities.


AI-Assisted Engineering

Use GitHub Copilot and AI tooling to accelerate delivery, standardize code, and improve testing, documentation, and refactoring.
Promote responsible, effective AI adoption across engineering teams.


Operational Excellence

Maintain 24x7 availability, performance, and reliability for APIs and data services.
Implement robust observability (logging, metrics, tracing).
Participate in incident response, RCA, and continuous improvement.
Maintain runbooks and operational documentation; meet all SLAs.","What You Will Need:



Technical Expertise

Bachelor’s degree required; Master’s preferred.
5–7+ years in software/data engineering with production APIs and data services.
Experience operating systems with defined SLAs in regulated environments.
Strong AWS background: API Gateway, Lambda, ECS/EKS, DynamoDB, Aurora, S3, Iceberg.
Hands-on Redis/ElastiCache and in-memory caching experience.
Strong API security, authentication, authorization knowledge.
CI/CD and modern DevOps experience.
Experience with REST, GraphQL (including federation/schema management).
Expertise with Kinesis, Kafka/MSK, streaming, and event-driven architectures.
Understanding of data modeling, canonical data patterns, contracts, and versioning.
Experience supporting operational consumers and governed APIs for analytics/AI/ML.
Exposure to data mesh, domain-oriented access, real-time architectures, and migration/modernization.


Engineering Practices

Solid fundamentals: design patterns, testing, code quality.
Experience with observability, debugging, and production support.
Ability to diagnose complex reliability and performance issues.


Financial Services Knowledge

Deep understanding of financial services data, compliance, and transactional flows.
Broker‑dealer and wealth management experience preferred.


Operational Excellence

Background managing large-scale 24x7 operational data systems.
Established incident management and escalation processes.
Experience optimizing ODS performance and availability.


Communication & Collaboration

Excellent problem-solving and communication skills.
Ability to explain technical topics to business and leadership stakeholders.
Strong collaboration mindset across platforms and teams.


What Will Stand Out

Financial Services certifications (SIE, Series‑99, etc.)
AWS certifications (Solutions Architect preferred, Data Analytics, API/GraphQL training","Bachelor’s degree required ; 5–7+ years in software/data engineering with production APIs and data services.
Experience operating systems with defined SLAs in regulated environments.
Strong AWS background: API Gateway, Lambda, ECS/EKS, DynamoDB, Aurora, S3, Iceberg.
Hands-on Redis/ElastiCache and in-memory caching experience.
Strong API security, authentication, authorization knowledge.
CI/CD and modern DevOps experience.
Experience with REST, GraphQL (including federation/schema management).
Expertise with Kinesis, Kafka/MSK, streaming, and event-driven architectures.
Understanding of data modeling, canonical data patterns, contracts, and versioning.
Experience supporting operational consumers and governed APIs for analytics/AI/ML.
Exposure to data mesh, domain-oriented access, real-time architectures, and migration/modernization.


Engineering Practices

Solid fundamentals: design patterns, testing, code quality.
Experience with observability, debugging, and production support.
Ability to diagnose complex reliability and performance issues.


Financial Services Knowledge

Deep understanding of financial services data, compliance, and transactional flows.
Broker‑dealer and wealth management experience preferred.


Operational Excellence

Background managing large-scale 24x7 operational data systems.
Established incident management and escalation processes.
Experience optimizing ODS performance and availability.


Communication & Collaboration

Excellent problem-solving and communication skills.
Ability to explain technical topics to business and leadership stakeholders.
Strong collaboration mindset across platforms and teams.","Master’s preferred, What Will Stand Out

Financial Services certifications (SIE, Series‑99, etc.)
AWS certifications (Solutions Architect preferred, Data Analytics, API/GraphQL training)","$111,000 - $148,000"
51,Saketh Thippireddy ,,LinkedIN,Lead Software Engineer Full Stack,Full time,Capital One,"Plano, TX",hybrid,,https://www.linkedin.com/jobs/search-results/?currentJobId=4367269455&eBP=CwEAAAGcYNkOVawqsyV9c4iH_rhQ08iiHNBKrQdzuIPE-neKjAse8Xqz3oi2NffTv_8aPKW3xfPUuCsChuyM67OaKyCQ9rJlaYqeKL48I2QMLyFF-582Tmh7QSnUyJDu40C36WnIOMySVHhWQgOSShztYmvN9VoTEVESx8DPKlApKIgS0TUmTC-wa8teaA35JX5FWvNeZFnJDK18sGDkRYuKorKMZW7SuQhaZDB2GptxwakwS9_KRDNpHCnSAm1yWOHpM0XH-_zN3KPiac4-5ob84Fy1iCzJ2DIMXeI4fS4wKbErDnuOinBktpVwI3l3HUj0B0XsD62wXkRAJQA8124EhOGtUHTnexD5otvRXeGOMxT3J95hJOl6TteabweEwxnYm06FS4sfZOKGuXR3UyeJQZ8Lle0ZpKYRQXzkHU8Q00Yrk4yRS46m7IN0-23WQ2_YZOsGpArb52KSrUsfbaYVBLPeMeFsDm_6MWRExe17ea1yCcl0dqPe2qijSMo2t95QPGMdTN9yr0bFvCUNqkZh4W_TQfDRmw&refId=ldIIEcOJD8kWlAY0K0VkPw%3D%3D&trackingId=fcILAS47BcL1aImzcWvYlw%3D%3D&keywords=software%20engineer&origin=SEMANTIC_SEARCH_LANDING_PAGE,"Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs.

We are seeking Full Stack Software Engineers who are passionate about marrying data with emerging technologies. As a Capital One Lead Software Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.",bachelor’s,5,"Lead a portfolio of diverse technology projects and a team of developers with deep experience in distributed microservices, and full stack systems to create solutions that help meet regulatory needs for the company
Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, mentoring other members of the engineering community
Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
Utilize programming languages like JavaScript, Java, HTML/CSS, TypeScript, SQL, Python, and Go, Open Source RDBMS and NoSQL databases, Container Orchestration services including Docker and Kubernetes, and a variety of AWS tools and services ","Basic Qualifications: 

Bachelor’s Degree
At least 4 years of experience in software engineering (Internship experience does not apply)
At least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud)

Preferred Qualifications:

Master's Degree
7+ years of experience in at least one of the following: JavaScript, Java, SpringBoot, TypeScript, SQL, Python, or Go
3+ years of experience with AWS, GCP, Microsoft Azure, or another cloud service
4+ years of experience in open source frameworks
1+ years of people management experience
2+ years of experience in Agile practices","Bachelor’s Degree
At least 4 years of experience in software engineering (Internship experience does not apply)
At least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud)","Master's Degree
7+ years of experience in at least one of the following: JavaScript, Java, SpringBoot, TypeScript, SQL, Python, or Go
3+ years of experience with AWS, GCP, Microsoft Azure, or another cloud service
4+ years of experience in open source frameworks
1+ years of people management experience
2+ years of experience in Agile practices","$179,400 - $204,700"
52,Pavithra Ramamoorthy,,Linkedin,Business Strategy Analyst – Mid Level – Member Experience Analytics,Full time,USAA,"Phoenix, AZ",hybrid,02/14/2026,https://www.linkedin.com/jobs/view/business-strategy-analyst-%E2%80%93-mid-level-%E2%80%93-member-experience-analytics-at-usaa-4364565572?position=1&pageNum=0&refId=2tLBeUfBZ8%2BaoX%2BNWqWqYg%3D%3D&trackingId=E8FARtR0ofUq%2FOh9Wtwxwg%3D%3D,"As a Business Strategy Analyst focused on Member Experience Analytics, you will define and implement instrumentation for end-to-end member experience analytics. Your responsibilities include designing how member interactions are captured across channels, transforming this data into actionable insights via visualization and reporting. You will collaborate with business leaders to understand business questions, define key performance indicators (KPIs) and the precise data instrumentation requirements necessary to measure them effectively. This role leverages your analytical and data instrumentation design skills to shape member experience with data-driven insights.",bachelor's,4+ years,"Your responsibilities include designing how member interactions are captured across channels, transforming this data into actionable insights via visualization and reporting. You will collaborate with business leaders to understand business questions, define key performance indicators (KPIs) and the precise data instrumentation requirements necessary to measure them effectively. This role leverages your analytical and data instrumentation design skills to shape member experience with data-driven insights.","What You Have Bachelor’s Degree in Business, Science, Finance, Economics or related discipline; OR 4 years of related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree. 4 years experience in data and/or analytics or strategy consulting; OR Advanced Degree in Business, Science, Finance, Economics or related discipline with 2 years experience in data and/or analytics or strategy consulting. Experience identifying business needs and developing strategic plans driven by qualitative/quantitative analysis and market insights. Demonstrated experience using data analytics to formulate data-driven insights. Experience performing data analysis using various data analytics tools (i.e. Microsoft Excel, Tableau, R, Python, SQL, Snowflake, SAS, Adobe Analytics). Experience in project management. What Sets You Apart Prior U.S. military service or being a military spouse/domestic partner is highly valued. Conceptualize, map and design data requirements for cross-channel member experiences. Translate business questions into metrics that accurately reflect experience performance. Identify and resolve data integration challenges and discrepancies. Collaborate effectively with IT, marketing, sales, and operations teams to ensure data instrumentation aligns with business needs.","Bachelor’s Degree in Business, Science, Finance, Economics or related discipline; OR 4 years of related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree. 4 years experience in data and/or analytics or strategy consulting; OR Advanced Degree in Business, Science, Finance, Economics or related discipline with 2 years experience in data and/or analytics or strategy consulting. Experience identifying business needs and developing strategic plans driven by qualitative/quantitative analysis and market insights. Demonstrated experience using data analytics to formulate data-driven insights. Experience performing data analysis using various data analytics tools (i.e. Microsoft Excel, Tableau, R, Python, SQL, Snowflake, SAS, Adobe Analytics). Experience in project management.","Prior U.S. military service or being a military spouse/domestic partner is highly valued. Conceptualize, map and design data requirements for cross-channel member experiences. Translate business questions into metrics that accurately reflect experience performance. Identify and resolve data integration challenges and discrepancies. Collaborate effectively with IT, marketing, sales, and operations teams to ensure data instrumentation aligns with business needs.","$85,040 - $162,550"
53,Pavithra Ramamoorthy,,Linkedin,Data Scientist Senior - AI/ ML,Full time,USAA,"Tampa, Florida",hybrid,2/13/2026,https://www.linkedin.com/jobs/view/data-scientist-senior-ai-ml-at-usaa-4363994573?position=14&pageNum=0&refId=nb2LoNdHBAp1nuIFVesHVw%3D%3D&trackingId=YgJGU%2FmYldbIHX64rePptQ%3D%3D,"Why USAA? At USAA, our mission is to empower our members to achieve financial security through highly competitive products, exceptional service and trusted advice. We seek to be the #1 choice for the military community and their families. Embrace a fulfilling career at USAA, where our core values – honesty, integrity, loyalty and service – define how we treat each other and our members. Be part of what truly makes us special and impactful. The Opportunity The Bank AI/ML team is looking to fill several Senior Data Science positions. Candidates with backgrounds in model development for credit risk, marketing, or everyday banking are preferred. As a dedicated Data Scientist Senior you will translate business problems into applied statistical, machine learning, simulation, and optimization solutions to advise actionable business insights and drive business value through automation, revenue generation, and expense and risk reduction. In collaboration with engineering partners, delivers solutions at scale, and enables customer-facing applications. Leverages database, cloud, and programming knowledge to build analytical modeling solutions using statistical and machine learning techniques. Collaborates with other data scientists to improve USAA’s tooling, growing the company’s library of internal packages and applications. Works with model risk management to validate the results and stability of models before being pushed to production at scale.",bachelor's,6+ years,"Gathers, interprets, and manipulates structured and unstructured data to enable advanced analytical solutions for the business. Develops scalable, automated solutions using machine learning, simulation, and optimization to deliver business insights and business value. Selects the appropriate modeling technique and/or technology with consideration to data limitations, application, and business needs. Develops and deploys models within the Model Development Control (MDC) and Model Risk Management (MRM) framework. Composes, and assists peers with composing, technical documents for knowledge persistence, risk management, and technical review audiences. Assesses business needs to propose/recommend analytical and modeling projects to add business value. Works with business and analytics leaders to prioritize analytics and modeling problems/research efforts. Builds and maintains a robust library of reusable, production-quality algorithms and supporting code, to ensure model development and research efforts are transparent and based on the highest quality data. Translates complex business request(s) into specific analytical questions, executes on the analysis and/or modeling, and then communicates outcomes to non-technical business colleagues with focus on business action and recommendations. Manages project milestones, risks, and impediments. Escalates potential issues that could limit project success or implementation. Develops best practices for engaging with Data Engineering and IT to deploy production-ready analytical assets consistent with modeling best practices and model risk management standards. Maintains expertise and awareness of cutting-edge techniques. Actively seeks opportunities and materials to learn new techniques, technologies, and methodologies. Serves as a mentor to junior data scientists in modeling, analytics, and computer science tasks. Participates in internal communities that drive the maintenance and transformation of data science technologies and culture. Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled in accordance with risk and compliance policies and procedures.","What You Have Bachelor’s degree in mathematics, computer science, statistics, economics, finance, actuarial sciences, science and engineering, or other similar quantitative discipline; OR 4 years of experience in statistics, mathematics, quantitative analytics, or related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree. 6 years of experience in a predictive analytics or data analysis OR Advanced Degree (e.g., Master’s, PhD) in mathematics, computer science, statistics, economics, finance, actuarial sciences, science and engineering, or other similar quantitative discipline and 4 years of experience in predictive analytics or data analysis. 4 years of experience in training and validating statistical, physical, machine learning, and other advanced analytics models. 4 years of experience in one or more dynamic scripted language (such as Python, R, etc.) for performing statistical analyses and/or building and scoring AI/ML models. Proven experience writing code that is easy to follow, well documented, and commented where necessary to explain logic (high code transparency). Strong experience in querying and preprocessing data from structured and/or unstructured databases using query languages such as SQL, HQL, NoSQL, etc. Strong experience in working with structured, semi-structured, and unstructured data files such as delimited numeric data files, JSON/XML files, and/or text documents, images, etc. Demonstrated skill in performing ad-hoc analytics using descriptive, diagnostic, and inferential statistics. Ability to assess and articulate regulatory implications and expectations of distinct modeling efforts. Advanced experience with the concepts and technologies associated with classical supervised modeling for prediction such as linear/logistic regression, discriminant analysis, support vector machines, decision trees, forest models, etc. Advanced experience with the concepts and technologies associated with unsupervised modeling such as k-means clustering, hierarchical/agglomerative clustering, neighbors algorithms, DBSCAN, etc. Experience guiding and mentoring junior technical staff in business interactions and model building. Experience communicating analytical and modeling results to non-technical business partners with emphasis on business recommendations and actionable applications of results. What Sets You Apart Medium or large bank experience. Strong knowledge of Python and/or SAS. Control partner collaboration experience. Knowledge of Model Risk Management, Model Governance, and Regulatory requirements.","Bachelor’s degree in mathematics, computer science, statistics, economics, finance, actuarial sciences, science and engineering, or other similar quantitative discipline; OR 4 years of experience in statistics, mathematics, quantitative analytics, or related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree. 6 years of experience in a predictive analytics or data analysis OR Advanced Degree (e.g., Master’s, PhD) in mathematics, computer science, statistics, economics, finance, actuarial sciences, science and engineering, or other similar quantitative discipline and 4 years of experience in predictive analytics or data analysis. 4 years of experience in training and validating statistical, physical, machine learning, and other advanced analytics models. 4 years of experience in one or more dynamic scripted language (such as Python, R, etc.) for performing statistical analyses and/or building and scoring AI/ML models. Proven experience writing code that is easy to follow, well documented, and commented where necessary to explain logic (high code transparency). Strong experience in querying and preprocessing data from structured and/or unstructured databases using query languages such as SQL, HQL, NoSQL, etc. Strong experience in working with structured, semi-structured, and unstructured data files such as delimited numeric data files, JSON/XML files, and/or text documents, images, etc. Demonstrated skill in performing ad-hoc analytics using descriptive, diagnostic, and inferential statistics. Ability to assess and articulate regulatory implications and expectations of distinct modeling efforts. Advanced experience with the concepts and technologies associated with classical supervised modeling for prediction such as linear/logistic regression, discriminant analysis, support vector machines, decision trees, forest models, etc. Advanced experience with the concepts and technologies associated with unsupervised modeling such as k-means clustering, hierarchical/agglomerative clustering, neighbors algorithms, DBSCAN, etc. Experience guiding and mentoring junior technical staff in business interactions and model building. Experience communicating analytical and modeling results to non-technical business partners with emphasis on business recommendations and actionable applications of results.","Medium or large bank experience. Strong knowledge of Python and/or SAS. Control partner collaboration experience. Knowledge of Model Risk Management, Model Governance, and Regulatory requirements.","$143,320 - $273,930"
54,Pavithra Ramamoorthy,,Linkedin,Intermediate Level Decision Science Analyst - Member Value,Full time,USAA,"San Anotonio, TX",hybrid,2/14/2026,https://www.linkedin.com/jobs/view/intermediate-level-decision-science-analyst-member-value-at-usaa-4371900017?position=8&pageNum=0&refId=xWHVD%2BbBQ1JpPPpPhO2gdw%3D%3D&trackingId=HZM6iJq5W5HOP60fhha5Aw%3D%3D,"Why USAA? At USAA, our mission is to empower our members to achieve financial security through highly competitive products, exceptional service and trusted advice. We seek to be the #1 choice for the military community and their families. Embrace a fulfilling career at USAA, where our core values – honesty, integrity, loyalty and service – define how we treat each other and our members. Be part of what truly makes us special and impactful. The Opportunity As a dedicated Intermediate Level Decision Science Analyst - Member Value, you will join our Member Value and will be instrumental in transforming member service experiences through in-depth, end-to-end analytics. You will uncover critical insights to drive higher member satisfaction and value, refine service strategies, and optimize performance. You will collaborate with business leaders, apply advanced analytical techniques, and translate complex data into clear, actionable recommendations that drive significant change. This is a unique opportunity to apply your analytical expertise and shape the future of member experience with data-driven insights. Provide decision support for business areas across the association. Staff in this area will be responsible for applying mathematical and statistical techniques and/or innovative /quantitative analytical approaches to draw conclusions and make 'insight to action' recommendations to answer business objectives and drive change. The essence of work performed by the Decision Science Analyst involves gathering, manipulating and synthesizing data (e.g., attributes, transactions, behaviors, etc.), models and other relevant information to draw conclusions and make recommendations resulting in implementable strategies.",bachelor's,4+ years,"Leverages intermediate business, analytical and technical knowledge to participate in discussions with cross functional teams to understand and collaborate on business objectives and influence solution strategies. Applies advanced analytical techniques to solve business problems that are typically medium to large scale with impact to current and/or future business strategy. Applies scientific/quantitative analytical approaches to draw conclusions and make 'insight to action' recommendations to answer the business objective and drive the appropriate change. Translates recommendation into communication materials to effectively present to colleagues for peer review and senior/lead analysts. Incorporates visualization techniques to support the relevant points of the analysis and ease the understanding for less technical audiences. Supports identifying and gathering the relevant and quality data sources required to fully answer and address the problem for the recommended strategy through testing or exploratory data analysis (EDA). Thoroughly documents assumptions, methodology, validation and testing to facilitate peer reviews and compliance requirements. Adopts emerging technology that can affect the application of scientific methodologies and/or quantitative analytical approaches to problem resolutions. Delivers analysis/findings in a manner that conveys understanding, influences up to mid level management, garners support for recommendations, drives business decisions, and influences business strategy. Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled in accordance with risk and compliance policies and procedures.","What You Have Bachelor's degree in quantitative analytics field such as Economics, Finance, Statistics, Mathematics, Actuarial Sciences, Operations Research, Data and/or Business Analysis, Data Science or other quantitative field; OR 4 years of related experience in statistics, mathematics or quantitative analytics (in addition to the minimum years of experience required) may be substituted in lieu of degree. 2 years of experience in data/analytics or functional business experience within the respective industry of responsibility (i.e. P&C, Bank, Finance) OR Advanced degree in quantitative analytics field such as Economics, Finance, Statistics, Mathematics, Actuarial Sciences, Operations Research, Data and/or Business Analysis, Data Science or other quantitative field. Demonstrates intermediate knowledge of mathematical and statistical techniques and approaches used to drive fact-based decision-making. Intermediate knowledge of data analysis tools, data visualization, developing analysis queries and procedures in SQL, SAS, BI tools or other analysis software, and relevant industry data & methods and ability to connect external insights to business problems. What Sets You Apart Prior U.S. military service or being a military spouse/domestic partner is highly valued. An advanced degree in a quantitative field such as Economics, Finance, Statistics, Mathematics, Operations Research, Data Analysis, Data Science, or a related area. An aptitude for learning and applying analytical techniques to explore data and identify trends. Exposure to data visualization tools (e.g., Tableau) for reporting. Ability to explain findings simply and clearly. A proactive and curious mindset, eager to learn and contribute to strategic initiatives.","Bachelor's degree in quantitative analytics field such as Economics, Finance, Statistics, Mathematics, Actuarial Sciences, Operations Research, Data and/or Business Analysis, Data Science or other quantitative field; OR 4 years of related experience in statistics, mathematics or quantitative analytics (in addition to the minimum years of experience required) may be substituted in lieu of degree. 2 years of experience in data/analytics or functional business experience within the respective industry of responsibility (i.e. P&C, Bank, Finance) OR Advanced degree in quantitative analytics field such as Economics, Finance, Statistics, Mathematics, Actuarial Sciences, Operations Research, Data and/or Business Analysis, Data Science or other quantitative field. Demonstrates intermediate knowledge of mathematical and statistical techniques and approaches used to drive fact-based decision-making. Intermediate knowledge of data analysis tools, data visualization, developing analysis queries and procedures in SQL, SAS, BI tools or other analysis software, and relevant industry data & methods and ability to connect external insights to business problems.","Prior U.S. military service or being a military spouse/domestic partner is highly valued. An advanced degree in a quantitative field such as Economics, Finance, Statistics, Mathematics, Operations Research, Data Analysis, Data Science, or a related area. An aptitude for learning and applying analytical techniques to explore data and identify trends. Exposure to data visualization tools (e.g., Tableau) for reporting. Ability to explain findings simply and clearly. A proactive and curious mindset, eager to learn and contribute to strategic initiatives.","$77,120.00 - $147,390.00"
55,Peyton Kocher,,Linkedin,Data Analyst / Engineer,Full time,Quest Global,"Sunnyvale, CA",onsite,02/14/2026,https://www.linkedin.com/jobs/search-results/?currentJobId=4372058043&eBP=NON_CHARGEABLE_CHANNEL&refId=SAjh%2BB%2FQoROR1chjFOPrXg%3D%3D&trackingId=rfKuS6BcOaRH%2BtDCjDOJ1A%3D%3D&keywords=data%20science%20jobs&origin=BLENDED_SEARCH_RESULT_NAVIGATION_JOB_CARD&originToLandingJobPostings=4290979040%2C4363247453%2C4365156290,"About the job
Job Requirements

POSITION: Data Analyst / Engineer

Who We Are

Quest Global delivers world-class end-to-end engineering solutions by leveraging our deep industry knowledge and digital expertise. By bringing together technologies and industries, alongside the contributions of diverse individuals and their areas of expertise, we are able to solve problems better, faster. This multi-dimensional approach enables us to solve the most critical and large-scale challenges across the aerospace & defense, automotive, energy, hi-tech, healthcare, medical devices, rail and semiconductor industries.

We are looking for humble geniuses, who believe that engineering has the potential to make the impossible possible; innovators, who are not only inspired by technology and innovation, but also perpetually driven to design, develop, and test as a trusted partner for Fortune 500 customers. As a team of remarkably diverse engineers, we recognize that what we are really engineering is a brighter future for us all. If you want to contribute to meaningful work and be part of an organization that truly believes when you win, we all win, and when you fail, we all learn, then we’re eager to hear from you. The achievers and courageous challenge-crushers we seek, have the following characteristics and skills

What You Will Do

Perform root cause analysis on processes and data to identify opportunities for improvement and answer questions
Build processes that support data transformation, workload management, data structures, dependency and metadata
Perform data validation checks, identify and rectifying errors, and maintaining a quality standard throughout the data's lifecycle. 
Explore datasets to identify trends, patterns, and insights. 
Perform analysis for stakeholders and other non-technical professionals. Build models to generate actionable insights for making efficient business decisions. ‍
Build data pipelines that clean, transform, and aggregate data from disparate sources
Work with data to solve business problems, building and maintaining the infrastructure to answer questions and improve processes
Streamline data science workflows, adding value to our product offerings and building out the customer lifecycle and retention models
Primary skills - Must have: Snowflake, Tableau, SQL
Secondary: Python 
Other skills: DBT, ETL etc..,
Great communication
Work with business teams 

What You Will Bring

Create and improve data visualization tools like Tableau & ThoughtSpot
Work with Snowflake & it’s built in infrastructure, SQL, Python, Excel, & Numbers
Experience presentation/project management Tools like Quip, Keynote, Miro, Slack
Experience and understanding of machine learning tools like datarobot 
Project Management experience
to provide support to a wide variety of business teams
Good Interpersonal, relationship building, communication and presentation skills

Pay Range: $105000 - $110000 per annum

Compensation decisions are made based on factors including experience, skills, education, and other job-related factors, in accordance with our internal pay structure. We also offer a comprehensive benefits package, including health insurance, paid time off, and retirement plan.

Work Requirements

This role is considered an on-site position located in Sunnyvale, CA, USA

You must be able to commute to and from the location with your own transportation arrangements to meet the required working hours. 
Shop floor environment, which may include but not limited to extensive walking, and ability to lift up to 40 lbs. 

Benefits Begin On Day One

401(k) matching
Dental insurance
Health insurance
Paid time off
Vision insurance
Employer paid Life Insurance, Short- & Long-Term Disability

Work Experience

Primary skills - Must have: Snowflake, Tableau, SQL
Secondary: Python 
Other skills: DBT, ETL etc..,
Great communication
Work with business teams 

Benefits

Applicable ones
",,0,"Perform root cause analysis on processes and data to identify opportunities for improvement and answer questions
Build processes that support data transformation, workload management, data structures, dependency and metadata
Perform data validation checks, identify and rectifying errors, and maintaining a quality standard throughout the data's lifecycle. 
Explore datasets to identify trends, patterns, and insights. 
Perform analysis for stakeholders and other non-technical professionals. Build models to generate actionable insights for making efficient business decisions. ‍
Build data pipelines that clean, transform, and aggregate data from disparate sources
Work with data to solve business problems, building and maintaining the infrastructure to answer questions and improve processes
Streamline data science workflows, adding value to our product offerings and building out the customer lifecycle and retention models
Primary skills - Must have: Snowflake, Tableau, SQL
Secondary: Python 
Other skills: DBT, ETL etc..,
Great communication
Work with business teams ","
Create and improve data visualization tools like Tableau & ThoughtSpot
Work with Snowflake & it’s built in infrastructure, SQL, Python, Excel, & Numbers
Experience presentation/project management Tools like Quip, Keynote, Miro, Slack
Experience and understanding of machine learning tools like datarobot 
Project Management experience
to provide support to a wide variety of business teams
Good Interpersonal, relationship building, communication and presentation skills","You must be able to commute to and from the location with your own transportation arrangements to meet the required working hours. 
Shop floor environment, which may include but not limited to extensive walking, and ability to lift up to 40 lbs. ",Not Specified,"$105,000 - $110,000"
56,Peyton Kocher,,Linkedin,Data Scientist I,Full time,Plainview,"Austin, TX",onsite,02/08/2026,https://www.linkedin.com/jobs/search-results/?currentJobId=4352514498&eBP=NON_CHARGEABLE_CHANNEL&refId=SAjh%2BB%2FQoROR1chjFOPrXg%3D%3D&trackingId=ussYuKyIETNxnOmJ6LL%2BzA%3D%3D&keywords=data%20science%20jobs&origin=BLENDED_SEARCH_RESULT_NAVIGATION_JOB_CARD&originToLandingJobPostings=4290979040%2C4363247453%2C4365156290,"Join our team as a Data Scientist to help integrate data science capabilities within Planview's project management and planning solutions. You will contribute to data collection and analysis, build predictive models, and work with Generative AI technologies.",master's,0,"
AI Engineering: Design and implement AI-powered features to enhance project planning and resource management. Work with Large Language Models and generative AI to automate workflows and provide intelligent recommendations to users.
Data Engineering: Extract, transform, and derive features from raw data to improve machine learning model performance.
Predictive Modeling: Build, test, and refine models to predict task completion times and project outcomes.
Collaboration: Work closely with cross-functional teams including product managers, engineers, and fellow data scientists to integrate solutions into our products.
","What You'll Bring

Required Qualifications:

Master's degree in Industrial Engineering, Operations Research, Statistics, Data Science, or a related field.
Proficiency in Python and SQL, along with familiarity with libraries such as pandas and scikit-learn.
Demonstrated experience in translating customer challenges into data-driven product enhancements.
Strong knowledge of machine learning algorithms and statistical methodologies.
Strong written and verbal communication skills.

Preferred Qualifications:

Familiarity with project management frameworks like Agile, Scrum, or Waterfall.
Hands-on experience with AWS tools such as Athena, SageMaker, and Bedrock.
Experience building with Large Language Models
Basic understanding of knowledge graphs and ontologies","Master's degree in Industrial Engineering, Operations Research, Statistics, Data Science, or a related field.
Proficiency in Python and SQL, along with familiarity with libraries such as pandas and scikit-learn.
Demonstrated experience in translating customer challenges into data-driven product enhancements.
Strong knowledge of machine learning algorithms and statistical methodologies.
Strong written and verbal communication skills.","Familiarity with project management frameworks like Agile, Scrum, or Waterfall.
Hands-on experience with AWS tools such as Athena, SageMaker, and Bedrock.
Experience building with Large Language Models
Basic understanding of knowledge graphs and ontologies",Not specified
57,Peyton Kocher,,Linkedin,ML/AI  Engineer,Full time,AMD,"Austin, TX",onsite,02/08/2026,https://www.linkedin.com/jobs/search-results/?currentJobId=4358081522&eBP=NON_CHARGEABLE_CHANNEL&refId=3wXwGkBN5PBrsK1uOcq4bw%3D%3D&trackingId=efGej%2FUXS16hDs9EhHznHQ%3D%3D&keywords=data%20science%20jobs&origin=BLENDED_SEARCH_RESULT_NAVIGATION_JOB_CARD&start=25,"About the job
WHAT YOU DO AT AMD CHANGES EVERYTHING

At AMD, our mission is to build great products that accelerate next-generation computing experiences—from AI and data centers, to PCs, gaming and embedded systems. Grounded in a culture of innovation and collaboration, we believe real progress comes from bold ideas, human ingenuity and a shared passion to create something extraordinary. When you join AMD, you’ll discover the real differentiator is our culture. We push the limits of innovation to solve the world’s most important challenges—striving for execution excellence, while being direct, humble, collaborative, and inclusive of diverse perspectives. Join us as we shape the future of AI and beyond. Together, we advance your career. 

The Role

The candidate is a technical expert in Machine Learning (ML) and Artificial Intelligence (AI) tool development, ML/AI model deployment, and quality control. The candidate works within our AI engineering team to automate data analytics, identifies opportunities for ML and AI applications, develops ML/AI models, monitors the output data quality in production environments.",bachelor's,0,"Develop, deploy, and test ML/AI software tools. 
Use Python, JavaScript, and C++ to create a faster, more capable AI. 
Conduct data analytics and statistical analysis, develop algorithms and automation scripts. 
Work with AMD AI engineering team to ensure seamless AI development and integration. 
Use AI analysis to make strategy recommendations that align with the team’s goals. 
Stay current on AI knowledge, trends, and regulations. 
Collect, organize, and present progress with team leadership and stakeholders. 
","The Role

The candidate is a technical expert in Machine Learning (ML) and Artificial Intelligence (AI) tool development, ML/AI model deployment, and quality control. The candidate works within our AI engineering team to automate data analytics, identifies opportunities for ML and AI applications, develops ML/AI models, monitors the output data quality in production environments.

The Person

The ideal candidate will have a strong understanding of machine learning, principles of statistical analysis and algorithms, as well as experience with developing and deploying ML/AI models in production.

PREFERRED EXPERIENCE And SKILLS
In-depth knowledge of computer programming languages, such as Python, JavaScript, and C++. 
Deep understanding of data science, linear algebra, algorithms, and statistics. 
Experience developing and deploying machine learning. 
Practical knowledge of neural networks and data science 
Experience with PyTorch, Tensorflow and Python packages, such as NumPy 
(Plus) Experience with web development using Javascript and frameworks such Flask, Angular, ASP.Net Core, etc. 
(Plus) Experience using relational (SQL) and noSQL databases. 
Excellent problem-solving skills with the ability to thrive in a demanding, fast-paced work environment. 
Strong interpersonal and communication skills and a willingness s to collaborate with different functional teams. 
","The candidate is a technical expert in Machine Learning (ML) and Artificial Intelligence (AI) tool development, ML/AI model deployment, and quality control. The candidate works within our AI engineering team to automate data analytics, identifies opportunities for ML and AI applications, develops ML/AI models, monitors the output data quality in production environments.


The ideal candidate will have a strong understanding of machine learning, principles of statistical analysis and algorithms, as well as experience with developing and deploying ML/AI models in production.","In-depth knowledge of computer programming languages, such as Python, JavaScript, and C++. 
Deep understanding of data science, linear algebra, algorithms, and statistics. 
Experience developing and deploying machine learning. 
Practical knowledge of neural networks and data science 
Experience with PyTorch, Tensorflow and Python packages, such as NumPy 
(Plus) Experience with web development using Javascript and frameworks such Flask, Angular, ASP.Net Core, etc. 
(Plus) Experience using relational (SQL) and noSQL databases. 
Excellent problem-solving skills with the ability to thrive in a demanding, fast-paced work environment. 
Strong interpersonal and communication skills and a willingness s to collaborate with different functional teams. ","$118,800 - $178,200"
58,David Garudo,,Indeed,Data Scientist,Full time,Ferrovial,"Austin, TX",onsite,,https://www.indeed.com/viewjob?jk=efb9c2a3fcf2bca8&tk=1jhh63eg622jk02e&from=serp&vjs=3,"Objective: Develop your data driven skills to optimize our current operations and develop analysis to increase our knowledge for new development. Utilizing advanced analytics, you will work with the best in industry to optimize revenue and improve accuracy of Cintra and our concessions. Develop and generate new ideas/projects for using Advanced Analytics with the two strategic goals: Optimizing revenues in existing projects in operations. Improving accuracy of Traffic and Revenue forecasts by using new data sources and techniques to improve knowledge of main variables affecting the forecasts. Develop, lead, and execute Data Analytics projects used either for Business Development activities (analysis of new projects) or for optimization of projects in Operations. Support Advanced Analytic projects conducted by analytics teams at Cintra’s major projects (407 ETR in Toronto and DFW managed lanes). Support Cintra Europe and North American Traffic & Revenue teams when using Advanced Analytics for Traffic & Revenue studies. Stay informed of new developments in Advanced Analytic techniques, systems, data sources, and providers and explore how to utilize them for the benefit of Cintra",masters,5+,"Develop and generate new ideas/projects for using Advanced Analytics with the two strategic goals:

, Optimizing revenues in existing projects in operations, Improving accuracy of Traffic and Revenue forecasts by using new data sources and techniques to improve knowledge of main variables affecting the forecasts, Develop, lead, and execute Data Analytics projects used either for Business Development activities (analysis of new projects) or for optimization of projects in Operations

, Support Advanced Analytic projects conducted by analytics teams at Cintra’s major projects (407 ETR in Toronto and DFW managed lanes)

Support Cintra Europe and North American Traffic & Revenue teams when using Advanced Analytics for Traffic & Revenue studies

Stay informed of new developments in Advanced Analytic techniques, systems, data sources, and providers and explore how to utilize them for the benefit of Cintra","Master’s degree in a quantitative field such as Operations Research, Data Science, Statistics, Civil or Industrial Engineering, Proficiency in Advanced Analytic Techniques, High level of skill in SQL and/or Spark to process

Experience in R and/or Python in implementing data science packages/routines

Experience in Databases

Knowledge with designing data visualizations and the utilization of software such as Tableau

Ethical, caring and with the ability to work in a collaborative environment","Master’s degree in a quantitative field such as Operations Research, Data Science, Statistics, Civil or Industrial Engineering, Proficiency in Advanced Analytic Techniques, High level of skill in SQL and/or Spark to process

Experience in R and/or Python in implementing data science packages/routines

Experience in Databases

Knowledge with designing data visualizations and the utilization of software such as Tableau

Ethical, caring and with the ability to work in a collaborative environment",,Not Listed
59,David Garudo,,Indeed,AI Data Scientist,Full time,HP,"Spring, TX",onsite,,https://www.indeed.com/viewjob?jk=6fd0d806d111523f&tk=1jhh63eg622jk02e&from=serp&vjs=3,"The HP Enterprise AI & Machine Learning organization is a centralized team of data scientists and machine learning engineers building GenAI-based tools and digital products that enable increased productivity for 50,000+ employees and improve the effectiveness of hundreds of critical business processes. We collaborate closely with business stakeholders across HP to scope, prototype, and develop models and products in the cloud and on the edge. We also serve as HP’s AI Center of Excellence, providing consulting assistance, reuseable components and frameworks, and training to other teams across the company.

As a Data Scientist focused on Generative AI, you will work across multiple HP projects involving large language and multi-model models and other cutting-edge Generative AI capabilities for deployment on the cloud or edge. In addition to working with our core technical team, you’ll collaborate with business stakeholders and across various units to develop and deploy solutions at scale. Your primary focus and mindset will be on delivering real business value to our internal customers. Please note, this is not a research role.",masters or phd,5+,"Delivers Generative AI-based models of high complexity to surface insights; drives action, defines success measures and tracks performance of models.
Develops monitoring metrics to reflect real-world model performance and makes recommendations to shape the future direction of models and digital solutions.
Strategizes models to uncover patterns and predictions creating business value and innovation.
Manages relationships with business partners to evaluate and foster data driven innovation, provides domain-specific expertise in cross-organization projects/initiatives.
Ties insights into effective visualizations communicating business value and innovation potential.
Works with development teams and business units to ensure models are scalable and can be implemented as part of the delivered solution.
Leads project team(s) of data science professionals, assuring insights are communicated regularly and effectively, reviewing designs, models and data compliance.
Represents the data science team for all phases of larger and more-complex development projects.
Provides guidance, training and mentoring to less experienced staff members.
","Education & Experience Recommended PhD related to AI or a Master’s degree in computer science or a related field and 5+ years of experience with GenAI and related technologies including machine learning. data analytics, and statistical modeling.

Preferred Certifications
Programming Language/s Certification (SQL, Python, or similar)

Knowledge & Skills
Strong foundation in data science and core machine learning concepts.

Experience with large language models, multi-modal modals, prompt engineering, vector databases, Retrieval-Augmented Generation (RAG), and search engines.

Solid technical background. Experience working on software development teams, especially in cloud-based business applications, is a strong plus.

Familiarity with tools such as Azure Machine Learning, Azure Prompt Flow, Python, LangChain, Streamlit, and Docker.

Experience working in distributed, diverse teams, with bonus points for time spent in small fast-paced start-ups.

Comfortable representing the team in meetings with multiple stakeholders and driving discussions clearly and respectfully. Mastery of English is required.

Able to explain technical concepts (e.g., LLMs) to non-technical audiences.

You suggest pragmatic solutions that are as simple as possible—even if that means no AI is required.

","Strong foundation in data science and core machine learning concepts.

Experience with large language models, multi-modal modals, prompt engineering, vector databases, Retrieval-Augmented Generation (RAG), and search engines.

Solid technical background. Experience working on software development teams, especially in cloud-based business applications, is a strong plus.

Familiarity with tools such as Azure Machine Learning, Azure Prompt Flow, Python, LangChain, Streamlit, and Docker.

Experience working in distributed, diverse teams, with bonus points for time spent in small fast-paced start-ups.

Comfortable representing the team in meetings with multiple stakeholders and driving discussions clearly and respectfully. Mastery of English is required.

Able to explain technical concepts (e.g., LLMs) to non-technical audiences.

You suggest pragmatic solutions that are as simple as possible—even if that means no AI is required.

","Programming Language/s Certification (SQL, Python, or similar)","130,700 - $205,200"
60,David Garudo,,Indeed,Data Modeller,Full time,NES Firecroft,"Houston, TX",onsite,,https://www.indeed.com/viewjob?jk=1a9e699ef936ebce&from=shareddesktop_copy,"The Trading Data Analytics discipline within the company Trading Analytics & Insights (TA&I) organization brings together Quantitative Analysts, Data Strategists, and Core Strategists (software engineers). United by a strong focus on data, numerical algorithms, and technology, the team delivers innovative models, tradable insights, and agile technology solutions that enhance commercial performance across Trading & Shipping.
This position sits within the Gas & Power Trading Americas – Fundamental Modeling and Innovation Team, offering a unique opportunity to partner closely with analysts and strategists across the North American region and multiple commodity lines. The role focuses on designing and building scalable, high‑impact analytical solutions to address business‑critical challenges in a fast‑paced, data‑rich trading environment.
",bachelors,3-5,"The Trading Data Analytics discipline within the company Trading Analytics & Insights (TA&I) organization brings together Quantitative Analysts, Data Strategists, and Core Strategists (software engineers). United by a strong focus on data, numerical algorithms, and technology, the team delivers innovative models, tradable insights, and agile technology solutions that enhance commercial performance across Trading & Shipping.
This position sits within the Gas & Power Trading Americas – Fundamental Modeling and Innovation Team, offering a unique opportunity to partner closely with analysts and strategists across the North American region and multiple commodity lines. The role focuses on designing and building scalable, high‑impact analytical solutions to address business‑critical challenges in a fast‑paced, data‑rich trading environment.
","Required Education

Bachelor’s degree in a STEM field or other quantitative discipline.
Essential Experience & Skills

3–5 years of hands-on experience building and deploying machine learning models and regressions.
Strong proficiency in Python, with deep knowledge of core data science libraries (e.g., pandas, numpy, scikit‑learn).
Proven experience working with large, complex datasets.
Excellent attention to detail and problem‑solving capabilities.
Demonstrated success collaborating with traders or business stakeholders to deliver commercially actionable models.
Independent, innovative thinker with the ability to develop new analytical methodologies and identify alternative solutions to complex problems.
Ability to thrive in a fast‑paced, dynamic trading environment.
Strong desire for continuous learning and innovation.
Desirable Experience & Skills

Knowledge of U.S. or North American energy markets, including low‑carbon, oil, gas, LNG, or power.
Understanding of supply and demand fundamentals and how related physical and financial instruments are traded.","Required Education

Bachelor’s degree in a STEM field or other quantitative discipline.
Essential Experience & Skills

3–5 years of hands-on experience building and deploying machine learning models and regressions.
Strong proficiency in Python, with deep knowledge of core data science libraries (e.g., pandas, numpy, scikit‑learn).
Proven experience working with large, complex datasets.
Excellent attention to detail and problem‑solving capabilities.
Demonstrated success collaborating with traders or business stakeholders to deliver commercially actionable models.
Independent, innovative thinker with the ability to develop new analytical methodologies and identify alternative solutions to complex problems.
Ability to thrive in a fast‑paced, dynamic trading environment.
Strong desire for continuous learning and innovation.
","Desirable Experience & Skills

Knowledge of U.S. or North American energy markets, including low‑carbon, oil, gas, LNG, or power.
Understanding of supply and demand fundamentals and how related physical and financial instruments are traded.","112,000-124,800"
61,Thomas Koch,,LinkedIn,Software Engineer III,Full time,Blue Origin,"Huntsville, AL",onsite,1 Week Ago,https://www.linkedin.com/jobs/view/4357598761/,"This role is part of the Blue Origin Engines business unit, where our focus is the design, development, manufacturing, and testing of engines and propulsion systems. Built for multiple uses, our family of engines is powering the next generation of rockets for commercial, civil, national security, and human spaceflight.

As a software engineer, you will apply your expertise to the aerospace applications of engineering design, manufacturing, supply chain, mission operations, and customer experience.","bachelor's in computer science, engineering or related field",5 years,"Design, develop, and maintain robust and scalable software using modern languages.
Implement and manage APIs, ensuring flawless integration and efficient performance across systems.
Deploy applications and services on AWS, using cloud-native architectures for high availability and fault tolerance.
Collaborate with cross-functional teams to define and refine system requirements and technical specifications.
Drive the adoption of best practices in code quality, testing, and maintainability.
Be responsible for the entire application lifecycle, from initial design to deployment, optimization, and maintenance.
Engage in code reviews, mentor junior developers, and cultivate a culture of shared learning.
Diagnose and resolve issues within existing software, tackling intricate technical challenges that emerge.
Stay informed with emerging technologies and industry trends, evaluating and adopting them as appropriate to meet business needs.","Minimum Qualifications

Bachelor’s degree in Computer Science, Engineering, or a related field; or equivalent work experience
Minimum of 5 years of software development experience, with a consistent track record in Python and TypeScript.
Development with Rust, C++, SQL, and other software languages.
Knowledge of AI/ML tools and models.
Experience with AWS cloud services and infrastructure as code (IaC) frameworks.
Experience in developing, deploying, and integrating APIs within a microservices architecture.
Experience maintaining DevOps cultures and setting up new continuous integration/continuous deployment (CI/CD) pipelines.
Familiarity with monitoring tools and performance optimization techniques.
Excellent problem-solving abilities and strong communication skills.
Ability to work independently as well as part of a collaborative team.
Experience building, shipping, and maintaining production applications.

Preferred Qualifications

AWS certifications or relevant cloud technology certifications.
Familiarity with containerization tools (e.g., Docker or equivalent experience) and orchestration systems (e.g., Kubernetes).
Experience with serverless computing and event-driven architectures.
Understanding of Agile methodologies.
Manufacturing and/or Aerospace experience.","Minimum Qualifications

Bachelor’s degree in Computer Science, Engineering, or a related field; or equivalent work experience
Minimum of 5 years of software development experience, with a consistent track record in Python and TypeScript.
Development with Rust, C++, SQL, and other software languages.
Knowledge of AI/ML tools and models.
Experience with AWS cloud services and infrastructure as code (IaC) frameworks.
Experience in developing, deploying, and integrating APIs within a microservices architecture.
Experience maintaining DevOps cultures and setting up new continuous integration/continuous deployment (CI/CD) pipelines.
Familiarity with monitoring tools and performance optimization techniques.
Excellent problem-solving abilities and strong communication skills.
Ability to work independently as well as part of a collaborative team.
Experience building, shipping, and maintaining production applications.","AWS certifications or relevant cloud technology certifications.
Familiarity with containerization tools (e.g., Docker or equivalent experience) and orchestration systems (e.g., Kubernetes).
Experience with serverless computing and event-driven architectures.
Understanding of Agile methodologies.
Manufacturing and/or Aerospace experience.","164,700 - 230,500"
62,Thomas Koch,,LinkedIn,Software Engineer,Full time,"Mission Technologies, divison of HII",Greater Roanoke Area,onsite,3 days ago,https://www.linkedin.com/jobs/view/4326509201/,"Candidates for this position will lead a team performing reverse engineering tasks on existing products and encoding discoveries directly into our codebase. Additional tasks involve the research, design, and development of innovative algorithms to automate challenging or time-consuming tasks within the reverse engineering domain. Candidates will be exposed to and become proficient with a variety of technologies involving hardware description languages, embedded instruction architectures, high-level software development languages, formal verification tools, and more. ",bachelors or masters,"5 years with Bachelors, 3 years with Masters, 0 years with PhD",Candidates for this position will be responsible for leading reverse engineering efforts into systems of interest and mentoring junior engineers in the reverse engineering and development processes. Candidates will be expected to communicate clearly and effectively and demonstrate the ability to architect maintainable solutions to complex problems. Effective collaboration with teammates on the development of new ideas and accepting constructive feedback through the code review process is required. Candidates may also be expected to implement algorithms created by hardware engineers or from academic sources with limited documentation. Candidates must be U.S. citizens and be willing and able to obtain a DoD security clearance (if not already cleared).,"5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience.

You Will Meet Our Minimum Qualifications If You…

Are a United States citizen with the ability to obtain and maintain a DOD security clearance
Have extensive experience with object-oriented programming languages (C++, Java, Python)
Have exposure to basic logic gates and Boolean math (AND, OR)
Have the ability to learn new skills quickly

Preferred Requirements


Already possess an active security clearance
Have experience with modern C++ standards C++17) and STL
Have experience with Python
Can demonstrate the use of design patterns
Have developed using software development processes (Agile, TDD, etc.)
Familiarity with Verilog or VHDL
Have experience with FPGA design software (Quartus, ISE, Vivado, etc.)
Have experience with software reverse engineering (IDA Pro, Ghidra, Binary Ninja etc.)
Are proficient with source control systems (git, svn, perforce, etc.)
Have experience with the code review process
Have experience with binary patching
Have experience bypassing encryption schemes (power glitching, side channel attacks, etc.)
Have published research regarding cybersecurity, software exploitation, or reverse engineering","5 years relevant experience with Bachelors in related field; 3 years relevant experience with Masters in related field; 0 years experience with PhD or Juris Doctorate in related field; or High School Diploma or equivalent and 9 years relevant experience.

You Will Meet Our Minimum Qualifications If You…

Are a United States citizen with the ability to obtain and maintain a DOD security clearance
Have extensive experience with object-oriented programming languages (C++, Java, Python)
Have exposure to basic logic gates and Boolean math (AND, OR)
Have the ability to learn new skills quickly","You will go above and beyond if you...

Already possess an active security clearance
Have experience with modern C++ standards C++17) and STL
Have experience with Python
Can demonstrate the use of design patterns
Have developed using software development processes (Agile, TDD, etc.)
Familiarity with Verilog or VHDL
Have experience with FPGA design software (Quartus, ISE, Vivado, etc.)
Have experience with software reverse engineering (IDA Pro, Ghidra, Binary Ninja etc.)
Are proficient with source control systems (git, svn, perforce, etc.)
Have experience with the code review process
Have experience with binary patching
Have experience bypassing encryption schemes (power glitching, side channel attacks, etc.)
Have published research regarding cybersecurity, software exploitation, or reverse engineering","90,100 - 125,000"
63,Thomas Koch,,LinkedIn,Software Engineer,Full time,Capgemini,New York,onsite,3 weeks ago,https://www.linkedin.com/jobs/view/4359727247/,"Should have 7 years of strong handson experience with Core Java Spring bootShould have 4 years of strong handson experience with Angular or React

Hands On experience Relational DatabaseMicrosoft SQL Server UDBDB2 or No SQL is required

Should have strong hands on experience working on Microservices Kafka REST API Development experience

Hands on experience working with containerization technologies Docker Kubernetes

Experience in modernizingrewriting legacy application to modernized distributed platforms",bachelors,7 years of hands on experience,"\Works in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.
1. Applies scientific methods to analyse and solve software engineering problems.
2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.
3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.
4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.
5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.","Good to have

Python experience

AlML exposure is valuable

Experience in Cloud platforms Azure etc

Experience in DevOps pipeline CICD practice any tools eg Jenkinsteam city""

Should have 7 years of strong handson experience with Core Java Spring bootShould have 4 years of strong handson experience with Angular or React

Hands On experience Relational DatabaseMicrosoft SQL Server UDBDB2 or No SQL is required

Should have strong hands on experience working on Microservices Kafka REST API Development experience

Hands on experience working with containerization technologies Docker Kubernetes

Experience in modernizingrewriting legacy application to modernized distributed platforms","Should have 7 years of strong handson experience with Core Java Spring bootShould have 4 years of strong handson experience with Angular or React

Hands On experience Relational DatabaseMicrosoft SQL Server UDBDB2 or No SQL is required

Should have strong hands on experience working on Microservices Kafka REST API Development experience

Hands on experience working with containerization technologies Docker Kubernetes

Experience in modernizingrewriting legacy application to modernized distributed platforms","Good to have

Python experience

AlML exposure is valuable

Experience in Cloud platforms Azure etc

Experience in DevOps pipeline CICD practice any tools eg Jenkinsteam city""

Should have 7 years of strong handson experience with Core Java Spring bootShould have 4 years of strong handson experience with Angular or React

Hands On experience Relational DatabaseMicrosoft SQL Server UDBDB2 or No SQL is required

Should have strong hands on experience working on Microservices Kafka REST API Development experience

Hands on experience working with containerization technologies Docker Kubernetes

Experience in modernizingrewriting legacy application to modernized distributed platforms","104,400"
64,Ayooluwatomi Daniel Olubajo,,LinkedIn,"Software Engineer III, Android 
",Full time,Google,"San Fransico, CA",onsite,2/14/2026,https://www.linkedin.com/jobs/view/4365576571/?alternateChannel=search&eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=NsxG5S7uXKTilBb%2BUtGEww%3D%3D&trackingId=8o%2FXKlUJMp5NKk%2FxyhTueg%3D%3D,"About The Job

Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.

With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions.

Android is Google’s mobile operating system powering more than 3 billion devices worldwide. Android is about bringing computing to everyone in the world. We believe computing is a super power for good, enabling access to information, economic opportunity, productivity, connectivity between friends and family and more. We think everyone in the world should have access to the best computing has to offer. We provide the platform for original equipment manufacturers (OEMs) and developers to build compelling computing devices (smartphones, tablets, TVs, wearables, etc) that run the best apps/services for everyone in the world.

The US base salary range for this full-time position is $141,000-$202,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities

Write product or system development code.
Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies.
Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency).
Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback.
Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",bachelors,2+,"Write product or system development code.
Participate in, or lead design reviews with peers and stakeholders to decide amongst available technologies.
Review code developed by other developers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency).
Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback.
Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality.","Minimum qualifications:

Bachelor’s degree or equivalent practical experience.
2 years of experience programming in Python or C++.

Preferred qualifications:

Master's degree or PhD in Computer Science or related technical fields.
2 years of experience with data structures or algorithms in either an academic or industry setting.
2 years of experience with performance, large scale systems data analysis, visualization tools, or debugging.
Experience developing accessible technologies. 
Proficiency in code and system health, diagnosis and resolution, and software test engineering. ","Bachelor’s degree or equivalent practical experience.
2 years of experience programming in Python or C++.","Master's degree or PhD in Computer Science or related technical fields.                                                       
                                                                                                                                                                                     2 years of experience with data structures or algorithms in either an academic or industry setting.
                                                                                                                                                                                         2 years of experience with performance, large scale systems data analysis, visualization tools, or debugging.
                                                                                                                                                                        Experience developing accessible technologies. 
                                                                                                                                                                      Proficiency in code and system health, diagnosis and resolution, and software test engineering. ","$141,000 - $202,000"
65,William Gallegos,,LinkedIn,Data Analyst,Full Time,Zynga,"Austin, TX",on-site,02/02/2026,https://www.linkedin.com/jobs/view/4367305286,"Level Up Your Career with Zynga! At Zynga, we bring people together through the power of play. As a global leader in interactive entertainment and a proud label of Take-Two Interactive, our games have been downloaded over 6 billion times—connecting players in 175+ countries through fun, strategy, and a little friendly competition. From thrilling casino spins to epic strategy battles, mind-bending puzzles, and social word challenges, our diverse game portfolio has something for everyone. Fan-favorites and latest hits include FarmVille™, Words With Friends™, Zynga Poker™, Game of Thrones Slots Casino™, Wizard of Oz Slots™, Hit it Rich! Slots™, Wonka Slots™, Top Eleven™, Toon Blast™, Empires & Puzzles™, Merge Dragons!™, CSR Racing™, Harry Potter: Puzzles & Spells™, Match Factory™, and Color Block Jam™—plus many more! Founded in 2007 and headquartered in California, our teams span North America, Europe, and Asia, working together to craft unforgettable gaming experiences. Whether you're spinning, strategizing, matching, or competing, Zynga is where fun meets innovation—and where you can take your career to the next level. Join us and be part of the play!",bachelor's,2+,"Collaborate with the Product team to enhance revenue, retention, and engagement metrics. This includes conducting A/B testing, performing insights analysis, and developing dashboards. Design and maintain ETL pipelines to extract, transform, and load data from multiple sources, ensuring source of truth for analyses and business intelligence. Design game telemetry to collect important player interaction data to improve the game experience. Analyze player behavior to understand motivations and preferences, partnering with game design and consumer insights teams to translate findings into actionable experience improvements. Actively play and engage with our games to maintain first-hand understanding of player experience, game mechanics, and potential problems. Monitor, and maintain the integrity of a wide range of tools and models used to streamline workflows and personalize the player experience, in collaboration with other data analysts and data scientists on the team. Participate in and contribute to the Analytics Org’s AI initiative, which aims to significantly increase each analyst’s impact through the power of LLMs. Continuously learn about analytics best practices, and actively share and promote these practices across various games and teams.","Bachelor's degree in Computer Science, Mathematics, Statistics, Economics, or a related quantitative field. Advanced degrees (Masters or PhD) are a plus. Minimum of 2 years in data science or analytics roles. Proficiency in Python and SQL.  Demonstrated experience in more than one of the following: data mining, data visualization, experimental design, statistical analysis, and machine learning.  Familiarity with Business Intelligence (BI) tools like Tableau and version control systems such as Git is advantageous. Strong ability in both written and oral communication. Highly self-motivated with a keen interest in problem-solving. Willingness to take ownership of challenges. Proven ability to work collaboratively as part of a team. Familiarity with mobile games","Bachelor's degree in Computer Science, Mathematics, Statistics, Economics, or a related quantitative field. Advanced degrees (Masters or PhD) are a plus. Minimum of 2 years in data science or analytics roles.","Proficiency in Python and SQL.  Demonstrated experience in more than one of the following: data mining, data visualization, experimental design, statistical analysis, and machine learning.  Familiarity with Business Intelligence (BI) tools like Tableau and version control systems such as Git is advantageous. Strong ability in both written and oral communication. Highly self-motivated with a keen interest in problem-solving. Willingness to take ownership of challenges. Proven ability to work collaboratively as part of a team. Familiarity with mobile games","$77,100 - $114,120"
66,William Gallegos,,LinkedIn,"Principal, Data Engineering",Full Time,American Tower,"Woburn, MA",hybrid,01/06/2026,https://www.linkedin.com/jobs/view/4359688113,"We are seeking a Director, Data Engineering to join American Tower’s Information Technology (“IT”) organization’s Data & Analytics team and lead its Data Engineering team (“team”). The team builds and scales the enterprise data ecosystem and engineering capabilities to enable artificial intelligence, advanced analytics, and digital acceleration. Day to day you will lead the design, development, and optimization of scalable cloud-native data platforms, build robust data pipelines, and partner with the Data Governance team to ensure data quality. As Director, you will deliver high-value, end-to-end data solutions that provide a unified view of enterprise data and drive measurable business value through collaboration with stakeholders and IT partners.",nan,"12+, 5+ in leadership","Lead the design, development, and optimization of scalable cloud-native data platforms, working closely with IT teams. Design and build robust, end-to-end data pipelines to support data ingestions, transformations, and deliveries across the enterprise. Develop and optimize scalable data models that ensure data integrity, accessibility, and performance across analytics and operational systems. Design and implement an enterprise-wide semantic layer that provides a unified, business-friendly view of data. Lead the development and deployment of reusable, high-value data products that support business intelligence, advanced analytics, and operational reporting. Partner with the Data Governance team to implement data cleansing, enrichment, and transformation processes that ensure data are accurate and ready for use. Engage with business stakeholders, analytics teams, and IT partners to understand data needs and deliver solutions that drive measurable business value. Define and monitor key performance indicators for pipeline performance, data availability, and operational efficiencies. Drive automation and continuous improvement initiatives. Stay current with emerging technologies and industry best practices in data engineering. Introduce tools and methodologies that enhance data engineering capabilities. Responsible for leading talent selection, performance management, career development, and workforce planning within the approved headcount, for the team. Other duties as assigned.","Bachelor’s degree required, with a concentration in Business Administration, Information Technology, Data Engineering, or a related field preferred. MBA or other relevant advanced degree preferred. A minimum of 12 years of data engineering, platform development, or enterprise data management experience, with at least 5 years in a leadership role within a global organization and multitier environment, required. Expertise in building and maintaining large-scale data pipelines and models. Strong understanding of semantic layer design, data modeling, and cloud-based data architecture. Hands-on experience with modern cloud platforms (e.g., Amazon Web Services, Microsoft Azure, Google Cloud Platform) and big data technologies (e.g., Apache Spark, Apache Kafka). Familiarity with modern data platforms such as Databricks or Snowflake strongly preferred. Success at implementing technical enforcement of data governance policies in partnership with business-led governance teams. Strong analytical, problem-solving, and communication skills with an ability to drive change and influence stakeholders. Approximately 25% travel may be required to support the position’s responsibilities. Strong organization, planning, and project management skills; ability to prioritize tasks for yourself and a team to meet requirements and deadlines. Ability to work with different functional groups and levels of employees to effectively and professionally achieve results. Strong leadership skills; ability to drive and motivate a team to achieve results.","A minimum of 12 years of data engineering, platform development, or enterprise data management experience, with at least 5 years in a leadership role within a global organization and multitier environment, required. Approximately 25% travel may be required to support the position’s responsibilities.","Bachelor’s degree required, with a concentration in Business Administration, Information Technology, Data Engineering, or a related field preferred. MBA or other relevant advanced degree preferred. Expertise in building and maintaining large-scale data pipelines and models. Strong understanding of semantic layer design, data modeling, and cloud-based data architecture. Hands-on experience with modern cloud platforms (e.g., Amazon Web Services, Microsoft Azure, Google Cloud Platform) and big data technologies (e.g., Apache Spark, Apache Kafka). Familiarity with modern data platforms such as Databricks or Snowflake strongly preferred. Success at implementing technical enforcement of data governance policies in partnership with business-led governance teams. Strong analytical, problem-solving, and communication skills with an ability to drive change and influence stakeholders. Strong organization, planning, and project management skills; ability to prioritize tasks for yourself and a team to meet requirements and deadlines. Ability to work with different functional groups and levels of employees to effectively and professionally achieve results. Strong leadership skills; ability to drive and motivate a team to achieve results.","$190,000 - $220,000"
67,William Gallegos,,LinkedIn,"Principal, Data Scientist",Full Time,American Tower,"Woburn, MA",hybrid,01/09/2026,https://careers.americantower.com/#en/sites/CX_1/job/2271/?utm_medium=jobshare&utm_source=External+Job+Share,"We are seeking a Principal Data Scientist to join American Tower’s Information Technology organization’s Data & Analytics team. The team drives the strategy, architecture, and delivery of advanced machine learning (ML) and artificial intelligence (AI) solutions across the enterprise. Day to day you will design and implement scalable ML systems, partner with the Data Engineering team on pipelines, and collaborate with the Productization & Adoption team to deploy models into production. As a Principal Data Scientist, you will set technical standards, mentor team members, and ensure solutions align with governance frameworks established by the Strategy & Governance team.",bachelor's,8+,"Partner with Operations, Finance, Sales, and Legal department stakeholders to translate complex problems into measurable AI and ML initiatives, influence the analytics roadmap, and communicate findings to technical and non-technical audiences. Act as lead technical consultant and subject matter expert for scoping AI projects, defining requirements, and ensuring high-quality deliveries of advanced solutions. Design and implement supervised, unsupervised, and reinforcement learning models, including feature engineering, model selection, and rigorous validation for accuracy and scalability. Architect solutions for unstructured data (contracts, documents, images), geospatial data, and enterprise systems (Salesforce customer resource management (“CRM”), Oracle Enterprise Resource Planning) to deliver actionable insights. Design and build end-to-end ML systems aligned with machine learning operations (“MLOps”) best practices; collaborate with the Data Engineering team on pipelines and with the Productization & Adoption team on deployments. Define and enforce standards for model governance, ethics, and bias detection in compliance with organizational policies. Mentor and guide Data Scientists, lead technical reviews, and recommend tools and methodologies to enhance the team’s capabilities and performance. Other duties as assigned.    ","Bachelor’s degree required, with a concentration in Computer Science, Statistics, Engineering, Physics, or a related quantitative field required. Master’s degree or other advanced degree preferred. A minimum of 8 years of data science or machine learning experience required. Expert proficiency in Python programming language and ML libraries (e.g., scikit-learn, TensorFlow, PyTorch) required. Strong foundation in statistics, causal inference, time series, and optimization with an ability to select appropriate methods for given problems required. Deep expertise in computer vision or geospatial/geographic information system modeling preferred. Experience with MLOps platforms and workflows (Databricks, MLflow, Azure ML, Amazon SageMaker, or Google Vertex AI), including experiment tracking and model registry preferred. Experience deploying models to production systems (application programming interfaces, streaming, batch workflows) with appropriate monitoring and alerting preferred. Familiarity with data platforms (Databricks or Snowflake) and enterprise systems (Salesforce CRM, Oracle Enterprise Resource Planning) preferred. Strong written and oral communication skills, including the ability to present ideas and suggestions clearly and effectively. Ability to work with different functional groups and levels of employees to effectively and professionally achieve results. Strong organizational skills; ability to accomplish multiple tasks within the agreed-upon timeframes through effective prioritization of duties and functions in a fast-paced environment.",Bachelor's Degree in a related quantitative field. 8+ years experince in ML or DS. Strong Foundation in Statistics. Expert Proficiency in Python & ML libraries such as PyTorch and TensorFlow.,"Master’s degree or other advanced degree preferred. Deep expertise in computer vision or geospatial/geographic information system modeling preferred. Experience with MLOps platforms and workflows (Databricks, MLflow, Azure ML, Amazon SageMaker, or Google Vertex AI), including experiment tracking and model registry preferred. Experience deploying models to production systems (application programming interfaces, streaming, batch workflows) with appropriate monitoring and alerting preferred. Familiarity with data platforms (Databricks or Snowflake) and enterprise systems (Salesforce CRM, Oracle Enterprise Resource Planning) preferred. Strong written and oral communication skills, including the ability to present ideas and suggestions clearly and effectively. Ability to work with different functional groups and levels of employees to effectively and professionally achieve results. Strong organizational skills; ability to accomplish multiple tasks within the agreed-upon timeframes through effective prioritization of duties and functions in a fast-paced environment.","$150,000 - $180,000"
68,Ayooluwatomi Daniel Olubajo,,LinkedIn,"Senior Software Engineer, AI Apps and Frameworks",Full Time,Nvidia,"Santa Clara, CA",on-site,2/14/2026,https://www.linkedin.com/jobs/view/4372937993/?alternateChannel=search&eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=NsxG5S7uXKTilBb%2BUtGEww%3D%3D&trackingId=yWfQ2dGJN%2Fy%2FHm720CXCPQ%3D%3D,"We are looking for a skilled Open Source Software Developer to join our team. The ideal candidate will be responsible for designing, developing, and maintaining NVIDIA Models and Inference API integrations into open-source inference libraries and frameworks. You will work closely with multiple upstream projects and communities to enable Day-0 NVIDIA model support.","bachelors or masters degree in computer science or a related field, or equivalent experience",8+,"Lead the design and implement NVIDIA Inference connectors, Toolkit integrations in upstream OSS libraries and frameworks
Continued maintenance of NVIDIA Inference API Integrations into upstream OSS libraries and frameworks
Design and develop test harness to maintain high quality integrations
Evangelize NVIDIA Inference API and NVIDIA Inference connectors and integrations
Learn and have a good understanding of NVIDIA Inference microservices, release cadence and enable day-0 support for NVIDIA models in upstream projects
Partner closely with NVIDIA Inference microservices and release teams to design and enable inference API integrations into upstream projects
You will work with product to continuously discover, learn new upstream projects and enable integrations
Mentor junior engineers and review contributions","Bachelors or Masters degree in Computer Science or a related field, or equivalent experience
8+ years of experience in software design, development and test
Experience in open source development and releases
Experience working with upstream open source projects and communities
A good understanding of AI application Developer workflows, Inference frameworks, services and APIs
Strong verbal and written communication skills.
Strong teamwork and social skills.
Ability to adapt quickly in a dynamic environment.
Action driven with strong analytical skills.
Desire to be involved in multiple diverse projects","Bachelors or Masters degree in Computer Science or a related field, or equivalent experience
8+ years of experience in software design, development and test
Experience in open source development and releases
Experience working with upstream open source projects and communities
A good understanding of AI application Developer workflows, Inference frameworks, services and APIs
Strong verbal and written communication skills.
Strong teamwork and social skills.
Ability to adapt quickly in a dynamic environment.
Action driven with strong analytical skills.
Desire to be involved in multiple diverse projects","Bachelors or Masters degree in Computer Science or a related field, or equivalent experience
8+ years of experience in software design, development and test
Experience in open source development and releases
Experience working with upstream open source projects and communities
A good understanding of AI application Developer workflows, Inference frameworks, services and APIs
Strong verbal and written communication skills.
Strong teamwork and social skills.
Ability to adapt quickly in a dynamic environment.
Action driven with strong analytical skills.
Desire to be involved in multiple diverse projects. Background and strong contributions to open source projects
Deep Understanding and contributions to open source inference ecosystem libraries, APIs and frameworks
","$184,000 - $356,500"
69,Ayooluwatomi Daniel Olubajo,,LinkedIn,Data Engineer,Full TIme,Archer,"San Jose, CA",on-site,2/8/2026,https://www.linkedin.com/jobs/view/4360021845/?alternateChannel=search&eBP=CwEAAAGcY4CRookAqIwKeqSkrrdQnngiWyINiTizues3NwtPd6Vz55VhpCphvv25Vo7SBS1EEwLGITKMh9EL5yAWWJaL1yWNJSOGvg3pa73XzS7LBAJOqmrGkTZjF8CgV1CL8aJfeX03QToOke05nR8gKMQUCGC1O6MBoBSWKJtY5s6tcqiEJWBREYx63MQGobrtpiRWvzXNRoGX8CsvrCMF47Gj-Bt8QPsXO0wi55otYznQqkkTkqyWDiDkCqmvAtd2i73D-Zpcr00zmoy_WnngBLgX_18pPGmkKaKyCxs9ELqC-LXfAMaMffFZf4dCcGJ7D3WukAd1N1nbU4wrzTJdqTOIWGXJveWx9ADZ9x-ClqgqvAkyN5IVlKIYQxG13OiSnpJ0w8_pkpX71XSgCqe34CaeZ_S_OR2C-GcaPCGOqua-7MEw2tEQ0ZkTTtXQLxyQq7kYBm2bH2XeK8deAGhrgewwdOtBIc0i_DH1exbMelgej0S0ZDpd1scnUUs2U5sHcLUzPPzxuyyDQcfrWCH8dCNCZm0Wt_1aCIFjWQ&refId=PZcNluHVT9BIxgV5ywxEtQ%3D%3D&trackingId=Ev%2FOWFlhe9wrUB9L38ZYgA%3D%3D,"Archer is an aerospace company based in San Jose, California building an all-electric vertical takeoff and landing aircraft with a mission to advance the benefits of sustainable air mobility. We are designing, manufacturing, and operating an all-electric aircraft that can carry four passengers while producing minimal noise.

Our sights are set high and our problems are hard, and we believe that diversity in the workplace is what makes us smarter, drives better insights, and will ultimately lift us all to success. We are dedicated to cultivating an equitable and inclusive environment that embraces our differences, and supports and celebrates all of our team members.

What You’ll Do:

We are looking for an experienced Data Engineer to specialize in aviation data and analytics, focusing on two critical areas: scalable and efficient processing of flight test data for rapid design iteration and near-real-time analysis of aircraft health data for predictive maintenance. This role is vital for accelerating our aircraft design and improvement processes through efficient, scalable data processing and for ensuring operational reliability and safety through advanced predictive analytics.

In this role, you will be tasked with various aspects of data engineering. In addition to the above, your responsibilities will include but not limited to the following.

Architect, build, and optimize our data processing systems to ensure reliability, efficiency, and scalability
Develop and optimize ETL processes, data models, and data architectures for data transformation, structures, metadata, and workload management
Develop and maintain data models that support analytics, reporting, and custom app development
Create robust data quality observability, monitoring, testing, and validation frameworks
Engage actively with analytics teams and business stakeholders to understand their data needs, ensuring the data architecture supports decision-making processes effectively
Support the integration of data systems with aircraft telemetry, flight testing, and operational systems","bachelor’s or master’s degree in computer science, aerospace engineering, data analytics, or a related field",3+,"Architect, build, and optimize our data processing systems to ensure reliability, efficiency, and scalability
Develop and optimize ETL processes, data models, and data architectures for data transformation, structures, metadata, and workload management
Develop and maintain data models that support analytics, reporting, and custom app development
Create robust data quality observability, monitoring, testing, and validation frameworks
Engage actively with analytics teams and business stakeholders to understand their data needs, ensuring the data architecture supports decision-making processes effectively
Support the integration of data systems with aircraft telemetry, flight testing, and operational systems","Bachelor’s or Master’s degree in Computer Science, Aerospace Engineering, Data Analytics, or a related field
At least 3 years experience in data or software engineering with background implementing best practices for SQL and programming languages (e.g. Python, Go, Rust)
Experience designing and managing data warehouse / lakehouse architectures for high performance and low latency
Led development of real-time data pipelines using Kafka or related technologies
Expertise with one or more cloud data platforms (e.g., AWS, GCP, Azure) 
Deep understanding of data security and quality governance
Deployed and scaled data workloads using Docker and Kubernetes, with the ability to manage compute resources for high-volume processing 
Familiarity with ERP systems and how to extract data to build custom tools & applications
Knowledge of integrating Gen AI into production data workflows 
Exceptional analytical skills, attention to detail, and the ability to collaborate effectively across multidisciplinary teams
Clear communication skills that are essential for working across diverse stakeholders","Bachelor’s or Master’s degree in Computer Science, Aerospace Engineering, Data Analytics, or a related field
At least 3 years experience in data or software engineering with background implementing best practices for SQL and programming languages (e.g. Python, Go, Rust)
Experience designing and managing data warehouse / lakehouse architectures for high performance and low latency
Led development of real-time data pipelines using Kafka or related technologies
Expertise with one or more cloud data platforms (e.g., AWS, GCP, Azure) 
Deep understanding of data security and quality governance
Deployed and scaled data workloads using Docker and Kubernetes, with the ability to manage compute resources for high-volume processing 
Familiarity with ERP systems and how to extract data to build custom tools & applications
Knowledge of integrating Gen AI into production data workflows 
Exceptional analytical skills, attention to detail, and the ability to collaborate effectively across multidisciplinary teams
Clear communication skills that are essential for working across diverse stakeholders","Bachelor’s or Master’s degree in Computer Science, Aerospace Engineering, Data Analytics, or a related field.
At least 3 years experience in data or software engineering with background implementing best practices for SQL and programming languages (e.g. Python, Go, Rust).
Experience designing and managing data warehouse / lakehouse architectures for high performance and low latency.
Led development of real-time data pipelines using Kafka or related technologies.
Expertise with one or more cloud data platforms (e.g., AWS, GCP, Azure). 
Deep understanding of data security and quality governance.
Deployed and scaled data workloads using Docker and Kubernetes, with the ability to manage compute resources for high-volume processing.
Familiarity with ERP systems and how to extract data to build custom tools & applications
Knowledge of integrating Gen AI into production data workflows.
Exceptional analytical skills, attention to detail, and the ability to collaborate effectively across multidisciplinary teams.
Clear communication skills that are essential for working across diverse stakeholders. Solid foundation in machine learning and other data science fundamentals.
Familiarity with time series data applications and related technologies.
Experience with Infrastructure as Code (Terraform, CloudFormation).
Advanced skills in predictive analytics and machine learning models for maintenance and anomaly detection.
Experience in aerospace or a related field, particularly with flight test data analysis and aircraft health monitoring.",Not stated
70,Kenneth Nguyen,,Amazon Jobs,"Senior Applied Scientist, Generative AI Innovation Center",Full,Amazon,USA,hybrid,,https://www.amazon.jobs/en/jobs/3106302/senior-applied-scientist-generative-ai-innovation-center,"The GenAI Innovation Center helps AWS customers develop and scale generative AI solutions. The team helps customers imagine and scope bespoke use cases that will create the greatest value for their businesses, define paths to navigate technical or business challenges, develop models to power real world applications, and make plans for launching solutions at scale. The GenAI Innovation Center team provides guidance on best practices for applying generative AI responsibly and cost efficiently.You will work directly with customers and innovate in a fast-paced organization that contributes to game-changing projects and technologies. You will design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience.
We’re looking for Applied Scientists capable of using GenAI and other techniques to design, evangelize, and implement state-of-the-art solutions for never-before-solved problems.",phd or masters,"6+ years research 
3+ years machine learning models","Key job responsibilities
As an Applied Scientist, you will
• Collaborate with AI/ML scientists and architects to research, design, develop, and evaluate generative AI solutions to address real-world challenges
• Interact with customers directly to understand their business problems, aid them in implementation of generative AI solutions, brief customers and guide them on adoption patterns and paths to production
• Help customers build their solutions through approaches such as prompt engineering, model selection, training or fine-tuning
• Provide customer and market feedback to product and engineering teams to help define product direction","Basic Qualifications
- 3+ years of building machine learning models for business application experience
- PhD, or Master's degree and 6+ years of applied research experience
- Experience programming in Java, C++, Python or related language
- Experience with neural deep learning methods and machine learning

Preferred Qualifications
- Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc.
- Experience with large scale distributed systems such as Hadoop, Spark etc.","- 3+ years of building machine learning models for business application experience
- PhD, or Master's degree and 6+ years of applied research experience
- Experience programming in Java, C++, Python or related language
- Experience with neural deep learning methods and machine learning","- Experience with modeling tools such as R, scikit-learn, Spark MLLib, MxNet, Tensorflow, numpy, scipy etc.
- Experience with large scale distributed systems such as Hadoop, Spark etc.","National $150,400 - $260,000 annually"
71,Kenneth Nguyen,,"
Indeed",Data Scientist,Full,KForce Inc.,"Houston, TX",onsite,2/10/2026,https://www.linkedin.com/jobs/view/data-scientist-at-kforce-inc-4371029207?refId=yxE7Pn8uZ4sI9vGblHNs%2Bw%3D%3D&trackingId=ZCqCz5UheNmK3jX6PJqJqA%3D%3D,"Kforce has a client in Houston, TX that is looking for a Data Scientist to join a team at the forefront of building a smarter, cleaner, digitally enhanced energy ecosystem. Our data scientists combine technical expertise with business acumen to help brands achieve financial and strategic objectives. This is an excellent opportunity to learn and grow while performing hands-on analytics and modeling. Essential Duties & Responsibilities:",masters,3 years,"Data Scientist will embrace a culture of humility, curiosity, and impact
Process data using Python, PySpark, and Databricks
Develop predictive models and interactive dashboards
As a Data Scientist, you will perform hands-on analytics and modeling to support business decisions
Provide insights that help business partners make more profitable, customer-focused decisions","Master's degree in a quantitative discipline or equivalent practical experience
0-3 years of experience in data analysis or a related field
Experience with statistical software and database languages
PhD in a quantitative discipline
Experience applying data science to improve customer experience and business profitability
Experience working with cloud-based data storage and processing
Knowledge of methods such as frequentist and Bayesian statistics, forecasting, optimization, causal inference, machine learning, and natural language processing
Proficiency in Python packages such as PySpark, NumPy, pandas, scikit-learn, XGBoost, Matplotlib, and lifelines
Proficiency with version control systems
Strong collaboration skills and ability to communicate persuasively and informatively across functions","Master's degree in a quantitative discipline or equivalent practical experience
0-3 years of experience in data analysis or a related field
Experience with statistical software and database langua","PhD in a quantitative discipline
Experience applying data science to improve customer experience and business profitability
Experience working with cloud-based data storage and processing
Knowledge of methods such as frequentist and Bayesian statistics, forecasting, optimization, causal inference, machine learning, and natural language processing
Proficiency in Python packages such as PySpark, NumPy, pandas, scikit-learn, XGBoost, Matplotlib, and lifelines
Proficiency with version control systems
Strong collaboration skills and ability to communicate persuasively and informatively across functions","$120,640 - $135,200"
72,Kenneth Nguyen,,Indeed,Senior Solutions Engineer Hospital Healthcare Data and Data Tools focus,Full,ChatGPT Jobs,"Houstno, TX",remote,2/11/2026,https://www.linkedin.com/jobs/view/senior-solutions-engineer-hospital-healthcare-data-and-data-tools-focus-at-chatgpt-jobs-4363088642?refId=KzWpXl33XtqwDfhrRu8Euw%3D%3D&trackingId=qk%2BxsPEHhz4brElZ7PSMIw%3D%3D,"Focus on ensuring hospital and payer-facing healthcare data is accurate, available, compliant, and correctly translated into product and engineering requirements. Heavy emphasis on EMR data (Epic, Cerner), regulatory logic, and healthcare data standards.",bachelor's,,"Focus on ensuring hospital and payer-facing healthcare data is accurate, available, compliant, and correctly translated into product and engineering requirements. Heavy emphasis on EMR data (Epic, Cerner), regulatory logic, and healthcare data standards.","Strong background in healthcare analytics, hospital data, or payer-provider data workflows.
Hands-on experience with EMR data (Epic, Cerner strongly preferred).
Strong SQL skills and ability to validate logic.
Familiarity with healthcare data standards (ICD, CPT, LOINC, SNOMED, NDC, HL7/FHIR).
Experience interpreting CMS, AHRQ, HEDIS, or similar regulatory documentation.
Experience working with data warehouses (Snowflake, BigQuery, Redshift).
Ability to work cross-functionally with product, engineering, and clinical stakeholders.
Curiosity about AI and willingness to use AI tools to accelerate analysis.
A BS Degree is Preferred (MS Degree is a strong plus), Technical-Data-Focused Training or Certifications are preferred.","Translate business and clinical requirements into clear technical specifications for engineering and data teams.
Evaluate hospital and claims data for completeness, accuracy, and readiness for use in analytics products.
Identify data quality issues, missing fields, mapping gaps, and inconsistencies across EMR and claims sources.
Review SQL logic to confirm it matches product requirements, regulatory rules, and measure definitions.
Interpret and validate CMS, AHRQ, HEDIS, and other regulatory specifications to ensure correct implementation.
Document logic, data assumptions, and regulatory interpretations in a clear, traceable format.
Communicate findings to both technical and non‐technical stakeholders across product, engineering, and clinical teams.","Epic/Cerner data is correctly understood, mapped, and validated early. 
Regulatory rules and quality measures are implemented accurately with no rework. E
ngineering builds align with requirements on the first pass. 
Data issues are caught before they impact clients or downstream analytics.","$145,000.00/yr - $195,000.00/yr"
73,Tony Moreno,,Indeed,Marketing / Data Analyst,Full,San Antonio Wings,"18803 Meisner Drive, San Antonio, TX 78258",onsite,30+ days ago,https://workforcenow.adp.com/mascsr/default/mdf/recruitment/recruitment.html?cid=ee935b13-4a8d-4910-bb4e-71ed24130075&ccId=9200446332552_2&jobId=514585&source=IN&lang=en_US&ittk=0GUFY7LMKX,"As a Marketing Analyst / Data Analyst at our quick-service restaurant (QSR) chain franchisor, managing 247 locations across our Pizza Patron brand (87 locations) and Wingstop franchisee locations (160 locations), you will leverage data analysis to drive marketing strategies for Pizza Patron and support operational insights for our Wingstop locations. For Pizza Patron, you will focus on marketing analytics, including campaign optimization and customer segmentation. For Wingstop locations, you will perform data analysis to uncover sales trends, operational efficiencies, and customer behavior insights. You will support projects from the Marketing and Business Systems roadmap, creating reports and visualizations tailored to each brand’s needs. Our ideal candidate has a solid foundation in data analysis, strong problem-solving skills, and the ability to communicate findings clearly to marketing teams, operations, leadership, and franchisee partners. Familiarity with SQL, Excel, and BI tools (e.g., Tableau, Power BI) is preferred.",bachelor's,1-3,"Pizza Patron (Marketing Analyst): Analyze marketing data to identify customer behavior trends, campaign performance, and market opportunities to enhance Pizza Patron campaigns across 87 locations. Wingstop Locations (Data Analyst): Analyze sales, operational, and customer data to identify trends and efficiencies for Wingstop franchisee locations across 160 locations. Support data-driven marketing strategies for Pizza Patron to improve customer acquisition, retention, and engagement, and provide data insights to optimize Wingstop operations. Use analytical skills to uncover patterns in customer data, campaign results (Pizza Patron), and sales/operational data (Wingstop locations). Query and manage marketing and operational databases (e.g., CRM systems, POS systems) to ensure accurate and actionable data for both brands. Assist in creating data models for customer segmentation and campaign targeting for Pizza Patron and operational analysis for Wingstop locations. Develop dashboards and reports to visualize key metrics (e.g., conversion rates, customer engagement, campaign ROI for Pizza Patron; sales trends, operational KPIs for Wingstop) for stakeholders across 247 locations. Monitor digital marketing channels (e.g., email, social media, paid ads) for Pizza Patron and operational performance metrics (e.g., sales, order times) for Wingstop locations to support optimization efforts. Evaluate marketing campaign performance for Pizza Patron and operational data trends for Wingstop locations, providing recommendations to improve effectiveness. Collaborate with cross-functional teams (e.g., marketing, operations, IT) and franchisee partners to translate brand-specific needs into data-driven plans for Pizza Patron and Wingstop locations. Perform quality checks on marketing and operational data to ensure accuracy across both brands. Support the evaluation of analytics tools and platforms to enhance marketing (Pizza Patron) and operational (Wingstop) performance. Assist marketing and operations teams with data retrieval, Excel analysis, and interpreting analytics outputs for brand-specific strategies. Incorporate feedback from franchisee partners and department leaders to refine marketing strategies for Pizza Patron and operational insights for Wingstop locations","Bachelor's degree with around 1-3 year of relevant work. Experience in food and beverage industry, proficiency in data manipulation and reporting. Strong teamwork and communication skills.","Bachelor's degree in marketing, business, statistics, etc. 1-3 years of relevant work in marketing analyitcs or data analysis. Profeciency in Excel for data manipulation and reporting.",Regulatory rules and quality measures are implemented accurately with no rework.,"65,000 - 80,000"
74,Tony Moreno,,Indeed,Junior Data Scientist,Full,Techfield,"Austin, TX",onsite,,https://www.indeed.com/jobs?q=data+analyst&l=Kyle%2C+TX&latLong=29.99835%2C-97.87153&locString=Kyle%2C+TX%2C+78640&radius=100&vjk=21dd960e5755641f&advn=7378060039423654,"We are seeking a motivated and detail-oriented Junior Data Scientist to join our dynamic team. In this role, you will assist in analyzing complex data sets, developing predictive models, and contributing to data-driven decision-making processes. The ideal candidate will have a strong foundation in data science principles and be eager to learn and grow within the field.",master's,"None specified, strong profieciency though","Collaborate with senior data scientists to design and implement data models using Python and TensorFlow. Assist in the development of ETL processes to extract, transform, and load data from various sources. Conduct exploratory data analysis to identify trends and patterns using tools such as SAS and Hadoop. Participate in model training and deployment activities, ensuring models are optimized for performance. Utilize natural language processing techniques to analyze text data as needed. Support the integration of quantum engineering concepts into existing projects where applicable. Work with big data technologies like Spark to process large datasets efficiently. Document methodologies, findings, and insights for presentation to stakeholders.","Master's degree in Data Science, Computer Science, Statistics, or a related field. Proficiency in programming languages such as Python; experience with TensorFlow is a plus. Familiarity with ETL processes and tools for data integration. Knowledge of machine learning concepts, including model training and deployment. Experience with big data frameworks like Hadoop or Spark is desirable. Understanding of statistical analysis techniques; experience with SAS is advantageous. Strong analytical skills with the ability to work independently as well as part of a team. Excellent communication skills to convey complex information clearly.","Master's degree in Data Science, Computer Science, Statistics, or a related field. Proficiency in programming languages such as Python. Familiarity with ETL processes and tools for data integration. Knowledge of machine learning concepts, including model training and deployment. Understanding of statistical analysis techniques; experience with SAS is advantageous. Strong analytical skills with the ability to work independently as well as part of a team. Excellent communication skills to convey complex information clearly.",Engineering builds align with requirements on the first pass.,"72,800"
75,Tony Moreno,,Indeed,Data Governance Analyst,Contract,Vailexa,"San Antonio, TX",onsite,,https://www.indeed.com/jobs?q=data+analyst&l=Kyle%2C+TX&latLong=29.99835%2C-97.87153&locString=Kyle%2C+TX%2C+78640&radius=100&start=10&vjk=241981438ea650c0,"Alation experience is MUST for this role. Job Description: We are seeking a Data Consultant / Information Management Analyst (IMA) with strong experience in Data Governance and Information Governance Catalogs to support enterprise data management, metadata governance, and data quality initiatives. The role focuses on enabling trusted, compliant, and well-cataloged data across business and technology teams.Key Responsibilities",bachelor's,6+ Years of Experience,"Support data governance frameworks, policies, standards, and stewardship processes. Manage and maintain Information Governance Catalogs (metadata, lineage, data definitions). Work closely with business and IT teams to identify critical data elements and data owners. Ensure data quality, compliance, and regulatory alignment across enterprise systems. Assist in onboarding data assets into governance and catalog platforms","6+ years of experience in Data Governance / Information Management. Strong knowledge of Information Governance Catalog tools (e.g., Elation, Collibra, Alation, Informatica). Experience as an Information Management Analyst (IMA) or similar role. Understanding of metadata management, data lineage, and data quality concepts. Strong communication and stakeholder collaboration skills","6+ years of experience in Data Governance / Information Management. Strong knowledge of Information Governance Catalog tools (e.g., Elation, Collibra, Alation, Informatica). Experience as an Information Management Analyst (IMA) or similar role. Understanding of metadata management, data lineage, and data quality concepts. Strong communication and stakeholder collaboration skills. Alation experience is MUST for this role.",Data issues are caught before they impact clients or downstream analytics.,"18,720 - 20,800"
76,Colin Horwedel,,LinkedIn,Data Analysis & Engineering Intern,Full Time,Texas Instruments,"Dallas, TX",onsite,2/12/2026,https://www.linkedin.com/jobs/search/?currentJobId=4362577331&geoId=103644278&keywords=palantir&origin=JOB_SEARCH_PAGE_SEARCH_BUTTON&refresh=true&start=50,"As a Data Engineering intern, you'll help build the data infrastructure that powers TI's AI/ML initiatives, analytics, and data-driven decision-making across the organization. You'll work with cutting-edge data technologies and cloud platforms, gaining hands-on experience in transforming raw data into actionable insights. And, you'll have the opportunity to work in exciting areas like machine learning pipelines, big data processing, AI-driven analytics, cloud data architecture, real-time data streaming, and automated data workflows.",high school,Not stated," Assisting in the development and maintenance of data pipelines and ETL/ELT workflows for processing datasets from multiple sources
 Supporting the building and optimization of data models, schemas, and databases to ensure efficient data storage and accessibility
 Participating in data cleaning, validation, and quality checks to help deliver accurate and reliable data for analytical use
 Working with SQL, Python, and modern data tools such as Spark to support data flows and data science initiatives
 Collaborating with data engineers and business teams to understand data requirements and contribute to solution development
 Assisting in monitoring data infrastructure performance and helping troubleshoot issues as needed
 Contributing to documentation for pipelines, data models, and transformation logic
 Learning about emerging data technologies and supporting recommendations for data architecture improvements
 Supporting the implementation of software engineering best practices such as testing and monitoring in data workflows","Minimum requirements:

 Currently pursuing an undergraduate or graduate degree in Electrical Engineering, Computer Engineering, Computer Science, Data Science, or related field
 Cumulative 3.0/4.0 GPA or higher

Preferred Qualifications

 Coursework or project experience with programming languages such as Python, Java, or SQL
 Basic understanding of database concepts and data manipulation
 Exposure to big data platforms (e.g., Spark), cloud services (AWS, Azure, or GCP), or machine learning concepts through coursework or personal projects
 Ability to establish strong relationships with key stakeholders critical to success, both internally and externally
 Strong verbal and written communication skills
 Ability to quickly ramp on new systems and processes
 Demonstrated strong interpersonal, analytical and problem-solving skills
 Ability to work in teams and collaborate effectively with people in different functions
 Ability to take the initiative and drive for results
 Strong time management skills that enable on-time project delivery"," Currently pursuing an undergraduate or graduate degree in Electrical Engineering, Computer Engineering, Computer Science, Data Science, or related field
 Cumulative 3.0/4.0 GPA or higher"," Coursework or project experience with programming languages such as Python, Java, or SQL
 Basic understanding of database concepts and data manipulation
 Exposure to big data platforms (e.g., Spark), cloud services (AWS, Azure, or GCP), or machine learning concepts through coursework or personal projects
 Ability to establish strong relationships with key stakeholders critical to success, both internally and externally
 Strong verbal and written communication skills
 Ability to quickly ramp on new systems and processes
 Demonstrated strong interpersonal, analytical and problem-solving skills
 Ability to work in teams and collaborate effectively with people in different functions
 Ability to take the initiative and drive for results
 Strong time management skills that enable on-time project delivery",Not stated
77,Colin Horwedel,,LinkedIn,Data Scientist - Digital,Full Time,Abercrombie & Fitch,"Columbus, Oh",remote,2/8/2026,https://www.linkedin.com/jobs/search/?currentJobId=4318508931&geoId=103644278&keywords=palantir&origin=JOB_SEARCH_PAGE_SEARCH_BUTTON&refresh=true&start=50,"Our Global Data & Analytics (D&A) team is the hub of harvesting and analyzing data to drive strategic business decisions across our brands. By collaborating with partners throughout the organization, associates on our D&A team provide recommendations that allow our teams to push boundaries and stay at the forefront of retail trends

We seek a Data Scientist with a strong focus on digital transformation and Gen AI initiatives. This role will leverage advanced statistical modeling, machine learning and Gen AI techniques to enhance product discovery, personalization and customer experience across our digital channels, which includes but is not limited to product recommendations, intelligent sorting, semantic search and agentic AI solutions. The successful candidate will monetize clickstream and customer data for personalized messaging, conduct deep customer analyses, optimize omni-channel sales, and develop robust modeling and segmentation approaches for diverse digital workstreams. You will partner closely with Digital and Decision Analytics teams to support advanced analytics needs, shaping a holistic view of the business and elevating every aspect of the customer journey, from front-end web and store experience to order fulfillment and customer service.",bachelor's,Not stated,"Design and implement innovative machine learning and Gen AI solution for product and content discovery, personalization and customer engagement.
Develop and deploy generative AI solutions (e.g., language and vision models, agentic AI) to enhance and automate digital experiences.
Build predictive models (propensity, lifetime value, customer affinity, churn, etc.) and recommender systems tailored for e-commerce.
Apply advanced modeling techniques, including classification, generalized linear models, decision trees, time series forecasting, clustering, survival analysis, deep learning, and transformer-based architectures.
Integrate new data sources (internal and external) and modalities (clickstream, text, images, audio) into ML and Gen AI pipelines.
Identify and capitalize on opportunities to increase conversion rates, reduce costs, and drive revenue through data-driven solutions.","Bachelor's Degree or related experience
Proficiency in SQL, Python, and R; familiarity with big data platforms, cloud-based ML/AI services, and MLOps best practices. Experience with Databricks and MLflow is preferred.
Experience using foundational text/vision/multimodal models, finetuning foundational models and familiarity with generative AI frameworks (e.g., Hugging Face, Google Vertex AI, Azure AI foundry, LangChain) is highly desirable.
Strong communication skills, with the ability to explain complex technical concepts to both technical and business audiences
Highly motivated/self-starter with a sense of ownership, willingness to learn, and desire to succeed.
Commitment to continuous learning and professional growth in the rapidly evolving field of digital and Gen AI analytics.
Must perform well in high pressure situations, balance competing priorities, and demonstrate the ability to work without direct supervision.","Bachelor's degree, Proficiency in SQL, Python, and R, ML/AI services, MLOps best practices, Experience with foundational text/vision/multimodal models, communication skills, ability to explain complex tasks, motivated, commitment to continuous learning, perform well in high stress situations","Experience with Databricks and MLflow, experience with generative AI frameworks, ",75k-85k/yr
78,Colin Horwedel,,LinkedIn,Data Scientist - Machine Learning,Full Time,United Airlines,"Chicago, Il",onsite`,2/8/2026,https://www.linkedin.com/jobs/search/?currentJobId=4369635444&geoId=103644278&keywords=palantir%20data&origin=JOB_SEARCH_PAGE_SEARCH_BUTTON&refresh=true,"United's Digital Technology team is comprised of many talented individuals all working together with cutting-edge technology to build the best airline in the history of aviation. Our team designs, develops and maintains massively scaling technology solutions brought to life with innovative architectures, data analytics, and digital solutions. Job overview and responsibilities Provides mathematical modeling and analysis services to support critical financial, operational, and/or strategic planning decisions and engages in supporting project teams in value added activities that generate practical solutions to complex business problems, explores new business alternatives, and drives improvement in business decisions

 Develops the approach and methods to define and solve management problems through quantitative analysis and analytical models using machine learning, statistical, and structured programming languages
 Identifies, researches, or solves large complex problems using big data and machine learning principles
 Leverages understanding of the business process to identify and implement predictive and prescriptive solutions that will result in significant bottom-line contributions
 Builds and develops machine learning model applications, and provides client support leveraging machine learning knowledge
 Participates in model design, prototype, and model development for several efforts that occur simultaneously, and interfaces with product delivery groups
 Raises concerns when scope of analysis may not align with time available and can choose an appropriate scope of analysis to conduct balancing ROI to time available
 Designs analytic plan/develop hypotheses to test; understands limitations of analysis (what it can and cannot be used for)
 Anticipates working team questions to data and approach
 Identifies solution quality risks and on-time risks
 Understands the business value, process, and expectations before focusing on choice of a technical solution
 Understands the intuition behind the numbers (i.e. does it make sense?)
 Provides on-going analytical services to client organizations
 Communicates results to management and clients
 Contributes deck content and builds the story for the deck with guidance to summarize findings
 Develops and delivers presentations aligned with Analytics & Innovation team standards
 Speaks in a manner appropriate for working team and their level +1
 Keeps informed about the latest analytical methods and research in machine learning, data science, and other analytics fields
 Research and socialize tools and techniques in data science, ensuring best practices are applied at United",master's,Not stated,"Develops the approach and methods to define and solve management problems through quantitative analysis and analytical models using machine learning, statistical, and structured programming languages
 Identifies, researches, or solves large complex problems using big data and machine learning principles
 Leverages understanding of the business process to identify and implement predictive and prescriptive solutions that will result in significant bottom-line contributions
 Builds and develops machine learning model applications, and provides client support leveraging machine learning knowledge
 Participates in model design, prototype, and model development for several efforts that occur simultaneously, and interfaces with product delivery groups
 Raises concerns when scope of analysis may not align with time available and can choose an appropriate scope of analysis to conduct balancing ROI to time available
 Designs analytic plan/develop hypotheses to test; understands limitations of analysis (what it can and cannot be used for)
 Anticipates working team questions to data and approach
 Identifies solution quality risks and on-time risks
 Understands the business value, process, and expectations before focusing on choice of a technical solution
 Understands the intuition behind the numbers (i.e. does it make sense?)
 Provides on-going analytical services to client organizations
 Communicates results to management and clients
 Contributes deck content and builds the story for the deck with guidance to summarize findings
 Develops and delivers presentations aligned with Analytics & Innovation team standards
 Speaks in a manner appropriate for working team and their level +1
 Keeps informed about the latest analytical methods and research in machine learning, data science, and other analytics fields
 Research and socialize tools and techniques in data science, ensuring best practices are applied at United","Qualifications

What’s needed to succeed (Minimum Qualifications):

 Master’s degree in quantitative field (machine learning, data science, statistics, engineering, etc.)
 Coursework or work experience with mathematical programming techniques
 Coursework or work experience implementing supervised machine learning to real-world tabular data use cases
 Hands-on experience with ML and statistical modeling in applied projects
 Strong Python software engineering skills with a focus on object-oriented programming and GitHub usage
 Proficiency in SQL for analytical tasks and data manipulation
 Ability to identify high-value opportunities and efficiently apply data science techniques to drive business impact
 Strong ownership mindset, with the ability to work independently and collaborate across teams, including with SMEs and stakeholders, without direct supervision
 Demonstrated intellectual curiosity, with a proactive approach to solving complex problems and a willingness to navigate ambiguity
 Excellent oral and written communication skills, with the ability to clearly explain algorithms, modeling techniques, and data-driven insights to diverse audiences
 Good business, technical, verbal/written communication, presentation and sales skills. Adaptability to changing business environment
 Good interpersonal skills and ability to interact with clients
 Proficient with MS Office
 Must be legally authorized to work in the United States for any employer without sponsorship
 Successful completion of interview required to meet job qualifications
 Reliable, punctual attendance is an essential function of the position

What will help you propel from the pack (Preferred Qualifications):

 Supervised computer vision (object detection) & NLP
 Signal processing & machine learning applied to sensor data
 Causal ML (DML, DR, etc.)
 Probabilistic programming (Pyro, PyMC, Stan, etc.) and Bayesian modeling
 AWS cloud stack experience
 PySpark
 Docker
 Generative AI
 Demonstrated ability to create business value"," Master’s degree in quantitative field (machine learning, data science, statistics, engineering, etc.)
 Coursework or work experience with mathematical programming techniques
 Coursework or work experience implementing supervised machine learning to real-world tabular data use cases
 Hands-on experience with ML and statistical modeling in applied projects
 Strong Python software engineering skills with a focus on object-oriented programming and GitHub usage
 Proficiency in SQL for analytical tasks and data manipulation
 Ability to identify high-value opportunities and efficiently apply data science techniques to drive business impact
 Strong ownership mindset, with the ability to work independently and collaborate across teams, including with SMEs and stakeholders, without direct supervision
 Demonstrated intellectual curiosity, with a proactive approach to solving complex problems and a willingness to navigate ambiguity
 Excellent oral and written communication skills, with the ability to clearly explain algorithms, modeling techniques, and data-driven insights to diverse audiences
 Good business, technical, verbal/written communication, presentation and sales skills. Adaptability to changing business environment
 Good interpersonal skills and ability to interact with clients
 Proficient with MS Office
 Must be legally authorized to work in the United States for any employer without sponsorship
 Successful completion of interview required to meet job qualifications
 Reliable, punctual attendance is an essential function of the position"," Supervised computer vision (object detection) & NLP
 Signal processing & machine learning applied to sensor data
 Causal ML (DML, DR, etc.)
 Probabilistic programming (Pyro, PyMC, Stan, etc.) and Bayesian modeling
 AWS cloud stack experience
 PySpark
 Docker
 Generative AI
 Demonstrated ability to create business value",94k-122k/yr
79,Ananya Sharma,,LinkedIn,Data Engineer,Full Time,Netflix,"Los Gatos, CA",hybrid,2/1/2026,https://www.linkedin.com/jobs/view/data-engineer-l5-games-at-netflix-4313842380,"As a Senior Data Engineer, your focus will be on architecting the foundation for all business measurements across our games portfolio on all platforms.
Own Core Metric Systems: Design, develop, and maintain the single source of truth for core business and operational metrics (e.g., DAU/MAU, retention, engagement rates). Ensure metric consistency, explainability, and reliability for high-stakes business decisions.
Data Modeling Architecture: Create advanced analytical data models (facts, dimensions, aggregations) optimized for performance, partitioning, and backfill considerations.
Implement High-Reliability Pipelines: Build and optimize robust, high-volume data pipelines using distributed processing frameworks like Spark, Flink, Python, and Scala. Master complex processing patterns (batch, CDC, incremental loads, upserts) and address challenges like event-time partitioning, late data handling, and windowing for real-time applications.
Data Governance and Quality Leadership: Define and enforce data quality standards (accuracy, completeness, consistency, validity) at scale. Implement data lineage tracking and monitor metadata to provide the necessary context for interpreting core metrics.
Strategic Collaboration: Partner with Games Product, Data Science, and Engineering stakeholders to translate their forecasting, research, and analytical needs into scalable data solutions. Collaborate on strategies for metric collection, dashboarding, and integration with analytical tools.
Technical Leadership: Proactively identify and resolve technical debt, increase automation, and champion best practices in data engineering and software development across the team. Mentor junior team members and help raise the technical bar for the entire DSE organization.","bachelor’s or master’s degree in computer science, engineering, or related technical field (implicit requirement based on technical qualifications)",Typically 5+ years,"Build scalable data pipelines and distributed systems

Develop batch and real-time data processing solutions

Model data to support analytics and machine learning

Work with distributed systems and large-scale datasets

Collaborate with data science, engineering, and business teams","Experience: 7+ years of hands-on experience in software development with a deep focus on building high-performance data systems that collect, process, and govern high-volume telemetry data for analytics.
Technical Expertise (The Core Domain):
Expert-level Data Modeling: Proven mastery of telemetry (event schema design) and analytical modeling (dimensional modeling, aggregation strategies, partitioning considerations).
Distributed Processing Mastery: Demonstrated experience building production-grade data pipelines using distributed processing frameworks (e.g., Spark, Flink, Hive/Hadoop), with a strong understanding of distributed systems and performance optimization.
Advanced Data Processing: Direct experience with complex batch and streaming data processing patterns, including CDC, incremental loads, event-driven architectures, and robust error handling.
Programming & SQL: Expert-level programming proficiency in Python and/or Scala/Java and mastery of SQL. You maintain a strong software engineering mindset.
Partnership and Leadership:
Strong Partnership Skills: Exceptional communication skills and a proven ability to collaborate effectively with non-technical stakeholders to ensure metrics are accessible, reliable, and actionable.
Proven ability to drive and own complex, cross-functional engineering projects with a high degree of autonomy.
Humble confidence and the awareness to recognize when to course-correct, valuing continuous learning and improvement.","Strong programming skills (Python, Java, or Scala)

Strong SQL skills

Experience with distributed systems

Experience with Spark or Flink

Data modeling experience","Experience with large-scale distributed architectures

Strong debugging and documentation skills

Experience supporting machine learning pipelines","$150,000-$200,000"
80,Ananya Sharma,,LinkedIn,Data Engineer,Full Time,Meta,"Menlo Park, CA",hybrid,2/12/2026,https://www.linkedin.com/jobs/view/data-engineer-par-at-meta-4363974939,"Meta’s Products & Applied Research (PAR) team is where product-focused research meets real-world impact, taking breakthrough AI research and transforming it into products that reach billions. As part of Meta Superintelligence Labs (MSL), we’re driving the transformation of Meta’s core experiences—across Facebook, Instagram, WhatsApp, Threads, and beyond—by applying cutting-edge research to real-world products at massive scale.We are looking for a Data Engineer to join our PAR organization where your technical skills and analytical mindset will be utilized designing and building some of the world's most extensive data sets, helping to craft experiences for billions of people and hundreds of millions of businesses worldwide.In this role, you will collaborate with software engineering, data science, and product management teams to design/build scalable data solutions across Meta to optimize growth, strategy, and user experience.You will be at the forefront of identifying and solving some of the most interesting data challenges at a scale few companies can match. By joining Meta, you will become part of a world-class data engineering community dedicated to skill development and career growth in data engineering and beyond.Data Engineering: You will guide teams by building optimal data artifacts (including datasets and visualizations) to address key questions. You will refine our systems, design logging solutions, and create scalable data models. Ensuring data security and quality, and with a focus on efficiency, you will suggest architecture and development approaches and data management standards to address complex analytical problems.Product leadership: You will use data to shape product development, identify new opportunities, and tackle upcoming challenges. You'll ensure our products add value for users and businesses, by prioritizing projects, and driving innovative solutions to respond to challenges or opportunities.Communication and influence: You won't simply present data, but tell data-driven stories. You will convince and influence your partners using clear insights and recommendations. You will build credibility through structure and clarity, and be a trusted strategic partner.","bachelor’s degree in computer science, computer engineering, or related technical field",4+ years,"Design and build scalable data pipelines

Create data models and datasets

Build ETL pipelines

Maintain data quality and reliability

Collaborate with engineering and product teams

Create data visualizations","Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience
4+ years of experience where the primary responsibility involves working with data. This could include roles such as data analyst, data scientist, data engineer, or similar positions
4+ years of experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)","Bachelor’s degree in technical field

4+ years data-related experience

SQL experience

Programming experience (Python, C++, Scala, or similar)

Data modeling experience","Master’s degree in STEM field

Large-scale data system experience

ETL pipeline experience","$147,000 – $208,000 per year"
81,Ananya Sharma,,LinkedIn,Data Scientist,Full Time,PayPal,"Chicago, IL",hybrid,2/9/2026,https://www.linkedin.com/jobs/view/software-engineer-at-paypal-4361894210?position=6&pageNum=0&refId=o%2BWgueWypJjXAPgNIv1cpQ%3D%3D&trackingId=25M9DRAVVWt9TzBHQt1F%2Fw%3D%3D,"Job Description Summary:
The Credit Platform team builds the core foundation behind PayPal’s global credit ecosystem, powering PayPal’s credit products like Credit Cards, Buy Now Pay Later, Working Capital, and Merchant Term Loans for millions of customers and businesses worldwide. Our team supports credit products across the United States, Canada, the United Kingdom, France, Italy, Spain, Germany, and Australia, with plans to expand into additional markets in 2026. We own and develop core credit business capabilities through well-defined RESTful APIs that support the end-to-end credit application journey, from offers and eligibility through application, account management, and asset externalization. Our platform enables consistent and scalable credit experiences across products and markets.

Job Description:
Essential Responsibilities:

Implements tasks within the Software Development Lifecycle (SDLC), receiving structure and oversight from more experienced staff
Follows well-established internal conventions and standard procedures
Understands internal standards & processes an applies them to make technical decisions
Collaborates with peers, manager, and project lead to gain understanding of tasks and review solutions
May contribute to code & design reviews
","bachelor’s degree or higher in computer science, engineering, or related field",1+ years relevant experience (Expected qualifications)     3+ years preferred professional software engineering experience,"Design and build backend services for PayPal credit platform

Develop RESTful APIs and microservices

Maintain and support distributed backend systems

Write secure, reliable, and scalable code

Participate in code reviews and system design discussions

Monitor and support production systems

Improve performance and scalability","Bachelor’s degree in Computer Science, Engineering, or related field

Experience with Java and backend development

Experience building REST APIs

Experience with relational or NoSQL databases

Strong SQL and data modeling skills

Experience with distributed systems","Bachelor’s degree in Computer Science or related field

Java programming experience

REST API development experience

SQL and database experience

Backend development experience","Experience with cloud platforms (AWS or GCP)

Experience with distributed systems

Experience in financial services or payments

Experience with Kafka or event-driven systems","$100,500 – $157,300 per year"
82,Ruhi Ashley,,LinkedIn,Data Scientist,Full Time,SynergisticIT,"Boston, MA",remote,2/13/2026,https://www.linkedin.com/jobs/view/4371704584/?alternateChannel=search&refId=NotAvailable,"Entry-level full-time position supporting client projects in data science, machine learning, data engineering, and software development. Role focuses on helping recent graduates transition into industry roles by applying programming, data, and software engineering skills in real-world environments. Candidates work with modern tech stacks including Java, Python, AI, and data tools to support client technical needs.",bachelor's,"0–2 years (entry level, recent grads accepted)","Develop and support software and data science solutions using Java, Python, and related technologies. Work with client teams on data science, machine learning, and software development projects. Apply technical and programming skills to real-world business problems. Build and maintain applications using full stack, data engineering, and ML tools.","Recent graduates in CS, Engineering, Math, or Statistics with limited or no job experience. Candidates interested in Data Science, Machine Learning, Data Engineering, or Software Development roles. Knowledge of Java or Python. Candidates seeking entry-level full-time positions with client companies. Strong technical foundation and willingness to learn modern tech stack.","Bachelor’s or Master’s degree in Computer Science, Engineering, Math, Statistics, or related field
Knowledge of Java or Python
Basic programming and technical skills
Interest in data science, software development, or machine learning","Experience with Data Science, Machine Learning, or Data Engineering tools
Knowledge of Full Stack Development or DevOps
Strong problem-solving skills
Relevant academic projects, coursework, or certifications","$82,000 – $128,000"
83,Ruhi Ashley,,LinkedIn,AI Engineer,Full Time,Jobright.ai,USA,remote,2/14/2026,https://www.linkedin.com/jobs/view/4364426786/?alternateChannel=search&eBP=CwEAAAGcZQcbV1bc9XNqgvPfxlw6MLUwkslQzk0SlRvK8N7X0XVlu_dDXrbLz-ViJk-RFnyOXqxKtKP2eVe2P7tkBoJePK-JqZ3b1YXUBMvRQ5j4KyInpVt4gVobT0f3C7x36UWQOFuMe1sOtyOeoSBzTpzN_8JAH4WKsnQ-zLCREN9vxnnvqZNzNvMc8ZKOwWy5J1IrX86bHMq5jXp9iyW-VqU4diihL8CEEKm8L_ZQhCJO-apZPN5d36uLlQ_zGD7t4Fi2reS1Pog_sHLdMQ59GptLCtB32pToX95LsSnrjY7gvFYtk3NIX3oexm6PPStCgffjTG3ibSPnCfEC-3LRpcNlcBWpMnK7Q9esWm-BAOprqi4pMk8kwg1fu6WAYAkeJkj5SCSPqTXZ_3PK5JrfGdSPKGkNZbxd1R8_Cuti0Dae847ikgGYYGqR9yzz2zLyFBb-Aa9izuS1uPddXPyTGaYFp-HjVeeCaxU6sFyuWjaDGC6X44GtcjF8RWsqQbpypfIdf9bq7-JahsSM5pvHny71r4t02IbTbxXvAc1HsoI-2hk&refId=MxiRJSC3I2IgILWYo4NGSw%3D%3D&trackingId=TxOKEvanAOrog0JNVGIpRg%3D%3D,"Entry-level AI Engineer responsible for building and scaling AI agents used in production. Role involves developing autonomous AI agents, integrating large language models into applications, implementing retrieval-augmented generation systems, and improving AI performance and reliability. Engineer works across product and engineering teams to build AI-driven features and deploy production-ready AI solutions.","bachelor’s degree in computer science, artificial intelligence, or related technical field",0–2 years,Build and refine autonomous AI agents to solve real-world problems. Develop prompt engineering workflows and multi-agent systems. Integrate large language models into applications. Implement retrieval-augmented generation systems and fine-tune models. Work with product and engineering teams to develop AI-driven features.,"Recent graduate or entry-level professional with degree in Computer Science, AI, or related field. Strong Python skills and experience with large language model APIs. Understanding of generative AI workflows, prompt engineering, and agent systems. Knowledge of APIs, asynchronous programming, and Git. Must be authorized to work in the United States.","Bachelor’s degree in Computer Science, AI, or related field
0–2 years experience
Strong proficiency in Python
Experience working with LLM APIs
Knowledge of APIs, asynchronous programming, and Git
Authorization to work in the United States","Internship or project experience building AI applications or agents
Experience with LangChain, AutoGPT, or CrewAI
Experience with vector databases and semantic search
Basic front-end or full-stack integration knowledge",Not specified
84,Ruhi Ashley,,LinkedIn,Software Engineer,Full Time,Intuit,"Atlanta, Georgia",onsite,2/2/2026,https://www.linkedin.com/jobs/view/4333433471/?alternateChannel=search&eBP=CwEAAAGcZQcbV-v0oVllMas6LUWPvFNpJfWxulf2k7lHmIRn6Y9yci3K0VIaY8ZscMKoYHtUgE5hZr5ejA-RY_ueCVCnBQ9HqmR8ia8bB43M2qKiKEcfQEmvVV_fEMHdh8toG0P_DyXBrSB7UPYOj_IOoMeiRoIc8gjUyYs_kjlBeRb9N-6A04ohlKie5vMgZQCAhFWNxcIOFXUY_-hWMXFQnwVLbG1PU-coaY-G89rpqTcx9NHLkCqo-heBVNX3y_2jTYpl8m7L5wMAQv5wTJfZ5xa-NAk_zlNUpIF-e25ux7Duden3Jc_gPfE7WjsxtHtI6gftmdEsMmLwPYTzVf70wdAiqMy19RF50_H2eM95Jy21Yo1CY5rfKeDM444qvUWCbC0fxVHawAYpG4WenuJE1aqgv4tosL61RqcH5kT-CEfkLmyTv-lY5xlrVbMqj4qxxa2WEEBi_y678L9FOg5DNIayTmHK-RIO6WWBhXgIxtGm_DOcAEyxSsj7yTxjwdf8&refId=MxiRJSC3I2IgILWYo4NGSw%3D%3D&trackingId=sB3%2FBGocZZs8pwLFcQTWQA%3D%3D,"Entry-level Software Engineer responsible for developing and supporting cloud, platform, mobile, and SaaS applications used by millions of customers. Role involves working on frontend, backend, full stack, or mobile engineering teams to build scalable applications, integrate APIs, and contribute to product development. Engineers collaborate with cross-functional teams, apply software engineering best practices, and help deliver impactful software solutions while growing technical skills.",bachelor’s or master’s degree in computer science or related technical field,0–2 years,"Develop scalable web, mobile, and cloud applications. Work on frontend, backend, full stack, or mobile engineering tasks. Build and integrate APIs and database systems. Collaborate with engineers, designers, and product teams. Apply software development best practices and Agile methodologies. Contribute to software products and engineering systems.","Bachelor’s or Master’s degree in Computer Science or related field. Foundational understanding of programming, Agile development, and object-oriented design. Experience through coursework, internships, or personal projects with programming languages such as Java, Python, JavaScript, or C++. Knowledge of frontend technologies, APIs, and software development tools. Strong collaboration and communication skills.","Bachelor’s or Master’s degree in Computer Science or related technical field
Foundational programming knowledge
Experience with at least one programming language
Understanding of Agile development and software design principles
Strong teamwork and communication skills","Experience with frontend frameworks such as React, Angular, or Vue
Experience with backend development using Java, Python, or Node.js
Knowledge of databases such as MySQL, PostgreSQL, or MongoDB
Experience with Git and software development tools
Understanding of mobile development or cloud-based applications","$115,000 – $156,000"
85,Ruhi Ashley,,LinkedIn,Python Developer,Full Time,Emonics LLC,New York,onsite,2/12/2026,https://www.linkedin.com/jobs/view/4371151797/?alternateChannel=search&eBP=CwEAAAGcZQcbWMBzZoFTYkUgzyriwMQXDkdb78poZI8hlXplECQj7C7bGuspmxBuojSwrilRZHD6h9yl_7YWIm5PKhr9dOTpKv7z4PpamTukzW6ZZ2KG-mIbLjU8JCUYc7R3NyRaqimdPbgQofp5kefQhFhz4rZ0d8QNtWH8X2pFssFQJMVlHQRYbwpYDzfSiERzHyGyRiD2PU8EdeIBErf69mnvVAMT83AMB1pAJUtZUNxD6DNceuLq9pPEBpsuqdyMjPB9PlFt4oAsBtCf-2KpXdP4oCTCNE0Fz33zvM9S9eH-0cySwhwj6Rp4rAGuc0cxqlNtVWzFPfieh0ndE2JTD9UesWQqApGcqnzQBA84yUY65ILfyvvUsUokUJ2pyR7TnT1nuM_1yjILui-Oxn458t9rCoA6kIWjQ7pEszCw7X5ee-Ju3sSciqxJ1Ep21kyccK0ZVcSUGYwRfP3nkj9MV8ovJ0rn3EubxLMNKwTzUassDyJGpmwPe7_2HQBj-sRhRSTWE7_KuGqAwo6-4NbYWsD-R-1z45L2HIVJ08isKZhJ-pPJ5_gA&refId=MxiRJSC3I2IgILWYo4NGSw%3D%3D&trackingId=M4l%2Bqdc2TGM06ojBxraDVA%3D%3D,"Entry-level Python Developer responsible for building and maintaining backend services, automation systems, and data-driven applications. Role involves developing Python scripts and APIs, working with databases, fixing bugs, improving performance, and collaborating with engineering teams in an Agile environment to support software and data solutions.",bachelor’s degree in computer science or related technical field,0–2 years,"Develop Python backend services, scripts, and APIs. Work with databases to store, query, and manage data. Write unit tests and participate in code reviews. Fix bugs and improve software performance. Collaborate with product and engineering teams in an Agile environment.","Strong Python fundamentals including data structures, functions, and object-oriented programming. Familiarity with REST APIs and JSON. Basic SQL and database knowledge. Experience using Git and willingness to learn software development best practices.","Strong Python programming fundamentals
Understanding of data structures and object-oriented programming
Knowledge of REST APIs and JSON
Basic SQL and database knowledge
Experience using Git","Experience with FastAPI, Flask, or Django
Experience with cloud platforms, Docker, or CI/CD
Familiarity with data tools such as pandas
Experience with automation scripting",Not specified
86,Vihaan Ketavarapu,,Indeed,Data Scientist,Full time,Data Xpander,Dallas,onsite,2/1/26,https://www.indeed.com/m/viewjob?jk=cdaa9e9635b3200e&from=serp&mclk=default&xpse=SoAf67I3ny1WhGyen50LbzkdCdPP&xfps=f697a785-7434-4190-b7af-6e2a8d5331dc&xkcb=SoC867M3ny1fGWSO650MbzkdCdPP,Entry level data scientist,bachelors degree in software or statistics related field ,0-2 years,Develop predictive modeling and algorithms,Strong software and analytics mind with mathematical reasoning and programming expertise,Not specified,Experience with databases but mostly unspecified,Not specified
87,Vihaan Ketavarapu ,,LinkedIn,Data Scientist,Full time,Toyota,Plano,hybrid,2/9/26,https://www.linkedin.com/jobs/view/4320766131/,Entry level data scientist,masters degree in relevant field,0-2 years,"Extract, manipulate, and clean data from diverse sources using SQL and Python, preparing it for detailed analysis and model development. 

Develop and implement sophisticated predictive and prescriptive models using statistical and machine learning techniques. Ensure these models address key business challenges and deliver actionable insights","Master degree and Knowledge of methods like Logistic Regression, Time Series Analysis, GLMs, Mixed Modeling, Multivariate Statistics, Predictive Modeling, Decision Trees, Gradient-Boosted Trees, Random Forests, and Neural Networks. ","Knowledge of methods like Logistic Regression, Time Series Analysis, GLMs, Mixed Modeling, Multivariate Statistics, Predictive Modeling, Decision Trees, Gradient-Boosted Trees, Random Forests, and Neural Networks. ","Experience with version control systems such as GitHub, and familiarity with CI/CD practices to streamline model deployment and code management. 

Hands-on experience with cloud-based machine learning platforms (e.g., AWS SageMaker or Azure ML) to leverage scalable computing resources and tools.",Not specified
88,Vihaan Ketavarapu ,,LinkedIn,Staff Data Scientist,Full time ,Gartner,"Irving, TX",hybrid,2/2/26,https://www.linkedin.com/jobs/view/4344576100/,Entry level Data Scientist,bs in related field ,2-4 years ,"Designing and implementing state of the art Large Language Model (LLM) based agents that seamlessly synthesize complex information and initiate important actions in a business workflow.
· Using advanced Generative AI techniques deriving actionable insights from unstructured text data, such as call transcripts and emails.
· Predicting client interest basis their digital footprint and making relevant recommendations to drive higher client value delivery
· Leverage statistical and machine learning techniques to extract actionable insights from client retention data.","
· BS required/ MS/ preferred; in Computer Science or other technology, Math, Physics, Statistics or Economics (focus on Natural Language Processing, Information Retrieval a plus)
· 4 years’ experience in data science methodologies as applied to live initiatives or software development// Experience working with Gen AI projects
· Minimum 4+ years of experience in python coding and statistical analysis
· Minimum 2 years working experience in several of the following:
o Prompt Engineering and working with LLMs
o Machine Learning and statistical techniques
o Data mining and recommendation systems
o Natural Language Processing and Information Retrieval
o Experience working with large volumes of data
o User behavior modeling","
· BS required/ MS/ preferred; in Computer Science or other technology, Math, Physics, Statistics or Economics (focus on Natural Language Processing, Information Retrieval a plus)
· 4 years’ experience in data science methodologies as applied to live initiatives or software development// Experience working with Gen AI projects
· Minimum 4+ years of experience in python coding and statistical analysis
· Minimum 2 years working experience in several of the following:
o Prompt Engineering and working with LLMs
o Machine Learning and statistical techniques
o Data mining and recommendation systems
o Natural Language Processing and Information Retrieval
o Experience working with large volumes of data
o User behavior modeling",MS in related field,98K-133K
89,Yohan Arul,,Indeed,Data Engineer-AI trainer,Contract,DataAnnotation,"Seattle, WA",remote,,https://www.indeed.com/viewjob?jk=ae7f85a0838b0707&from=shareddesktop_copy,"This role involves creating and solving coding problems to help train and improve AI systems, while evaluating and providing feedback on AI-generated code. It requires strong programming skills, clear written communication, and offers flexible, remote contract work paid hourly.",bachelors degree in software or statistics related field ,Not stated,Design and solve diverse coding problems used to train AI systems.,"Fluent in english, bachelors degree, ability to write code well.","Fluent in english, bachelors degree, ability to write code well.","Fluent in english, bachelors degree, ability to write code well.",Not specified
90,Yohan Arul,,Linkedln,Data Scientist,Full time,Chord energy,"Houston, TX",hybrid,11/1/2026,https://www.linkedin.com/jobs/view/4308829874,"The Chord Energy Data Scientist role is a technical individual contributor role, focused on supporting business opportunities through the use of exploratory data analytics, machine learning models and generative AI opportunities.",masters or bachelors degree in data science,5+ Years,"The primary responsibility involves leading and participating in multi-disciplinary projects aimed at providing business solutions to a diverse set of problems ranging from, but not limited to, production automation/optimization, drilling and completion process optimization, back-office process improvement and automation, dashboard generation and deployment, and computer vision aided operations.","Master's or Bachelor's degree in Data Science, Computer Science, or related field
5+ years in data science/ML (including time-series, geospatial, and predictive modeling)
Proven experience and/or education in data analytics and management of large datasets
Proficiency in Python (pandas, scikit-learn) and SQL; experience with Azure ML/MLflow and deploying models to production.
Domain familiarity with upstream oil & gas workflows (subsurface and operations) and the ability to translate expert knowledge into features and experiments.
Strong interpersonal and collaborative skills
Demonstrated ability to work in a team-oriented environment
Excellent presentation skills
Ability to work in a fast-paced and fluid environment; flexible with the demands of a growing company
Strong coaching, prioritization, and stakeholder-management skills; able to convert business problems into robust, scalable model solutions and communicate outcomes clearly.
Ability to meet deadlines
Physical Requirements and Working Conditions: Must possess mobility to work in a standard office setting and to use standard office equipment, including a computer, stamina to maintain attention to detail despite interruptions, strength to lift and carry files weighing up to 10 pounds; vision to read printed materials and a computer screen, and hearing and speech to communicate in person and over the telephone","Master's or Bachelor's degree in Data Science, Computer Science, or related field
5+ years in data science/ML (including time-series, geospatial, and predictive modeling)
Proven experience and/or education in data analytics and management of large datasets
Proficiency in Python (pandas, scikit-learn) and SQL; experience with Azure ML/MLflow and deploying models to production.
Domain familiarity with upstream oil & gas workflows (subsurface and operations) and the ability to translate expert knowledge into features and experiments.
Strong interpersonal and collaborative skills
Demonstrated ability to work in a team-oriented environment
Excellent presentation skills
Ability to work in a fast-paced and fluid environment; flexible with the demands of a growing company
Strong coaching, prioritization, and stakeholder-management skills; able to convert business problems into robust, scalable model solutions and communicate outcomes clearly.
Ability to meet deadlines
Physical Requirements and Working Conditions: Must possess mobility to work in a standard office setting and to use standard office equipment, including a computer, stamina to maintain attention to detail despite interruptions, strength to lift and carry files weighing up to 10 pounds; vision to read printed materials and a computer screen, and hearing and speech to communicate in person and over the telephone","Master’s degree or PHD or certification in Data Science or Data Analytics
Familiarity with additional programming languages (SQL, R, C++, etc.)
Previous Oil and Gas operator experience
Exposure to Petroleum Engineering and Geoscience workflows
Exposure to the energy sector, particularly unconventional exploitation programs",Not specified
91,Yohan Arul,,Linkedln,Data Engineer,Full time,"Scribd, Inc.","Houston, TX",hybrid,2/9/2026,https://www.linkedin.com/jobs/view/4317982162,"Scribd’s Data Platform team builds the data pipelines, storage layers and developer tooling that power analytics, experimentation, ML and product features across Scribd, Everand and Slideshare.",bachelors degree in software or statistics related field ,8+ years,"As a Staff Data Engineer, you’ll be both a hands-on technical expert and a strategic leader. You’ll drive the design of core data models and pipelines in our Databricks/Delta Lake lakehouse, setting the standards for quality, reliability, and scalability across the platform.","8+ years of experience in data engineering, with a strong background in data architecture, data modeling, and distributed data systems.
Deep expertise in Databricks, Delta Lake, Spark, and modern lakehouse technologies.
Advanced proficiency in SQL and Python or Scala, including performance optimization and large-scale ETL design.
Proven experience designing data models and schemas that serve multiple downstream use cases (analytics, ML, APIs).
Experience implementing modern data orchestration patterns for big data use-cases, including batch and streaming workloads.
Demonstrated ability to lead technical initiatives, set standards, and influence decisions across teams.
Comfort owning systems end-to-end, including monitoring, reliability, and cost management.
Excellent communication skills with the ability to translate technical trade-offs to both engineers and non-technical stakeholders.","8+ years of experience in data engineering, with a strong background in data architecture, data modeling, and distributed data systems.
Deep expertise in Databricks, Delta Lake, Spark, and modern lakehouse technologies.
Advanced proficiency in SQL and Python or Scala, including performance optimization and large-scale ETL design.
Proven experience designing data models and schemas that serve multiple downstream use cases (analytics, ML, APIs).
Experience implementing modern data orchestration patterns for big data use-cases, including batch and streaming workloads.
Demonstrated ability to lead technical initiatives, set standards, and influence decisions across teams.
Comfort owning systems end-to-end, including monitoring, reliability, and cost management.
Excellent communication skills with the ability to translate technical trade-offs to both engineers and non-technical stakeholders.","Experience with subscription, payments, or large-scale consumer data domains.
Familiarity with AWS data services (S3, Glue, EMR, Kinesis) and cloud cost optimization.
Knowledge of streaming architectures (Kafka, Kinesis, or similar).
Experience implementing data quality, governance, and observability standards at scale.
Contributions to open-source projects or thought leadership in the data engineering community.
Experience operationalizing data observability through Datadog or equivalent monitoring tools.
Experience working with Analytics teams to understand their requirements and translate to data products and data solutions.","$167,000 - $260,500"
92,Carson Phillips,,LinkedIn,Junior Data Engineer,Full Time,Mod Op,"Dallas, TX",hybrid,10/16/2025,https://www.linkedin.com/jobs/view/4306635567/,"As a Data Engineer with (1-2) years of experience, you will be responsible for designing and implementing robust data pipelines, optimizing data workflows, and supporting analytics initiatives. You will work with AWS and GCP cloud services, integrate with CRM and marketing platforms, and enable data-driven decision-making through visualization tools like Google Looker and Tableau.",,1-2 years,"Data Pipeline Development: Design, develop, and maintain scalable ETL/ELT pipelines in GCP, Azure & AWS using various services including Data Flow, Composer, Azure Synapse, AWS Data Pipelines and etc Data Integration: Work with structured and unstructured data sources, including CRM and marketing data platforms. Database Management: Develop and optimize queries for SQL & NoSQL databases (Teradata, BigQuery, Cassandra, etc.). Data Science & ML: Implementing Models using GCP Vertex ai and utilizing Python and its data science libraries (Pandas, NumPy, Scikit-learn, etc.) for data analysis and ML model deployment. Data Visualization: Build and manage dashboards using Google Looker and Tableau to provide business insights. Collaboration: Work closely with data analysts, marketing teams, and other stakeholders to understand business needs and implement effective data solutions. The position operates under a hybrid work model, requiring in-office presence at the Grapevine, Texas location two days per week, with the remaining days worked remotely","Required Qualifications: Cloud Expertise: GCP or AWS (Data Engineering or ML focus) experience. Programming Skills: Strong proficiency in Python and experience with its data science libraries. Database Management: Experience with SQL (Teradata, BigQuery, etc.) and NoSQL databases. Data Visualization: Hands-on experience with Google Looker and Tableau for reporting and dashboards. CRM & Marketing Data: Experience working with CRM, marketing platforms, and analytics tools. Machine Learning Knowledge: working GCP/Azure/AWS Services with ML workflows, model training, AI Models and deployment. Data Automation & Transformation: Knowledge with Alteryx for workflow automation and data preparation. Preferred Qualifications: Experience with data warehousing solutions (Snowflake, Redshift, etc.). GCP Certified focused on Data Engineering. Exposure to Apache Spark, Airflow, or other data orchestration tools. Strong understanding of data governance, security, and compliance.","Cloud Expertise: GCP or AWS (Data Engineering or ML focus) experience. Programming Skills: Strong proficiency in Python and experience with its data science libraries. Database Management: Experience with SQL (Teradata, BigQuery, etc.) and NoSQL databases. Data Visualization: Hands-on experience with Google Looker and Tableau for reporting and dashboards. CRM & Marketing Data: Experience working with CRM, marketing platforms, and analytics tools. Machine Learning Knowledge: working GCP/Azure/AWS Services with ML workflows, model training, AI Models and deployment. Data Automation & Transformation: Knowledge with Alteryx for workflow automation and data preparation.","Experience with data warehousing solutions (Snowflake, Redshift, etc.). GCP Certified focused on Data Engineering. Exposure to Apache Spark, Airflow, or other data orchestration tools. Strong understanding of data governance, security, and compliance.",Not specified
93,Carson Phillips,,LinkedIn,Associate Data Engineer ,Full Time,Ascensus,"Boston, MA",hybrid,2/12/2026,https://www.linkedin.com/jobs/view/4371694719/,"As an Associate Data Engineer at Ascensus, you will enable data-driven decision making by collecting, transforming and visualizing the data. You will build, maintain and troubleshoot data processing systems with emphasis on security, reliability, fault",bachelors degree,1,"Responsible for protecting, securing, and proper handling of all confidential data held by Ascensus to ensure against unauthorized access, improper transmission, and/or unapproved disclosure of information that could result in harm to Ascensus or our clients. Our I-Client service philosophy and our Core Values of People Matter, Quality First and Integrity Always® should be visible in your actions on a day to day basis showing your support of our organizational culture. Build Power BI dashboards and reports that translate data into clear, decision-ready insights for stakeholders Build and maintain data structures and data processing systems (tools, infrastructure, frameworks, services). Assist with EIM project definition and planning. Implement and troubleshoot deployments. Data Modeling: Assist with conceptual, logical and physical data models. Update the Entity Relationship diagrams and Dimensional models. Data Integration Services: Build data ingestion tools, metrics, alerts and notifications, metadata management. Build data replication services and Change Data Capture (CDC) processes to incrementally update data in the data warehouse / data marts from Ascensus systems of record. ETL development: Follow standards and best practices for implementing ETL tools in support of the EIM vision and reference architecture. Build and maintain ETL solutions and platform. Participate in creating long term ETL application support model. Data Warehouse and Data Marts: Follow technical standards and specifications addressing performance, security and orchestration of ETL and data warehouse / mart management. Build processes for loading data into and extracting data from the warehouse / marts. Assist with other tasks and projects as assigned","Required Skills And Experience: 1+ years of relevant experience in data/software development, including data warehousing and ETL tools, techniques and technology. Bachelor’s degree or equivalent work experience. Excellent analytical skills. Excellent oral and written communication skills including active listening, asking appropriate questions, clarifying information and writing clear, concise documents. Working experience with SQL. Understanding of data modeling techniques. Understanding of Data Warehousing and ETL design/tools. Working experience with C# Python or other data related programming languages. Experience with PowerBI, Cognos Analytics and Cognos Framework Manager. Preferred knowledge, skills and abilities: Experience with relational databases: SQL Server, Sybase ASE, Oracle, MySQL. Experience with NoSQL databases such as MongoDB, Redis. Experience with Fabric. Experience with data modeling tools like IDERA’s Embarcadero ER/Studio Data Architect. Experience with SSIS. Experience with SSAS.","1+ years of relevant experience in data/software development, including data warehousing and ETL tools, techniques and technology. Bachelor’s degree or equivalent work experience. Excellent analytical skills. Excellent oral and written communication skills including active listening, asking appropriate questions, clarifying information and writing clear, concise documents. Working experience with SQL. Understanding of data modeling techniques. Understanding of Data Warehousing and ETL design/tools. Working experience with C# Python or other data related programming languages.","Experience with relational databases: SQL Server, Sybase ASE, Oracle, MySQL. Experience with NoSQL databases such as MongoDB, Redis. Experience with Fabric. Experience with data modeling tools like IDERA’s Embarcadero ER/Studio Data Architect. Experience with SSIS. Experience with SSAS. Experience with PowerBI, Cognos Analytics and Cognos Framework Manager.",75k-85k
94,Carson Phillips,,LinkedIn,Data Engineer,Full Time,Zoox,"Foster City, CA",hybrid,2/14/2026,https://www.linkedin.com/jobs/view/4342766614/,The Data team leverages data from our autonomous vehicles and operations to determine autonomy and service readiness. We provide the foundation for strategic decision-making at Zoox. You will develop and implement the next generation of our data pipeline to ensure visibility into our business as we scale toward the launch of an autonomous mobility service. You will define the system and build the pipeline to enable Zoox to develop and scale with a data-first culture.,bachelor's degree,Not specified,"Design, build, and maintain the infrastructure that transforms autonomous vehicle data at scale to support analytics throughout the company Define and execute on how data from perception, prediction, planning and other parts of the autonomous stack is consumed to generate valuable insights by data scientists, engineers, and business users Establish robust data integrity monitoring so that company-wide metrics are based on accurate data Partner with engineering and product teams to define data consumption patterns and establish best practices","Qualifications: BS/MS degree in a technical field Experience designing and building complex data modeling at scale Advanced Structure Query Language (SQL) and data warehousing experience Experience operating a workflow manager such as Airflow Experience with large scale streaming platforms (e.g. Kafka, Kinesis), processing frameworks (e.g. Spark, Hadoop) and storage engines (e.g. HDFS, HBase) Bonus Qualifications: Exceptional Python or Scala skills Basic fluency in C++ Familiarity with or exposure to experimentation platforms A strong DataOps mindset and opinions on next-generation warehousing tools","BS/MS degree in a technical field Experience designing and building complex data modeling at scale Advanced Structure Query Language (SQL) and data warehousing experience Experience operating a workflow manager such as Airflow Experience with large scale streaming platforms (e.g. Kafka, Kinesis), processing frameworks (e.g. Spark, Hadoop) and storage engines (e.g. HDFS, HBase)",Exceptional Python or Scala skills Basic fluency in C++ Familiarity with or exposure to experimentation platforms A strong DataOps mindset and opinions on next-generation warehousing tools,153k-230k
95,Navya Vegesna,,LinkedIn,AI Data Engineer,Full time,Deloitte,"Dallas, TX",hybrid,2/14/2026,https://www.linkedin.com/jobs/search-results/?currentJobId=4373205359&eBP=CwEAAAGcZzVGhYnNXRUmDhUJdn0aACLNO7O_EDvkvIufTj3z-aNZXAesHdrKf2bnXFuvCNK7Rl9Po2CBooMSPuZ-7e4Yh9tD9Mu5-9KtK1xBTirVXbyJYEyNMJ__F3wzINn13mq3cm1PPNnnvxfMrLs9zJFUiSJB0HGa_iuM962Ywq8RrXzsfQX50h1SgV6JoWEnMC8H6Faelom82HZx0NHef9vhnaVVKxM1RcM9kMc4YyWKyPim6YpYqBYfnVzRS41Uc8GWWjOqflbs8kR54ybnd2NCBck2vdWepSlMRXOZWh3ik0DWjel0GVkiVKDGyWTdZBiBcnZ65XuiscIIWBaik0a3_zdrDw7jKeg15yolkfjY7ZDSLPP50r8Pcax7KABUdUKrgD3RWbaljMh2qf7-rkA17MK4MCptRakoJu2Rls7qpDx7BMr5eLEUe4_ptZdQM34sf3dTy55X5TBZxb6krCnhHVOzriFlc-Opo6iVeWrCEdqIhibNKXFro6tg8klJ8z7JZuVuEmfv3vp0ryV0ldY8N7aM3FSqsz8&refId=SrUuzTQz%2FTiW%2BMZfHqwiVQ%3D%3D&trackingId=MeYnExNg5DLEMUBFiNp1wg%3D%3D&keywords=Data%20science%20full%20time%20open%20jobs&origin=JOB_SEARCH_PAGE_JOB_FILTER&referralSearchId=Lw78GtZqb9AtrOlPhBllig%3D%3D&f_TPR=r604800 ,,"bachelor’s degree in computer science, engineering, or a relevant discipline.","5+ years designing, building, and operating production-grade data platforms and pipelines using Python and Structured Query Language (SQL), distributed processing (Apache Spark), streaming (Apache Kafka), cloud data services (Microsoft Azure), and data storage across SQL and NoSQL systems.","Lead the design, build, deployment, and operations of analytics platforms that process terabytes of data at scale. Design and implement data ingestion, real-time streaming, batch processing, and extract-transform-load (ETL) pipelines across multiple storage technologies. Tune complex Structured Query Language (SQL) queries and data flows for performance and reliability. Design and operationalize multi-agent Generative AI workflows (planner/worker patterns, tool use, memory, retries/fallbacks) integrated with enterprise data and retrieval services. Build and maintain agent tool backends, including search/retrieval, document ingestion, SQL generation guardrails, and governance checks, with strong observability and quality evaluation. Own the vector retrieval layer, including embedding pipelines, indexing strategies, hybrid search patterns, and latency/throughput optimization for Retrieval-Augmented Generation (RAG). Lead implementation of Zilliz Cloud/Milvus in production, including collection design, partitions, index selection/tuning, bulk ingest patterns, and retrieval performance tuning. Implement MongoDB-based data services for GenAI workloads, including schema design, aggregation pipelines, change streams, and sharding/scale patterns.","Ability to perform job responsibilities within a hybrid work model that requires US Tax professionals to co-locate in person 2 - 3 days per week. Bachelor's degree in computer science, engineering, or a relevant discipline. 5+ years designing, building, and operating production-grade data platforms and pipelines using Python and Structured Query Language (SQL), distributed processing (Apache Spark), streaming (Apache Kafka), cloud data services (Microsoft Azure), and data storage across SQL and NoSQL systems. Proven track record of delivering Retrieval-Augmented Generation (RAG) to production, including embedding generation, vector indexing, hybrid retrieval, and latency/throughput optimization evidenced by shipped features, runbooks, and performance metrics. Demonstrated experience delivering vector databases such as Milvus or Zilliz Cloud to production, including collection design, index tuning, and metadata filtering evidenced by deployed clusters, index configurations, and observed retrieval performance. Hands on experience in the design and operation of MongoDB-based data services, including schema design, aggregation pipelines, indexing strategies, security configuration, and performance tuning. Ability to travel 20%, on average, based on the work you do and the clients and industries/sectors you serve. Limited immigration sponsorship may be available. One of the following active accreditations obtained: Licensed CPA in state of practice/primary office if eligible to sit for the CPA. If not CPA eligible: Licensed Attorney, Enrolled Agent. Technology Certifications: AWS Certified Solutions Architect, Open Group Certified, Architect (Open CA), IASA's Certified IT Architect (Level F or A), Certified SAFe DevOps Practioner, ITIL Certification, Certified Information Systems Security Professional (CISSP), Project Management Professional (PMP), Microsoft Azure","Ability to perform job responsibilities within a hybrid work model that requires US Tax professionals to co-locate in person 2 - 3 days per week. Bachelor's degree in computer science, engineering, or a relevant discipline. 5+ years designing, building, and operating production-grade data platforms and pipelines using Python and Structured Query Language (SQL), distributed processing (Apache Spark), streaming (Apache Kafka), cloud data services (Microsoft Azure), and data storage across SQL and NoSQL systems. Proven track record of delivering Retrieval-Augmented Generation (RAG) to production, including embedding generation, vector indexing, hybrid retrieval, and latency/throughput optimization evidenced by shipped features, runbooks, and performance metrics. Demonstrated experience delivering vector databases such as Milvus or Zilliz Cloud to production, including collection design, index tuning, and metadata filtering evidenced by deployed clusters, index configurations, and observed retrieval performance. Hands on experience in the design and operation of MongoDB-based data services, including schema design, aggregation pipelines, indexing strategies, security configuration, and performance tuning. Ability to travel 20%, on average, based on the work you do and the clients and industries/sectors you serve. Limited immigration sponsorship may be available. One of the following active accreditations obtained: Licensed CPA in state of practice/primary office if eligible to sit for the CPA. If not CPA eligible: Licensed Attorney, Enrolled Agent. Technology Certifications: AWS Certified Solutions Architect, Open Group Certified, Architect (Open CA), IASA's Certified IT Architect (Level F or A), Certified SAFe DevOps Practioner, ITIL Certification, Certified Information Systems Security Professional (CISSP), Project Management Professional (PMP), Microsoft Azure","Experience leading cross-functional engineering teams delivering GenAI-enabled data products. Leadership: Experience leading cross-functional engineering teams delivering GenAI-enabled data products. GenAI orchestration & safety: 2+ years building multi-agent systems (agent graphs, tool-calling, structured outputs) with evaluation, safety guardrails, and observability (tracing, eval pipelines, quality metrics). ML/DS enablement & MLOps: Experience supporting data scientists at scale, including model monitoring, feature stores (e.g., Feast/Vertex AI Feature Store), and data/model version management. Data/ML pipelines & CI/CD: Hands-on with LLM data pipelines (preprocessing), CI/CD for ML/data pipelines (e.g., Kubeflow, MLflow, Airflow, SageMaker Pipelines), and real-time inference streaming (Kafka/Spark Structured Streaming). Data platform & analytics: Strong data warehousing design/optimization, advanced SQL/performance tuning for high-volume flows, data quality automation/visualization, plus Power BI; cloud certification (Azure/AWS or similar) preferred.","$119,490 - $272,090"
96,Navya Vegesna,,LinkedIn,"Analyst, Data Science",Full time,Toyota,"Plano, TX",hybrid,2/13/2026,https://www.linkedin.com/jobs/search-results/?currentJobId=4371554509&eBP=CwEAAAGcZ0JkZQt6BofYcfd_DAX-O95u-4Cum4ie4IaBzRiETrhdmZNECQObhV-SxxJ8P3U6KieJk0Zx-FTiVg6GS1Z3RA-_Tq5f4BP6XZAUUmbqFAwANR75qr1UcpHsS7P0UJYXS5lbYP7fALb3HgmMo9pjnIlbV3lWKgK76WZtZH9Brl1fcXtiFSByFlOZMl5dbuZCVxd_4eQM-V2-6bMdCC6KZCz_m6QVK7evIUKoWmuFrPAP5A8ck8CYWvm4jpPNXh0n60ofKx7avpwJ0K7K9-Mm4ilsUwR7BJpJUfBijOvt4hIg4rpbAfm5yfQbc5ChZVBqm4it--_EpRYut7GASlZQtvD-oCyNgK4VjIcq74rhK6xFlyIKtci_wRX3_TOmncSVSS0SZME64nyVqTvnlfvfNQ2GJj_r09S0TVFXRrAKmAwR766ABzYX6D3XaHa0jGl23LQaBxkhg_tCLNy8MmsOF-Oa57Eo1X5TALF-1kcx-GFFa7oLjc-kYo-V1d2s_05tTZAlWMOFYCfl_Xm8pZoP_V61ubaVryyTJroqiYzfkMshpAhwC3QyCEgq&refId=NKfm5AsToaWsTSksyAEUUA%3D%3D&trackingId=IfpIX525evoMkJoEZXuBpQ%3D%3D&keywords=Data%20science%20full%20time%20open%20jobs&origin=JOB_SEARCH_PAGE_JOB_FILTER&referralSearchId=Lw78GtZqb9AtrOlPhBllig%3D%3D&start=0&f_TPR=r604800,"You will join a diverse, experienced team with rapidly growing scope and responsibility while also having access to one of the most unique data sets in the autonomous vehicle industry. Hence, we are seeking all skill levels to grow with the team.",bachelor's degree,Not specified,"Hands-on experience with tools such as Python or R. Using statistical and machine learning techniques to solve problems. Linear Regression, Logistic Regression, Time Series Analysis, Experimental Design, Generalized Linear Models, Mixed Modeling, Multivariate Statistics, Large-Scale Predictive Modeling, CHAID/decision trees, Gradient Boosted Trees, Random Forests, and Neural Networks. Pursue your development in Data Science","Bachelor’s degree or higher in a relevant analytical field. Knowledge of or exposure to building and optimizing data solutions using Python. Knowledge of or exposure to solving problems using a variety of statistical and machine learning techniques. Knowledge of or exposure to using statistical or machine learning frameworks to solve a variety of real-world problems (e.g., statsmodels, scikit-learn, PyTorch). Knowledge of methods like Logistic Regression, Time Series Analysis, GLMs, Mixed Modeling, Multivariate Statistics, Predictive Modeling, Decision Trees, Gradient-Boosted Trees, Random Forests, and Neural Networks. Proactive approach to identifying problems and developing innovative solutions. Added bonus if you have ;Master’s degree in relevant analytical field.Experience with version control systems such as GitHub, and familiarity with CI/CD practices to streamline model deployment and code management. Hands-on experience with cloud-based machine learning platforms (e.g., AWS SageMaker or Azure ML) to leverage scalable computing resources and tools. Demonstrated ability to lead through influence, effectively navigating and prioritizing complex cross-departmental projects to drive impactful change. Capability to replace and bridge existing legacy infrastructure and processes. ","Bachelor’s degree or higher in a relevant analytical field. Knowledge of or exposure to building and optimizing data solutions using Python. Knowledge of or exposure to solving problems using a variety of statistical and machine learning techniques. Knowledge of or exposure to using statistical or machine learning frameworks to solve a variety of real-world problems (e.g., statsmodels, scikit-learn, PyTorch). Knowledge of methods like Logistic Regression, Time Series Analysis, GLMs, Mixed Modeling, Multivariate Statistics, Predictive Modeling, Decision Trees, Gradient-Boosted Trees, Random Forests, and Neural Networks. Proactive approach to identifying problems and developing innovative solutions. ","Added bonus if you have ;Master’s degree in relevant analytical field.Experience with version control systems such as GitHub, and familiarity with CI/CD practices to streamline model deployment and code management. Hands-on experience with cloud-based machine learning platforms (e.g., AWS SageMaker or Azure ML) to leverage scalable computing resources and tools. Demonstrated ability to lead through influence, effectively navigating and prioritizing complex cross-departmental projects to drive impactful change. Capability to replace and bridge existing legacy infrastructure and processes. ",Not specified
97,Navya Vegesna,,LinkedIn,Data Scientist,Full time,JPMorganChase,"Plano, TX",on-site,2/10/2026,https://www.linkedin.com/jobs/search-results/?currentJobId=4371416601&eBP=CwEAAAGcZ0JkZXzEecBaJxXAAuy4I8-Kfh0oOphAH1sl1Qt9A_C2lYqz5ejEXttaqSzLWMdcH9YgcbECM1PpXWiJ5KMVlaVlMJwHaBbzx85Xjitzs_UYIEyCX1b-_0kTdGoD3_W6nEgXO1nZbcdYgKUOiVYfQjnSxzIe8veJ4HxBVGZFobCRmz0B3BNoaw3MnCOxeHcZ_9fGYayLTuMh0HMHTPUvN_SG0CDbxooSNNFBcaJYLUp9sAp7BGQHuiVVASUbx4vAEioINvX22TCZQhmriOdJjcUd0bR7YXWtvtWm9It_WOb_j00HhWtoDou-ljijHbwKbDIgmFxi3jMFPtKjAFFos8itWg-_0ViyrkqYVeuwPDRdbD-ZTF2EUC4Pyw2sXneHEZnaKzQecg0C-qOo_RMT9Ro4kOISo6J9Bkstx4bepST-CVo0BKp6CO7z_lRGWeQHreRp162R3LW7RqD9IiXXg6y3-juTIyt4JUkqe3RuRA3-emJRSb2cs3R1NOsrQnCIQ7QDU1XR-XwLNzb_IhIoM1446ZF7j6TWEQU84WEGY4q93CxO&refId=NKfm5AsToaWsTSksyAEUUA%3D%3D&trackingId=VacvzW%2FRu78YbgjFzwOe7Q%3D%3D&keywords=Data%20science%20full%20time%20open%20jobs&origin=JOB_SEARCH_PAGE_JOB_FILTER&referralSearchId=Lw78GtZqb9AtrOlPhBllig%3D%3D&start=0&f_TPR=r604800,"Duties: Generate analytical insights and develop statistical solutions that streamline business processes, uncover new opportunities, and bolster strategic decision-making. Develop and apply advanced statistical and mathematical models to analyze complex data trends and patterns. Perform data collection, organization, interpretation, and summarization. Conduct research on market trends and perform analysis of internal data. Utilize findings to craft actionable insights, guiding the strategic direction of the organization and identifying potential areas for product innovation and growth. Collaborate with cross-functional teams across product, business, and technology teams to implement data-driven strategies, supporting the creation and refinement of analytical models and algorithms that drive customer growth, improve engagement, and boost operational efficiency. Document and communicate complex technical and analytical results in a clear, concise manner to non-technical audiences, ensuring insights are accessible and actionable for decision-makers and senior management. Own monthly reporting of KPIs, highlighting any anomalies in trends for senior leadership.","master's degree in business analytics, data science, statistics, or related field of study","3+ years of experience in the job offered or as Data Scientist, Data Analyst, Project Engineer, or related occupation.","Generate analytical insights and develop statistical solutions that streamline business processes, uncover new opportunities, and bolster strategic decision-making. Develop and apply advanced statistical and mathematical models to analyze complex data trends and patterns. Perform data collection, organization, interpretation, and summarization. Conduct research on market trends and perform analysis of internal data. Utilize findings to craft actionable insights, guiding the strategic direction of the organization and identifying potential areas for product innovation and growth. Collaborate with cross-functional teams across product, business, and technology teams to implement data-driven strategies, supporting the creation and refinement of analytical models and algorithms that drive customer growth, improve engagement, and boost operational efficiency. Document and communicate complex technical and analytical results in a clear, concise manner to non-technical audiences, ensuring insights are accessible and actionable for decision-makers and senior management. Own monthly reporting of KPIs, highlighting any anomalies in trends for senior leadership.","Minimum education and experience required: Master's degree in Business Analytics, Data Science, Statistics, or related field of study plus 3 years of experience in the job offered or as Data Scientist, Data Analyst, Project Engineer, or related occupation. Skills Required: This position requires experience with the following: Performing SQL querying in Teradata, Oracle, or Snowflake database systems; Performing data manipulation, data structuring, data design flow, and query optimization using SQL or Python; Designing and developing analytical solutions and automating reports using SQL, Python, Alteryx, and Tableau; Designing, developing, and delivering dashboards, reports, and scorecards using Adobe Analytics; Performing data analysis using Adobe Analytics; Performing statistical analysis, deriving insights, and evaluating experiments or A/B tests using machine learning methods, including logistic regression, multivariate regression, classification techniques, attribution, cohort analysis, associative rule mining, and predictive modeling; Translating complex data into actionable insights for strategic decision-making; Synthesizing data analysis results into Tableau dashboards and Excel reports for presenting findings to business stakeholders.","Minimum education and experience required: Master's degree in Business Analytics, Data Science, Statistics, or related field of study plus 3 years of experience in the job offered or as Data Scientist, Data Analyst, Project Engineer, or related occupation. Skills Required: This position requires experience with the following: Performing SQL querying in Teradata, Oracle, or Snowflake database systems; Performing data manipulation, data structuring, data design flow, and query optimization using SQL or Python; Designing and developing analytical solutions and automating reports using SQL, Python, Alteryx, and Tableau; Designing, developing, and delivering dashboards, reports, and scorecards using Adobe Analytics; Performing data analysis using Adobe Analytics; Performing statistical analysis, deriving insights, and evaluating experiments or A/B tests using machine learning methods, including logistic regression, multivariate regression, classification techniques, attribution, cohort analysis, associative rule mining, and predictive modeling; Translating complex data into actionable insights for strategic decision-making; Synthesizing data analysis results into Tableau dashboards and Excel reports for presenting findings to business stakeholders.","Minimum education and experience required: Master's degree in Business Analytics, Data Science, Statistics, or related field of study plus 3 years of experience in the job offered or as Data Scientist, Data Analyst, Project Engineer, or related occupation. Skills Required: This position requires experience with the following: Performing SQL querying in Teradata, Oracle, or Snowflake database systems; Performing data manipulation, data structuring, data design flow, and query optimization using SQL or Python; Designing and developing analytical solutions and automating reports using SQL, Python, Alteryx, and Tableau; Designing, developing, and delivering dashboards, reports, and scorecards using Adobe Analytics; Performing data analysis using Adobe Analytics; Performing statistical analysis, deriving insights, and evaluating experiments or A/B tests using machine learning methods, including logistic regression, multivariate regression, classification techniques, attribution, cohort analysis, associative rule mining, and predictive modeling; Translating complex data into actionable insights for strategic decision-making; Synthesizing data analysis results into Tableau dashboards and Excel reports for presenting findings to business stakeholders.",Not specified
